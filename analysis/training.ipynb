{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded config:  {\"development\": {\"debug_mode\": true, \"profile\": false, \"runtime\": 36000, \"display_logs_in_console\": false, \"output_directory\": \"data/\"}, \"game\": {\"board_size\": 10, \"num_moves\": 6233, \"moves_directory\": \"../data/moves_10/\"}, \"network\": {\"main_body_channels\": 64, \"value_head_channels\": 16, \"value_head_flat_layer_width\": 64, \"policy_head_channels\": 64, \"residual_blocks\": 8}, \"architecture\": {\"gameplay_processes\": 6, \"coroutines_per_process\": 256, \"inference_batch_size\": 128}, \"mcts\": {\"full_move_probability\": 0.2, \"full_move_rollouts\": 500, \"fast_move_rollouts\": 100, \"ucb_exploration\": 1.4, \"root_dirichlet_alpha\": 0.03, \"root_exploration_fraction\": 0.25}}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "os.environ[\"CONFIG_PATHS\"] = \"../configs/small_model.toml,../configs/notebook_overrides.toml\"\n",
    "sys.path.append(\"../src\")\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "import time\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from display import Display\n",
    "from configuration import moves_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neural_net import NeuralNet\n",
    "from training.load_games import load_games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "MOVES = moves_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reserving 262 files for testing.\n",
      "Loaded 107244 training samples.\n",
      "Loaded 11910 testing samples.\n"
     ]
    }
   ],
   "source": [
    "train_data, test_data = load_games(\"../data/2024-11-11_13-31-42-gasterolichenes/games\")\n",
    "\n",
    "train_dataset = TensorDataset(*train_data)\n",
    "test_dataset = TensorDataset(*test_data)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _print_losses(value_loss, policy_loss, accuracy=None):\n",
    "    print(\"   Avg value loss:  \", value_loss)\n",
    "    print(\"   Avg policy loss: \", policy_loss)\n",
    "    print(\"   Avg total loss:  \", value_loss + policy_loss)\n",
    "    if accuracy:\n",
    "        print(\"   Accuracy:  \", accuracy)\n",
    "\n",
    "def _train(dataloader, optimizer, model, value_losses, policy_losses):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, (occupancies, children_visits, values) in enumerate(dataloader):\n",
    "        start_time = time.time()\n",
    "\n",
    "        batch_size = len(occupancies)\n",
    "\n",
    "        occupancies = occupancies.to(\"mps\")\n",
    "        children_visits = children_visits.to(\"mps\")\n",
    "        values = values.to(\"mps\")\n",
    "\n",
    "        pred_values, pred_children_visits = model(occupancies)\n",
    "        value_loss = nn.CrossEntropyLoss()(pred_values, values)\n",
    "        policy_loss = 0.158 * nn.CrossEntropyLoss()(pred_children_visits, children_visits)\n",
    "        loss = value_loss + policy_loss\n",
    "\n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        current = (batch + 1) * batch_size \n",
    "        runtime = time.time() - start_time\n",
    "        print(f\"Training [{current:>5d}/{size:>5d}] [{runtime / batch_size:e}s per sample]\")\n",
    "        _print_losses(\n",
    "            value_loss.item(),\n",
    "            policy_loss.item(),\n",
    "        )\n",
    "    value_losses.append(value_loss.item())\n",
    "    policy_losses.append(policy_loss.item())\n",
    "\n",
    "def _test(dataloader, model, value_losses, policy_losses):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.eval()\n",
    "\n",
    "    sum_value_loss, sum_policy_loss = 0.0, 0.0\n",
    "    correct_winner_count = 0\n",
    "    correct_stupid_winner_count = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for occupancies, children_visits, values in dataloader:\n",
    "            occupancies = occupancies.to(\"mps\")\n",
    "            children_visits = children_visits.to(\"mps\")\n",
    "            values = values.to(\"mps\")\n",
    "\n",
    "            pred_values, pred_children_visits = model(occupancies)         \n",
    "            sum_value_loss += nn.CrossEntropyLoss(reduction=\"sum\")(pred_values, values).item()\n",
    "            sum_policy_loss += 0.158 * nn.CrossEntropyLoss(reduction=\"sum\")(pred_children_visits, children_visits).item()\n",
    "\n",
    "            pred_values = pred_values.numpy(force=True)\n",
    "            values = values.numpy(force=True)\n",
    "\n",
    "            stupid_predicted_winners = np.argmax(np.sum(occupancies.numpy(force=True), axis=(2, 3)), axis=1)\n",
    "            predicted_winners = np.argmax(pred_values, axis=1)\n",
    "            predicted_winner_real_scores = values[\n",
    "                np.arange(len(predicted_winners)),\n",
    "                predicted_winners,\n",
    "            ]\n",
    "            correct_winner_count += np.sum(predicted_winner_real_scores > 0)\n",
    "\n",
    "            stupid_predicted_winner_real_scores =  values[\n",
    "                np.arange(len(stupid_predicted_winners)),\n",
    "                stupid_predicted_winners,\n",
    "            ]\n",
    "            correct_stupid_winner_count += np.sum(stupid_predicted_winner_real_scores > 0)\n",
    "\n",
    "    value_loss = sum_value_loss / size\n",
    "    policy_loss = sum_policy_loss / size\n",
    "    accuracy = correct_winner_count / size\n",
    "\n",
    "    value_losses.append(value_loss)\n",
    "    policy_losses.append(policy_loss)\n",
    "    print(\"Test Error:\")\n",
    "    _print_losses(\n",
    "        value_loss,\n",
    "        policy_loss,\n",
    "    )\n",
    "    print(\"Smart accuracy: \", accuracy)\n",
    "    print(\"Stupid accuracy: \", correct_stupid_winner_count / size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NeuralNet().to(\"mps\")\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "Training [  128/107244] [5.949922e-04s per sample]\n",
      "   Avg value loss:   1.18314790725708\n",
      "   Avg policy loss:  0.6476656198501587\n",
      "   Avg total loss:   1.8308135271072388\n",
      "Training [  256/107244] [2.274383e-04s per sample]\n",
      "   Avg value loss:   1.1291937828063965\n",
      "   Avg policy loss:  0.6641345620155334\n",
      "   Avg total loss:   1.79332834482193\n",
      "Training [  384/107244] [2.216939e-04s per sample]\n",
      "   Avg value loss:   1.1016137599945068\n",
      "   Avg policy loss:  0.6628749370574951\n",
      "   Avg total loss:   1.764488697052002\n",
      "Training [  512/107244] [2.226718e-04s per sample]\n",
      "   Avg value loss:   1.1522705554962158\n",
      "   Avg policy loss:  0.6280677318572998\n",
      "   Avg total loss:   1.7803382873535156\n",
      "Training [  640/107244] [2.203602e-04s per sample]\n",
      "   Avg value loss:   1.1879243850708008\n",
      "   Avg policy loss:  0.6094168424606323\n",
      "   Avg total loss:   1.797341227531433\n",
      "Training [  768/107244] [2.140161e-04s per sample]\n",
      "   Avg value loss:   1.2274730205535889\n",
      "   Avg policy loss:  0.6305207014083862\n",
      "   Avg total loss:   1.857993721961975\n",
      "Training [  896/107244] [2.081320e-04s per sample]\n",
      "   Avg value loss:   1.2029883861541748\n",
      "   Avg policy loss:  0.632415235042572\n",
      "   Avg total loss:   1.8354036211967468\n",
      "Training [ 1024/107244] [2.204217e-04s per sample]\n",
      "   Avg value loss:   1.098771572113037\n",
      "   Avg policy loss:  0.6495009064674377\n",
      "   Avg total loss:   1.7482724785804749\n",
      "Training [ 1152/107244] [2.165716e-04s per sample]\n",
      "   Avg value loss:   1.2266674041748047\n",
      "   Avg policy loss:  0.6399731636047363\n",
      "   Avg total loss:   1.866640567779541\n",
      "Training [ 1280/107244] [2.183653e-04s per sample]\n",
      "   Avg value loss:   1.1019957065582275\n",
      "   Avg policy loss:  0.6378347277641296\n",
      "   Avg total loss:   1.7398304343223572\n",
      "Training [ 1408/107244] [2.270155e-04s per sample]\n",
      "   Avg value loss:   1.1914035081863403\n",
      "   Avg policy loss:  0.6452972888946533\n",
      "   Avg total loss:   1.8367007970809937\n",
      "Training [ 1536/107244] [2.257489e-04s per sample]\n",
      "   Avg value loss:   1.1413624286651611\n",
      "   Avg policy loss:  0.6356400847434998\n",
      "   Avg total loss:   1.7770025134086609\n",
      "Training [ 1664/107244] [2.387036e-04s per sample]\n",
      "   Avg value loss:   1.0925246477127075\n",
      "   Avg policy loss:  0.6227572560310364\n",
      "   Avg total loss:   1.715281903743744\n",
      "Training [ 1792/107244] [2.257265e-04s per sample]\n",
      "   Avg value loss:   1.1745749711990356\n",
      "   Avg policy loss:  0.614266037940979\n",
      "   Avg total loss:   1.7888410091400146\n",
      "Training [ 1920/107244] [2.321191e-04s per sample]\n",
      "   Avg value loss:   1.1502187252044678\n",
      "   Avg policy loss:  0.6660791635513306\n",
      "   Avg total loss:   1.8162978887557983\n",
      "Training [ 2048/107244] [2.456717e-04s per sample]\n",
      "   Avg value loss:   1.099020004272461\n",
      "   Avg policy loss:  0.6506331562995911\n",
      "   Avg total loss:   1.749653160572052\n",
      "Training [ 2176/107244] [2.351943e-04s per sample]\n",
      "   Avg value loss:   1.1472444534301758\n",
      "   Avg policy loss:  0.6324348449707031\n",
      "   Avg total loss:   1.779679298400879\n",
      "Training [ 2304/107244] [2.419129e-04s per sample]\n",
      "   Avg value loss:   1.176509976387024\n",
      "   Avg policy loss:  0.6368370056152344\n",
      "   Avg total loss:   1.8133469820022583\n",
      "Training [ 2432/107244] [2.324600e-04s per sample]\n",
      "   Avg value loss:   1.1146321296691895\n",
      "   Avg policy loss:  0.6395384073257446\n",
      "   Avg total loss:   1.754170536994934\n",
      "Training [ 2560/107244] [2.176482e-04s per sample]\n",
      "   Avg value loss:   1.0980949401855469\n",
      "   Avg policy loss:  0.6590040922164917\n",
      "   Avg total loss:   1.7570990324020386\n",
      "Training [ 2688/107244] [2.034064e-04s per sample]\n",
      "   Avg value loss:   1.1418137550354004\n",
      "   Avg policy loss:  0.6273272037506104\n",
      "   Avg total loss:   1.7691409587860107\n",
      "Training [ 2816/107244] [2.247188e-04s per sample]\n",
      "   Avg value loss:   1.112877607345581\n",
      "   Avg policy loss:  0.659842312335968\n",
      "   Avg total loss:   1.772719919681549\n",
      "Training [ 2944/107244] [2.233442e-04s per sample]\n",
      "   Avg value loss:   1.2935367822647095\n",
      "   Avg policy loss:  0.6308745741844177\n",
      "   Avg total loss:   1.9244113564491272\n",
      "Training [ 3072/107244] [2.105702e-04s per sample]\n",
      "   Avg value loss:   1.1767116785049438\n",
      "   Avg policy loss:  0.6230970621109009\n",
      "   Avg total loss:   1.7998087406158447\n",
      "Training [ 3200/107244] [2.292413e-04s per sample]\n",
      "   Avg value loss:   1.220080852508545\n",
      "   Avg policy loss:  0.6415674686431885\n",
      "   Avg total loss:   1.8616483211517334\n",
      "Training [ 3328/107244] [2.183039e-04s per sample]\n",
      "   Avg value loss:   1.1802446842193604\n",
      "   Avg policy loss:  0.6669996380805969\n",
      "   Avg total loss:   1.8472443222999573\n",
      "Training [ 3456/107244] [2.110787e-04s per sample]\n",
      "   Avg value loss:   1.2023651599884033\n",
      "   Avg policy loss:  0.6410425305366516\n",
      "   Avg total loss:   1.843407690525055\n",
      "Training [ 3584/107244] [2.306476e-04s per sample]\n",
      "   Avg value loss:   1.2371195554733276\n",
      "   Avg policy loss:  0.6066135168075562\n",
      "   Avg total loss:   1.8437330722808838\n",
      "Training [ 3712/107244] [2.304986e-04s per sample]\n",
      "   Avg value loss:   1.2066569328308105\n",
      "   Avg policy loss:  0.6425086259841919\n",
      "   Avg total loss:   1.8491655588150024\n",
      "Training [ 3840/107244] [2.186652e-04s per sample]\n",
      "   Avg value loss:   1.2039141654968262\n",
      "   Avg policy loss:  0.6446083188056946\n",
      "   Avg total loss:   1.8485224843025208\n",
      "Training [ 3968/107244] [2.361406e-04s per sample]\n",
      "   Avg value loss:   1.2071417570114136\n",
      "   Avg policy loss:  0.6051971912384033\n",
      "   Avg total loss:   1.812338948249817\n",
      "Training [ 4096/107244] [2.196804e-04s per sample]\n",
      "   Avg value loss:   1.2007733583450317\n",
      "   Avg policy loss:  0.6406014561653137\n",
      "   Avg total loss:   1.8413748145103455\n",
      "Training [ 4224/107244] [2.277046e-04s per sample]\n",
      "   Avg value loss:   1.1173300743103027\n",
      "   Avg policy loss:  0.6347730159759521\n",
      "   Avg total loss:   1.7521030902862549\n",
      "Training [ 4352/107244] [2.198983e-04s per sample]\n",
      "   Avg value loss:   1.166203498840332\n",
      "   Avg policy loss:  0.6439319849014282\n",
      "   Avg total loss:   1.8101354837417603\n",
      "Training [ 4480/107244] [2.116878e-04s per sample]\n",
      "   Avg value loss:   1.183410406112671\n",
      "   Avg policy loss:  0.6370866298675537\n",
      "   Avg total loss:   1.8204970359802246\n",
      "Training [ 4608/107244] [2.208203e-04s per sample]\n",
      "   Avg value loss:   1.073229432106018\n",
      "   Avg policy loss:  0.6394560933113098\n",
      "   Avg total loss:   1.7126855254173279\n",
      "Training [ 4736/107244] [2.213810e-04s per sample]\n",
      "   Avg value loss:   1.1976306438446045\n",
      "   Avg policy loss:  0.6152257919311523\n",
      "   Avg total loss:   1.8128564357757568\n",
      "Training [ 4864/107244] [2.253428e-04s per sample]\n",
      "   Avg value loss:   1.1592844724655151\n",
      "   Avg policy loss:  0.6181025505065918\n",
      "   Avg total loss:   1.777387022972107\n",
      "Training [ 4992/107244] [2.254210e-04s per sample]\n",
      "   Avg value loss:   1.1601049900054932\n",
      "   Avg policy loss:  0.640718400478363\n",
      "   Avg total loss:   1.8008233904838562\n",
      "Training [ 5120/107244] [2.251323e-04s per sample]\n",
      "   Avg value loss:   1.083510160446167\n",
      "   Avg policy loss:  0.6213610172271729\n",
      "   Avg total loss:   1.7048711776733398\n",
      "Training [ 5248/107244] [2.272818e-04s per sample]\n",
      "   Avg value loss:   1.206820011138916\n",
      "   Avg policy loss:  0.6406439542770386\n",
      "   Avg total loss:   1.8474639654159546\n",
      "Training [ 5376/107244] [2.145544e-04s per sample]\n",
      "   Avg value loss:   1.1295956373214722\n",
      "   Avg policy loss:  0.6365807056427002\n",
      "   Avg total loss:   1.7661763429641724\n",
      "Training [ 5504/107244] [2.153292e-04s per sample]\n",
      "   Avg value loss:   1.2162433862686157\n",
      "   Avg policy loss:  0.6406222581863403\n",
      "   Avg total loss:   1.856865644454956\n",
      "Training [ 5632/107244] [2.278984e-04s per sample]\n",
      "   Avg value loss:   1.1964473724365234\n",
      "   Avg policy loss:  0.62107253074646\n",
      "   Avg total loss:   1.8175199031829834\n",
      "Training [ 5760/107244] [2.166871e-04s per sample]\n",
      "   Avg value loss:   1.1971802711486816\n",
      "   Avg policy loss:  0.6199197173118591\n",
      "   Avg total loss:   1.8170999884605408\n",
      "Training [ 5888/107244] [2.011172e-04s per sample]\n",
      "   Avg value loss:   1.2182836532592773\n",
      "   Avg policy loss:  0.6420845985412598\n",
      "   Avg total loss:   1.860368251800537\n",
      "Training [ 6016/107244] [2.072025e-04s per sample]\n",
      "   Avg value loss:   1.2210094928741455\n",
      "   Avg policy loss:  0.6260960698127747\n",
      "   Avg total loss:   1.8471055626869202\n",
      "Training [ 6144/107244] [2.229996e-04s per sample]\n",
      "   Avg value loss:   1.1582281589508057\n",
      "   Avg policy loss:  0.6439659595489502\n",
      "   Avg total loss:   1.8021941184997559\n",
      "Training [ 6272/107244] [2.075993e-04s per sample]\n",
      "   Avg value loss:   1.1493868827819824\n",
      "   Avg policy loss:  0.6577599048614502\n",
      "   Avg total loss:   1.8071467876434326\n",
      "Training [ 6400/107244] [2.225079e-04s per sample]\n",
      "   Avg value loss:   1.1932580471038818\n",
      "   Avg policy loss:  0.6379793286323547\n",
      "   Avg total loss:   1.8312373757362366\n",
      "Training [ 6528/107244] [2.225097e-04s per sample]\n",
      "   Avg value loss:   1.1907843351364136\n",
      "   Avg policy loss:  0.6584034562110901\n",
      "   Avg total loss:   1.8491877913475037\n",
      "Training [ 6656/107244] [2.121888e-04s per sample]\n",
      "   Avg value loss:   1.203161597251892\n",
      "   Avg policy loss:  0.6293004155158997\n",
      "   Avg total loss:   1.8324620127677917\n",
      "Training [ 6784/107244] [2.145935e-04s per sample]\n",
      "   Avg value loss:   1.102018117904663\n",
      "   Avg policy loss:  0.6634120941162109\n",
      "   Avg total loss:   1.765430212020874\n",
      "Training [ 6912/107244] [2.159849e-04s per sample]\n",
      "   Avg value loss:   1.13198983669281\n",
      "   Avg policy loss:  0.6266845464706421\n",
      "   Avg total loss:   1.7586743831634521\n",
      "Training [ 7040/107244] [2.126079e-04s per sample]\n",
      "   Avg value loss:   1.1843546628952026\n",
      "   Avg policy loss:  0.6373215913772583\n",
      "   Avg total loss:   1.821676254272461\n",
      "Training [ 7168/107244] [2.276339e-04s per sample]\n",
      "   Avg value loss:   1.231642484664917\n",
      "   Avg policy loss:  0.6329812407493591\n",
      "   Avg total loss:   1.8646237254142761\n",
      "Training [ 7296/107244] [2.138838e-04s per sample]\n",
      "   Avg value loss:   1.1096646785736084\n",
      "   Avg policy loss:  0.6430743932723999\n",
      "   Avg total loss:   1.7527390718460083\n",
      "Training [ 7424/107244] [2.266187e-04s per sample]\n",
      "   Avg value loss:   1.0925931930541992\n",
      "   Avg policy loss:  0.6229933500289917\n",
      "   Avg total loss:   1.715586543083191\n",
      "Training [ 7552/107244] [2.123360e-04s per sample]\n",
      "   Avg value loss:   1.141768455505371\n",
      "   Avg policy loss:  0.6353724598884583\n",
      "   Avg total loss:   1.7771409153938293\n",
      "Training [ 7680/107244] [2.199057e-04s per sample]\n",
      "   Avg value loss:   1.1394575834274292\n",
      "   Avg policy loss:  0.6418190002441406\n",
      "   Avg total loss:   1.7812765836715698\n",
      "Training [ 7808/107244] [2.276152e-04s per sample]\n",
      "   Avg value loss:   1.1993975639343262\n",
      "   Avg policy loss:  0.6514079570770264\n",
      "   Avg total loss:   1.8508055210113525\n",
      "Training [ 7936/107244] [2.229307e-04s per sample]\n",
      "   Avg value loss:   1.1698399782180786\n",
      "   Avg policy loss:  0.6281821727752686\n",
      "   Avg total loss:   1.7980221509933472\n",
      "Training [ 8064/107244] [2.160799e-04s per sample]\n",
      "   Avg value loss:   1.2348461151123047\n",
      "   Avg policy loss:  0.6277254223823547\n",
      "   Avg total loss:   1.8625715374946594\n",
      "Training [ 8192/107244] [2.398118e-04s per sample]\n",
      "   Avg value loss:   1.1923350095748901\n",
      "   Avg policy loss:  0.6413727402687073\n",
      "   Avg total loss:   1.8337077498435974\n",
      "Training [ 8320/107244] [2.197251e-04s per sample]\n",
      "   Avg value loss:   1.1399413347244263\n",
      "   Avg policy loss:  0.6210862994194031\n",
      "   Avg total loss:   1.7610276341438293\n",
      "Training [ 8448/107244] [2.262183e-04s per sample]\n",
      "   Avg value loss:   1.1585891246795654\n",
      "   Avg policy loss:  0.5847011804580688\n",
      "   Avg total loss:   1.7432903051376343\n",
      "Training [ 8576/107244] [2.180003e-04s per sample]\n",
      "   Avg value loss:   1.138899564743042\n",
      "   Avg policy loss:  0.6287724375724792\n",
      "   Avg total loss:   1.7676720023155212\n",
      "Training [ 8704/107244] [2.333522e-04s per sample]\n",
      "   Avg value loss:   1.1360284090042114\n",
      "   Avg policy loss:  0.6442356705665588\n",
      "   Avg total loss:   1.7802640795707703\n",
      "Training [ 8832/107244] [2.109222e-04s per sample]\n",
      "   Avg value loss:   1.1447241306304932\n",
      "   Avg policy loss:  0.6470940113067627\n",
      "   Avg total loss:   1.7918181419372559\n",
      "Training [ 8960/107244] [2.104677e-04s per sample]\n",
      "   Avg value loss:   1.2139300107955933\n",
      "   Avg policy loss:  0.6589341759681702\n",
      "   Avg total loss:   1.8728641867637634\n",
      "Training [ 9088/107244] [2.305731e-04s per sample]\n",
      "   Avg value loss:   1.0953774452209473\n",
      "   Avg policy loss:  0.6186293363571167\n",
      "   Avg total loss:   1.714006781578064\n",
      "Training [ 9216/107244] [2.210252e-04s per sample]\n",
      "   Avg value loss:   1.1728861331939697\n",
      "   Avg policy loss:  0.6155824065208435\n",
      "   Avg total loss:   1.7884685397148132\n",
      "Training [ 9344/107244] [2.353508e-04s per sample]\n",
      "   Avg value loss:   1.2544612884521484\n",
      "   Avg policy loss:  0.6422369480133057\n",
      "   Avg total loss:   1.896698236465454\n",
      "Training [ 9472/107244] [2.281237e-04s per sample]\n",
      "   Avg value loss:   1.1746573448181152\n",
      "   Avg policy loss:  0.6371031999588013\n",
      "   Avg total loss:   1.8117605447769165\n",
      "Training [ 9600/107244] [5.424134e-04s per sample]\n",
      "   Avg value loss:   1.1426373720169067\n",
      "   Avg policy loss:  0.6185559034347534\n",
      "   Avg total loss:   1.7611932754516602\n",
      "Training [ 9728/107244] [2.274197e-04s per sample]\n",
      "   Avg value loss:   1.2043371200561523\n",
      "   Avg policy loss:  0.6156314015388489\n",
      "   Avg total loss:   1.8199685215950012\n",
      "Training [ 9856/107244] [2.234522e-04s per sample]\n",
      "   Avg value loss:   1.210982084274292\n",
      "   Avg policy loss:  0.6339580416679382\n",
      "   Avg total loss:   1.8449401259422302\n",
      "Training [ 9984/107244] [2.119672e-04s per sample]\n",
      "   Avg value loss:   1.0482516288757324\n",
      "   Avg policy loss:  0.6105810403823853\n",
      "   Avg total loss:   1.6588326692581177\n",
      "Training [10112/107244] [2.142880e-04s per sample]\n",
      "   Avg value loss:   1.1526038646697998\n",
      "   Avg policy loss:  0.62469482421875\n",
      "   Avg total loss:   1.7772986888885498\n",
      "Training [10240/107244] [2.411883e-04s per sample]\n",
      "   Avg value loss:   1.1788122653961182\n",
      "   Avg policy loss:  0.6298195719718933\n",
      "   Avg total loss:   1.8086318373680115\n",
      "Training [10368/107244] [2.424773e-04s per sample]\n",
      "   Avg value loss:   1.1431127786636353\n",
      "   Avg policy loss:  0.5997456312179565\n",
      "   Avg total loss:   1.7428584098815918\n",
      "Training [10496/107244] [2.225321e-04s per sample]\n",
      "   Avg value loss:   1.1950829029083252\n",
      "   Avg policy loss:  0.6130157113075256\n",
      "   Avg total loss:   1.8080986142158508\n",
      "Training [10624/107244] [2.285410e-04s per sample]\n",
      "   Avg value loss:   1.1503419876098633\n",
      "   Avg policy loss:  0.6124258041381836\n",
      "   Avg total loss:   1.7627677917480469\n",
      "Training [10752/107244] [2.208427e-04s per sample]\n",
      "   Avg value loss:   1.092299222946167\n",
      "   Avg policy loss:  0.6344625353813171\n",
      "   Avg total loss:   1.7267617583274841\n",
      "Training [10880/107244] [2.331641e-04s per sample]\n",
      "   Avg value loss:   1.190581202507019\n",
      "   Avg policy loss:  0.6400905847549438\n",
      "   Avg total loss:   1.830671787261963\n",
      "Training [11008/107244] [2.170075e-04s per sample]\n",
      "   Avg value loss:   1.1106656789779663\n",
      "   Avg policy loss:  0.6246041059494019\n",
      "   Avg total loss:   1.7352697849273682\n",
      "Training [11136/107244] [2.400950e-04s per sample]\n",
      "   Avg value loss:   1.2777149677276611\n",
      "   Avg policy loss:  0.6283157467842102\n",
      "   Avg total loss:   1.9060307145118713\n",
      "Training [11264/107244] [2.224222e-04s per sample]\n",
      "   Avg value loss:   1.1988918781280518\n",
      "   Avg policy loss:  0.6229329109191895\n",
      "   Avg total loss:   1.8218247890472412\n",
      "Training [11392/107244] [2.123434e-04s per sample]\n",
      "   Avg value loss:   1.1107566356658936\n",
      "   Avg policy loss:  0.6278936862945557\n",
      "   Avg total loss:   1.7386503219604492\n",
      "Training [11520/107244] [2.250131e-04s per sample]\n",
      "   Avg value loss:   1.1782498359680176\n",
      "   Avg policy loss:  0.6431767344474792\n",
      "   Avg total loss:   1.8214265704154968\n",
      "Training [11648/107244] [2.116412e-04s per sample]\n",
      "   Avg value loss:   1.1378074884414673\n",
      "   Avg policy loss:  0.615887463092804\n",
      "   Avg total loss:   1.7536949515342712\n",
      "Training [11776/107244] [2.134386e-04s per sample]\n",
      "   Avg value loss:   1.1664984226226807\n",
      "   Avg policy loss:  0.6249455809593201\n",
      "   Avg total loss:   1.7914440035820007\n",
      "Training [11904/107244] [2.245530e-04s per sample]\n",
      "   Avg value loss:   1.1561115980148315\n",
      "   Avg policy loss:  0.6485976576805115\n",
      "   Avg total loss:   1.804709255695343\n",
      "Training [12032/107244] [2.114456e-04s per sample]\n",
      "   Avg value loss:   1.0905544757843018\n",
      "   Avg policy loss:  0.623167872428894\n",
      "   Avg total loss:   1.7137223482131958\n",
      "Training [12160/107244] [2.312586e-04s per sample]\n",
      "   Avg value loss:   1.1941940784454346\n",
      "   Avg policy loss:  0.6260702013969421\n",
      "   Avg total loss:   1.8202642798423767\n",
      "Training [12288/107244] [2.381634e-04s per sample]\n",
      "   Avg value loss:   1.1137505769729614\n",
      "   Avg policy loss:  0.6184101104736328\n",
      "   Avg total loss:   1.7321606874465942\n",
      "Training [12416/107244] [2.171025e-04s per sample]\n",
      "   Avg value loss:   1.1638721227645874\n",
      "   Avg policy loss:  0.624802827835083\n",
      "   Avg total loss:   1.7886749505996704\n",
      "Training [12544/107244] [2.098288e-04s per sample]\n",
      "   Avg value loss:   1.1975538730621338\n",
      "   Avg policy loss:  0.640789806842804\n",
      "   Avg total loss:   1.8383436799049377\n",
      "Training [12672/107244] [2.228059e-04s per sample]\n",
      "   Avg value loss:   1.206095576286316\n",
      "   Avg policy loss:  0.6379027962684631\n",
      "   Avg total loss:   1.843998372554779\n",
      "Training [12800/107244] [2.179760e-04s per sample]\n",
      "   Avg value loss:   1.1488043069839478\n",
      "   Avg policy loss:  0.6328944563865662\n",
      "   Avg total loss:   1.781698763370514\n",
      "Training [12928/107244] [2.251808e-04s per sample]\n",
      "   Avg value loss:   1.152848243713379\n",
      "   Avg policy loss:  0.617216169834137\n",
      "   Avg total loss:   1.7700644135475159\n",
      "Training [13056/107244] [2.177581e-04s per sample]\n",
      "   Avg value loss:   1.1372357606887817\n",
      "   Avg policy loss:  0.6435092091560364\n",
      "   Avg total loss:   1.7807449698448181\n",
      "Training [13184/107244] [2.233908e-04s per sample]\n",
      "   Avg value loss:   1.1772968769073486\n",
      "   Avg policy loss:  0.6467686891555786\n",
      "   Avg total loss:   1.8240655660629272\n",
      "Training [13312/107244] [2.297051e-04s per sample]\n",
      "   Avg value loss:   1.160435676574707\n",
      "   Avg policy loss:  0.6132007241249084\n",
      "   Avg total loss:   1.7736364006996155\n",
      "Training [13440/107244] [2.292283e-04s per sample]\n",
      "   Avg value loss:   1.2426667213439941\n",
      "   Avg policy loss:  0.6446679830551147\n",
      "   Avg total loss:   1.8873347043991089\n",
      "Training [13568/107244] [2.213586e-04s per sample]\n",
      "   Avg value loss:   1.1806371212005615\n",
      "   Avg policy loss:  0.6336866617202759\n",
      "   Avg total loss:   1.8143237829208374\n",
      "Training [13696/107244] [2.029520e-04s per sample]\n",
      "   Avg value loss:   1.2155842781066895\n",
      "   Avg policy loss:  0.6246902942657471\n",
      "   Avg total loss:   1.8402745723724365\n",
      "Training [13824/107244] [2.250653e-04s per sample]\n",
      "   Avg value loss:   1.1777732372283936\n",
      "   Avg policy loss:  0.6524141430854797\n",
      "   Avg total loss:   1.8301873803138733\n",
      "Training [13952/107244] [2.268981e-04s per sample]\n",
      "   Avg value loss:   1.1233114004135132\n",
      "   Avg policy loss:  0.6364858150482178\n",
      "   Avg total loss:   1.759797215461731\n",
      "Training [14080/107244] [2.143607e-04s per sample]\n",
      "   Avg value loss:   1.1576765775680542\n",
      "   Avg policy loss:  0.5891623497009277\n",
      "   Avg total loss:   1.746838927268982\n",
      "Training [14208/107244] [2.126247e-04s per sample]\n",
      "   Avg value loss:   1.1320549249649048\n",
      "   Avg policy loss:  0.6158706545829773\n",
      "   Avg total loss:   1.747925579547882\n",
      "Training [14336/107244] [2.168976e-04s per sample]\n",
      "   Avg value loss:   1.1930373907089233\n",
      "   Avg policy loss:  0.6071008443832397\n",
      "   Avg total loss:   1.800138235092163\n",
      "Training [14464/107244] [2.107900e-04s per sample]\n",
      "   Avg value loss:   1.2029035091400146\n",
      "   Avg policy loss:  0.632290780544281\n",
      "   Avg total loss:   1.8351942896842957\n",
      "Training [14592/107244] [2.136026e-04s per sample]\n",
      "   Avg value loss:   1.1120465993881226\n",
      "   Avg policy loss:  0.6461242437362671\n",
      "   Avg total loss:   1.7581708431243896\n",
      "Training [14720/107244] [2.238285e-04s per sample]\n",
      "   Avg value loss:   1.1701953411102295\n",
      "   Avg policy loss:  0.6182417869567871\n",
      "   Avg total loss:   1.7884371280670166\n",
      "Training [14848/107244] [2.196971e-04s per sample]\n",
      "   Avg value loss:   1.1476209163665771\n",
      "   Avg policy loss:  0.6379502415657043\n",
      "   Avg total loss:   1.7855711579322815\n",
      "Training [14976/107244] [2.246816e-04s per sample]\n",
      "   Avg value loss:   1.1602942943572998\n",
      "   Avg policy loss:  0.6269969344139099\n",
      "   Avg total loss:   1.7872912287712097\n",
      "Training [15104/107244] [2.136789e-04s per sample]\n",
      "   Avg value loss:   1.1805298328399658\n",
      "   Avg policy loss:  0.6325470209121704\n",
      "   Avg total loss:   1.8130768537521362\n",
      "Training [15232/107244] [2.063438e-04s per sample]\n",
      "   Avg value loss:   1.1237316131591797\n",
      "   Avg policy loss:  0.6147386431694031\n",
      "   Avg total loss:   1.7384702563285828\n",
      "Training [15360/107244] [2.148524e-04s per sample]\n",
      "   Avg value loss:   1.1443977355957031\n",
      "   Avg policy loss:  0.6376966834068298\n",
      "   Avg total loss:   1.782094419002533\n",
      "Training [15488/107244] [2.124533e-04s per sample]\n",
      "   Avg value loss:   1.1925444602966309\n",
      "   Avg policy loss:  0.640975296497345\n",
      "   Avg total loss:   1.8335197567939758\n",
      "Training [15616/107244] [2.058279e-04s per sample]\n",
      "   Avg value loss:   1.0563783645629883\n",
      "   Avg policy loss:  0.6313794255256653\n",
      "   Avg total loss:   1.6877577900886536\n",
      "Training [15744/107244] [2.018809e-04s per sample]\n",
      "   Avg value loss:   1.1507534980773926\n",
      "   Avg policy loss:  0.6161012053489685\n",
      "   Avg total loss:   1.766854703426361\n",
      "Training [15872/107244] [2.224781e-04s per sample]\n",
      "   Avg value loss:   1.1771881580352783\n",
      "   Avg policy loss:  0.5854395031929016\n",
      "   Avg total loss:   1.76262766122818\n",
      "Training [16000/107244] [2.190694e-04s per sample]\n",
      "   Avg value loss:   1.1423441171646118\n",
      "   Avg policy loss:  0.6291605830192566\n",
      "   Avg total loss:   1.7715047001838684\n",
      "Training [16128/107244] [2.227910e-04s per sample]\n",
      "   Avg value loss:   1.1823618412017822\n",
      "   Avg policy loss:  0.6323847770690918\n",
      "   Avg total loss:   1.814746618270874\n",
      "Training [16256/107244] [2.178438e-04s per sample]\n",
      "   Avg value loss:   1.1435835361480713\n",
      "   Avg policy loss:  0.5939092636108398\n",
      "   Avg total loss:   1.7374927997589111\n",
      "Training [16384/107244] [2.144519e-04s per sample]\n",
      "   Avg value loss:   1.1576241254806519\n",
      "   Avg policy loss:  0.6121572852134705\n",
      "   Avg total loss:   1.7697814106941223\n",
      "Training [16512/107244] [2.186019e-04s per sample]\n",
      "   Avg value loss:   1.1603749990463257\n",
      "   Avg policy loss:  0.6332089304924011\n",
      "   Avg total loss:   1.7935839295387268\n",
      "Training [16640/107244] [2.104230e-04s per sample]\n",
      "   Avg value loss:   1.13358473777771\n",
      "   Avg policy loss:  0.59527587890625\n",
      "   Avg total loss:   1.72886061668396\n",
      "Training [16768/107244] [2.188608e-04s per sample]\n",
      "   Avg value loss:   1.1208797693252563\n",
      "   Avg policy loss:  0.6087736487388611\n",
      "   Avg total loss:   1.7296534180641174\n",
      "Training [16896/107244] [2.082419e-04s per sample]\n",
      "   Avg value loss:   1.2657803297042847\n",
      "   Avg policy loss:  0.6434327363967896\n",
      "   Avg total loss:   1.9092130661010742\n",
      "Training [17024/107244] [2.168603e-04s per sample]\n",
      "   Avg value loss:   1.0907129049301147\n",
      "   Avg policy loss:  0.6462277173995972\n",
      "   Avg total loss:   1.736940622329712\n",
      "Training [17152/107244] [2.176799e-04s per sample]\n",
      "   Avg value loss:   1.1290419101715088\n",
      "   Avg policy loss:  0.6022443771362305\n",
      "   Avg total loss:   1.7312862873077393\n",
      "Training [17280/107244] [2.067741e-04s per sample]\n",
      "   Avg value loss:   1.1407244205474854\n",
      "   Avg policy loss:  0.6419489979743958\n",
      "   Avg total loss:   1.782673418521881\n",
      "Training [17408/107244] [2.114382e-04s per sample]\n",
      "   Avg value loss:   1.160611629486084\n",
      "   Avg policy loss:  0.6373457312583923\n",
      "   Avg total loss:   1.7979573607444763\n",
      "Training [17536/107244] [2.140161e-04s per sample]\n",
      "   Avg value loss:   1.1666340827941895\n",
      "   Avg policy loss:  0.6224795579910278\n",
      "   Avg total loss:   1.7891136407852173\n",
      "Training [17664/107244] [2.273116e-04s per sample]\n",
      "   Avg value loss:   1.110811710357666\n",
      "   Avg policy loss:  0.6049941778182983\n",
      "   Avg total loss:   1.7158058881759644\n",
      "Training [17792/107244] [2.242662e-04s per sample]\n",
      "   Avg value loss:   1.2023324966430664\n",
      "   Avg policy loss:  0.6403993964195251\n",
      "   Avg total loss:   1.8427318930625916\n",
      "Training [17920/107244] [2.037026e-04s per sample]\n",
      "   Avg value loss:   1.165837287902832\n",
      "   Avg policy loss:  0.6586722731590271\n",
      "   Avg total loss:   1.8245095610618591\n",
      "Training [18048/107244] [2.066717e-04s per sample]\n",
      "   Avg value loss:   1.203314185142517\n",
      "   Avg policy loss:  0.6164403557777405\n",
      "   Avg total loss:   1.8197545409202576\n",
      "Training [18176/107244] [2.082009e-04s per sample]\n",
      "   Avg value loss:   1.1191749572753906\n",
      "   Avg policy loss:  0.6130170822143555\n",
      "   Avg total loss:   1.732192039489746\n",
      "Training [18304/107244] [2.256874e-04s per sample]\n",
      "   Avg value loss:   1.1630983352661133\n",
      "   Avg policy loss:  0.6160327196121216\n",
      "   Avg total loss:   1.7791310548782349\n",
      "Training [18432/107244] [2.068672e-04s per sample]\n",
      "   Avg value loss:   1.1324259042739868\n",
      "   Avg policy loss:  0.6083331108093262\n",
      "   Avg total loss:   1.740759015083313\n",
      "Training [18560/107244] [2.072714e-04s per sample]\n",
      "   Avg value loss:   1.0581324100494385\n",
      "   Avg policy loss:  0.6247557401657104\n",
      "   Avg total loss:   1.682888150215149\n",
      "Training [18688/107244] [2.185628e-04s per sample]\n",
      "   Avg value loss:   1.1552479267120361\n",
      "   Avg policy loss:  0.6072123050689697\n",
      "   Avg total loss:   1.7624602317810059\n",
      "Training [18816/107244] [2.208520e-04s per sample]\n",
      "   Avg value loss:   1.106689214706421\n",
      "   Avg policy loss:  0.6059770584106445\n",
      "   Avg total loss:   1.7126662731170654\n",
      "Training [18944/107244] [2.154149e-04s per sample]\n",
      "   Avg value loss:   1.2142634391784668\n",
      "   Avg policy loss:  0.6136844158172607\n",
      "   Avg total loss:   1.8279478549957275\n",
      "Training [19072/107244] [2.195537e-04s per sample]\n",
      "   Avg value loss:   1.128150224685669\n",
      "   Avg policy loss:  0.6212518811225891\n",
      "   Avg total loss:   1.749402105808258\n",
      "Training [19200/107244] [2.139378e-04s per sample]\n",
      "   Avg value loss:   1.2605011463165283\n",
      "   Avg policy loss:  0.6118807792663574\n",
      "   Avg total loss:   1.8723819255828857\n",
      "Training [19328/107244] [2.109949e-04s per sample]\n",
      "   Avg value loss:   1.1798394918441772\n",
      "   Avg policy loss:  0.6382168531417847\n",
      "   Avg total loss:   1.818056344985962\n",
      "Training [19456/107244] [2.295859e-04s per sample]\n",
      "   Avg value loss:   1.1631178855895996\n",
      "   Avg policy loss:  0.6053655743598938\n",
      "   Avg total loss:   1.7684834599494934\n",
      "Training [19584/107244] [2.171807e-04s per sample]\n",
      "   Avg value loss:   1.2206319570541382\n",
      "   Avg policy loss:  0.5969868898391724\n",
      "   Avg total loss:   1.8176188468933105\n",
      "Training [19712/107244] [2.161879e-04s per sample]\n",
      "   Avg value loss:   1.1701364517211914\n",
      "   Avg policy loss:  0.6049486994743347\n",
      "   Avg total loss:   1.7750851511955261\n",
      "Training [19840/107244] [2.206769e-04s per sample]\n",
      "   Avg value loss:   1.1251040697097778\n",
      "   Avg policy loss:  0.6384333372116089\n",
      "   Avg total loss:   1.7635374069213867\n",
      "Training [19968/107244] [2.273917e-04s per sample]\n",
      "   Avg value loss:   1.1117546558380127\n",
      "   Avg policy loss:  0.6199401617050171\n",
      "   Avg total loss:   1.7316948175430298\n",
      "Training [20096/107244] [2.270844e-04s per sample]\n",
      "   Avg value loss:   1.1713354587554932\n",
      "   Avg policy loss:  0.6235855221748352\n",
      "   Avg total loss:   1.7949209809303284\n",
      "Training [20224/107244] [2.242569e-04s per sample]\n",
      "   Avg value loss:   1.2342636585235596\n",
      "   Avg policy loss:  0.620759129524231\n",
      "   Avg total loss:   1.8550227880477905\n",
      "Training [20352/107244] [2.272595e-04s per sample]\n",
      "   Avg value loss:   1.1832211017608643\n",
      "   Avg policy loss:  0.6139858365058899\n",
      "   Avg total loss:   1.7972069382667542\n",
      "Training [20480/107244] [2.204757e-04s per sample]\n",
      "   Avg value loss:   1.1767971515655518\n",
      "   Avg policy loss:  0.6118028163909912\n",
      "   Avg total loss:   1.788599967956543\n",
      "Training [20608/107244] [2.243370e-04s per sample]\n",
      "   Avg value loss:   1.136387586593628\n",
      "   Avg policy loss:  0.6198979616165161\n",
      "   Avg total loss:   1.756285548210144\n",
      "Training [20736/107244] [2.156310e-04s per sample]\n",
      "   Avg value loss:   1.193695068359375\n",
      "   Avg policy loss:  0.6577196717262268\n",
      "   Avg total loss:   1.8514147400856018\n",
      "Training [20864/107244] [2.195127e-04s per sample]\n",
      "   Avg value loss:   1.1313798427581787\n",
      "   Avg policy loss:  0.6138758063316345\n",
      "   Avg total loss:   1.7452556490898132\n",
      "Training [20992/107244] [2.101026e-04s per sample]\n",
      "   Avg value loss:   1.1459331512451172\n",
      "   Avg policy loss:  0.6309695839881897\n",
      "   Avg total loss:   1.7769027352333069\n",
      "Training [21120/107244] [2.504997e-04s per sample]\n",
      "   Avg value loss:   1.1968144178390503\n",
      "   Avg policy loss:  0.6156275272369385\n",
      "   Avg total loss:   1.8124419450759888\n",
      "Training [21248/107244] [2.090372e-04s per sample]\n",
      "   Avg value loss:   1.118492841720581\n",
      "   Avg policy loss:  0.6382164359092712\n",
      "   Avg total loss:   1.7567092776298523\n",
      "Training [21376/107244] [2.129618e-04s per sample]\n",
      "   Avg value loss:   1.0571715831756592\n",
      "   Avg policy loss:  0.6207120418548584\n",
      "   Avg total loss:   1.6778836250305176\n",
      "Training [21504/107244] [2.236255e-04s per sample]\n",
      "   Avg value loss:   1.1341078281402588\n",
      "   Avg policy loss:  0.6358902454376221\n",
      "   Avg total loss:   1.7699980735778809\n",
      "Training [21632/107244] [2.304632e-04s per sample]\n",
      "   Avg value loss:   1.124269962310791\n",
      "   Avg policy loss:  0.6239074468612671\n",
      "   Avg total loss:   1.748177409172058\n",
      "Training [21760/107244] [2.289768e-04s per sample]\n",
      "   Avg value loss:   1.139655351638794\n",
      "   Avg policy loss:  0.6297008395195007\n",
      "   Avg total loss:   1.7693561911582947\n",
      "Training [21888/107244] [2.102274e-04s per sample]\n",
      "   Avg value loss:   1.1511485576629639\n",
      "   Avg policy loss:  0.6238150000572205\n",
      "   Avg total loss:   1.7749635577201843\n",
      "Training [22016/107244] [2.129208e-04s per sample]\n",
      "   Avg value loss:   1.0466337203979492\n",
      "   Avg policy loss:  0.6179048418998718\n",
      "   Avg total loss:   1.664538562297821\n",
      "Training [22144/107244] [2.120528e-04s per sample]\n",
      "   Avg value loss:   1.2231346368789673\n",
      "   Avg policy loss:  0.673955500125885\n",
      "   Avg total loss:   1.8970901370048523\n",
      "Training [22272/107244] [2.217889e-04s per sample]\n",
      "   Avg value loss:   1.1185705661773682\n",
      "   Avg policy loss:  0.6139261722564697\n",
      "   Avg total loss:   1.732496738433838\n",
      "Training [22400/107244] [2.205856e-04s per sample]\n",
      "   Avg value loss:   1.2124685049057007\n",
      "   Avg policy loss:  0.6154380440711975\n",
      "   Avg total loss:   1.8279065489768982\n",
      "Training [22528/107244] [2.192724e-04s per sample]\n",
      "   Avg value loss:   1.063293695449829\n",
      "   Avg policy loss:  0.6083633303642273\n",
      "   Avg total loss:   1.6716570258140564\n",
      "Training [22656/107244] [2.206247e-04s per sample]\n",
      "   Avg value loss:   1.181095838546753\n",
      "   Avg policy loss:  0.598544716835022\n",
      "   Avg total loss:   1.779640555381775\n",
      "Training [22784/107244] [2.143439e-04s per sample]\n",
      "   Avg value loss:   1.1428637504577637\n",
      "   Avg policy loss:  0.6162801384925842\n",
      "   Avg total loss:   1.759143888950348\n",
      "Training [22912/107244] [2.049599e-04s per sample]\n",
      "   Avg value loss:   1.1533437967300415\n",
      "   Avg policy loss:  0.6422833800315857\n",
      "   Avg total loss:   1.7956271767616272\n",
      "Training [23040/107244] [2.082754e-04s per sample]\n",
      "   Avg value loss:   1.1381831169128418\n",
      "   Avg policy loss:  0.6058250069618225\n",
      "   Avg total loss:   1.7440081238746643\n",
      "Training [23168/107244] [2.162587e-04s per sample]\n",
      "   Avg value loss:   1.2083405256271362\n",
      "   Avg policy loss:  0.5994031429290771\n",
      "   Avg total loss:   1.8077436685562134\n",
      "Training [23296/107244] [2.168436e-04s per sample]\n",
      "   Avg value loss:   1.144986867904663\n",
      "   Avg policy loss:  0.6530006527900696\n",
      "   Avg total loss:   1.7979875206947327\n",
      "Training [23424/107244] [2.115984e-04s per sample]\n",
      "   Avg value loss:   1.2413222789764404\n",
      "   Avg policy loss:  0.6230801343917847\n",
      "   Avg total loss:   1.864402413368225\n",
      "Training [23552/107244] [2.274141e-04s per sample]\n",
      "   Avg value loss:   1.1531790494918823\n",
      "   Avg policy loss:  0.6406732201576233\n",
      "   Avg total loss:   1.7938522696495056\n",
      "Training [23680/107244] [2.135783e-04s per sample]\n",
      "   Avg value loss:   1.1982862949371338\n",
      "   Avg policy loss:  0.6228421330451965\n",
      "   Avg total loss:   1.8211284279823303\n",
      "Training [23808/107244] [2.181102e-04s per sample]\n",
      "   Avg value loss:   1.1946271657943726\n",
      "   Avg policy loss:  0.6259045004844666\n",
      "   Avg total loss:   1.8205316662788391\n",
      "Training [23936/107244] [2.325010e-04s per sample]\n",
      "   Avg value loss:   1.1945998668670654\n",
      "   Avg policy loss:  0.6161706447601318\n",
      "   Avg total loss:   1.8107705116271973\n",
      "Training [24064/107244] [2.183821e-04s per sample]\n",
      "   Avg value loss:   1.1498489379882812\n",
      "   Avg policy loss:  0.611622154712677\n",
      "   Avg total loss:   1.7614710927009583\n",
      "Training [24192/107244] [2.236161e-04s per sample]\n",
      "   Avg value loss:   1.180503010749817\n",
      "   Avg policy loss:  0.6043655872344971\n",
      "   Avg total loss:   1.784868597984314\n",
      "Training [24320/107244] [2.104472e-04s per sample]\n",
      "   Avg value loss:   1.1094235181808472\n",
      "   Avg policy loss:  0.5936135053634644\n",
      "   Avg total loss:   1.7030370235443115\n",
      "Training [24448/107244] [2.126023e-04s per sample]\n",
      "   Avg value loss:   1.1393588781356812\n",
      "   Avg policy loss:  0.6149110198020935\n",
      "   Avg total loss:   1.7542698979377747\n",
      "Training [24576/107244] [2.171472e-04s per sample]\n",
      "   Avg value loss:   1.1069574356079102\n",
      "   Avg policy loss:  0.6269688606262207\n",
      "   Avg total loss:   1.7339262962341309\n",
      "Training [24704/107244] [2.104528e-04s per sample]\n",
      "   Avg value loss:   1.2534732818603516\n",
      "   Avg policy loss:  0.6041411757469177\n",
      "   Avg total loss:   1.8576144576072693\n",
      "Training [24832/107244] [2.087411e-04s per sample]\n",
      "   Avg value loss:   1.0927929878234863\n",
      "   Avg policy loss:  0.6112798452377319\n",
      "   Avg total loss:   1.7040728330612183\n",
      "Training [24960/107244] [2.064127e-04s per sample]\n",
      "   Avg value loss:   1.2765188217163086\n",
      "   Avg policy loss:  0.6391932368278503\n",
      "   Avg total loss:   1.915712058544159\n",
      "Training [25088/107244] [2.118889e-04s per sample]\n",
      "   Avg value loss:   1.150390863418579\n",
      "   Avg policy loss:  0.6126660704612732\n",
      "   Avg total loss:   1.7630569338798523\n",
      "Training [25216/107244] [2.110079e-04s per sample]\n",
      "   Avg value loss:   1.1559211015701294\n",
      "   Avg policy loss:  0.6213635206222534\n",
      "   Avg total loss:   1.7772846221923828\n",
      "Training [25344/107244] [2.105087e-04s per sample]\n",
      "   Avg value loss:   1.187142014503479\n",
      "   Avg policy loss:  0.6129347085952759\n",
      "   Avg total loss:   1.8000767230987549\n",
      "Training [25472/107244] [2.197046e-04s per sample]\n",
      "   Avg value loss:   1.13767409324646\n",
      "   Avg policy loss:  0.6372007727622986\n",
      "   Avg total loss:   1.7748748660087585\n",
      "Training [25600/107244] [2.141166e-04s per sample]\n",
      "   Avg value loss:   1.171310305595398\n",
      "   Avg policy loss:  0.6194134950637817\n",
      "   Avg total loss:   1.7907238006591797\n",
      "Training [25728/107244] [2.216641e-04s per sample]\n",
      "   Avg value loss:   1.2159130573272705\n",
      "   Avg policy loss:  0.6387145519256592\n",
      "   Avg total loss:   1.8546276092529297\n",
      "Training [25856/107244] [2.099853e-04s per sample]\n",
      "   Avg value loss:   1.1213035583496094\n",
      "   Avg policy loss:  0.5973610281944275\n",
      "   Avg total loss:   1.7186645865440369\n",
      "Training [25984/107244] [2.051629e-04s per sample]\n",
      "   Avg value loss:   1.198099136352539\n",
      "   Avg policy loss:  0.6314963102340698\n",
      "   Avg total loss:   1.8295954465866089\n",
      "Training [26112/107244] [2.227128e-04s per sample]\n",
      "   Avg value loss:   1.1158925294876099\n",
      "   Avg policy loss:  0.6199328303337097\n",
      "   Avg total loss:   1.7358253598213196\n",
      "Training [26240/107244] [2.286881e-04s per sample]\n",
      "   Avg value loss:   1.182565689086914\n",
      "   Avg policy loss:  0.619888424873352\n",
      "   Avg total loss:   1.8024541139602661\n",
      "Training [26368/107244] [2.239924e-04s per sample]\n",
      "   Avg value loss:   1.1689469814300537\n",
      "   Avg policy loss:  0.6166128516197205\n",
      "   Avg total loss:   1.7855598330497742\n",
      "Training [26496/107244] [2.246182e-04s per sample]\n",
      "   Avg value loss:   1.2594367265701294\n",
      "   Avg policy loss:  0.6106205582618713\n",
      "   Avg total loss:   1.8700572848320007\n",
      "Training [26624/107244] [2.304222e-04s per sample]\n",
      "   Avg value loss:   1.1883268356323242\n",
      "   Avg policy loss:  0.6144907474517822\n",
      "   Avg total loss:   1.8028175830841064\n",
      "Training [26752/107244] [2.154838e-04s per sample]\n",
      "   Avg value loss:   1.1507441997528076\n",
      "   Avg policy loss:  0.63484126329422\n",
      "   Avg total loss:   1.7855854630470276\n",
      "Training [26880/107244] [2.198499e-04s per sample]\n",
      "   Avg value loss:   1.150762915611267\n",
      "   Avg policy loss:  0.605618417263031\n",
      "   Avg total loss:   1.756381332874298\n",
      "Training [27008/107244] [2.159849e-04s per sample]\n",
      "   Avg value loss:   1.1990573406219482\n",
      "   Avg policy loss:  0.6150493025779724\n",
      "   Avg total loss:   1.8141066431999207\n",
      "Training [27136/107244] [2.098605e-04s per sample]\n",
      "   Avg value loss:   1.1880720853805542\n",
      "   Avg policy loss:  0.6353871822357178\n",
      "   Avg total loss:   1.823459267616272\n",
      "Training [27264/107244] [2.194066e-04s per sample]\n",
      "   Avg value loss:   1.1750130653381348\n",
      "   Avg policy loss:  0.6332146525382996\n",
      "   Avg total loss:   1.8082277178764343\n",
      "Training [27392/107244] [2.179909e-04s per sample]\n",
      "   Avg value loss:   1.1523840427398682\n",
      "   Avg policy loss:  0.6132223010063171\n",
      "   Avg total loss:   1.7656063437461853\n",
      "Training [27520/107244] [2.327505e-04s per sample]\n",
      "   Avg value loss:   1.162199854850769\n",
      "   Avg policy loss:  0.6232075095176697\n",
      "   Avg total loss:   1.7854073643684387\n",
      "Training [27648/107244] [2.157558e-04s per sample]\n",
      "   Avg value loss:   1.1106374263763428\n",
      "   Avg policy loss:  0.6167596578598022\n",
      "   Avg total loss:   1.727397084236145\n",
      "Training [27776/107244] [2.123434e-04s per sample]\n",
      "   Avg value loss:   1.0941587686538696\n",
      "   Avg policy loss:  0.6125842928886414\n",
      "   Avg total loss:   1.706743061542511\n",
      "Training [27904/107244] [2.207011e-04s per sample]\n",
      "   Avg value loss:   1.1649153232574463\n",
      "   Avg policy loss:  0.6177969574928284\n",
      "   Avg total loss:   1.7827122807502747\n",
      "Training [28032/107244] [2.212748e-04s per sample]\n",
      "   Avg value loss:   1.1184563636779785\n",
      "   Avg policy loss:  0.6113006472587585\n",
      "   Avg total loss:   1.729757010936737\n",
      "Training [28160/107244] [2.314597e-04s per sample]\n",
      "   Avg value loss:   1.1348751783370972\n",
      "   Avg policy loss:  0.6147687435150146\n",
      "   Avg total loss:   1.7496439218521118\n",
      "Training [28288/107244] [2.121814e-04s per sample]\n",
      "   Avg value loss:   1.1482579708099365\n",
      "   Avg policy loss:  0.5912978053092957\n",
      "   Avg total loss:   1.7395557761192322\n",
      "Training [28416/107244] [2.186075e-04s per sample]\n",
      "   Avg value loss:   1.110628366470337\n",
      "   Avg policy loss:  0.6211516261100769\n",
      "   Avg total loss:   1.7317799925804138\n",
      "Training [28544/107244] [2.282877e-04s per sample]\n",
      "   Avg value loss:   1.1416163444519043\n",
      "   Avg policy loss:  0.6065328121185303\n",
      "   Avg total loss:   1.7481491565704346\n",
      "Training [28672/107244] [2.150796e-04s per sample]\n",
      "   Avg value loss:   1.2002990245819092\n",
      "   Avg policy loss:  0.6392399072647095\n",
      "   Avg total loss:   1.8395389318466187\n",
      "Training [28800/107244] [2.211165e-04s per sample]\n",
      "   Avg value loss:   1.1555111408233643\n",
      "   Avg policy loss:  0.6262712478637695\n",
      "   Avg total loss:   1.7817823886871338\n",
      "Training [28928/107244] [2.200156e-04s per sample]\n",
      "   Avg value loss:   1.18132483959198\n",
      "   Avg policy loss:  0.6115638017654419\n",
      "   Avg total loss:   1.7928886413574219\n",
      "Training [29056/107244] [2.112128e-04s per sample]\n",
      "   Avg value loss:   1.2136814594268799\n",
      "   Avg policy loss:  0.6009640097618103\n",
      "   Avg total loss:   1.8146454691886902\n",
      "Training [29184/107244] [2.196226e-04s per sample]\n",
      "   Avg value loss:   1.1382205486297607\n",
      "   Avg policy loss:  0.635404646396637\n",
      "   Avg total loss:   1.7736251950263977\n",
      "Training [29312/107244] [2.229046e-04s per sample]\n",
      "   Avg value loss:   1.184190034866333\n",
      "   Avg policy loss:  0.6167886257171631\n",
      "   Avg total loss:   1.800978660583496\n",
      "Training [29440/107244] [2.159141e-04s per sample]\n",
      "   Avg value loss:   1.198029637336731\n",
      "   Avg policy loss:  0.59182208776474\n",
      "   Avg total loss:   1.789851725101471\n",
      "Training [29568/107244] [2.108049e-04s per sample]\n",
      "   Avg value loss:   1.0766627788543701\n",
      "   Avg policy loss:  0.6111307144165039\n",
      "   Avg total loss:   1.687793493270874\n",
      "Training [29696/107244] [2.148990e-04s per sample]\n",
      "   Avg value loss:   1.160781741142273\n",
      "   Avg policy loss:  0.5910098552703857\n",
      "   Avg total loss:   1.7517915964126587\n",
      "Training [29824/107244] [2.319999e-04s per sample]\n",
      "   Avg value loss:   1.1155511140823364\n",
      "   Avg policy loss:  0.611135721206665\n",
      "   Avg total loss:   1.7266868352890015\n",
      "Training [29952/107244] [2.206080e-04s per sample]\n",
      "   Avg value loss:   1.1511704921722412\n",
      "   Avg policy loss:  0.6191940903663635\n",
      "   Avg total loss:   1.7703645825386047\n",
      "Training [30080/107244] [2.115946e-04s per sample]\n",
      "   Avg value loss:   1.0938397645950317\n",
      "   Avg policy loss:  0.5972504615783691\n",
      "   Avg total loss:   1.6910902261734009\n",
      "Training [30208/107244] [2.084207e-04s per sample]\n",
      "   Avg value loss:   1.1487970352172852\n",
      "   Avg policy loss:  0.628474235534668\n",
      "   Avg total loss:   1.7772712707519531\n",
      "Training [30336/107244] [2.154950e-04s per sample]\n",
      "   Avg value loss:   1.1650502681732178\n",
      "   Avg policy loss:  0.6129692196846008\n",
      "   Avg total loss:   1.7780194878578186\n",
      "Training [30464/107244] [2.240632e-04s per sample]\n",
      "   Avg value loss:   1.1298153400421143\n",
      "   Avg policy loss:  0.6021242141723633\n",
      "   Avg total loss:   1.7319395542144775\n",
      "Training [30592/107244] [2.150852e-04s per sample]\n",
      "   Avg value loss:   1.1254503726959229\n",
      "   Avg policy loss:  0.6121281385421753\n",
      "   Avg total loss:   1.7375785112380981\n",
      "Training [30720/107244] [2.112500e-04s per sample]\n",
      "   Avg value loss:   1.1442638635635376\n",
      "   Avg policy loss:  0.58318030834198\n",
      "   Avg total loss:   1.7274441719055176\n",
      "Training [30848/107244] [2.168976e-04s per sample]\n",
      "   Avg value loss:   1.0567269325256348\n",
      "   Avg policy loss:  0.5847011208534241\n",
      "   Avg total loss:   1.6414280533790588\n",
      "Training [30976/107244] [2.218224e-04s per sample]\n",
      "   Avg value loss:   1.1472028493881226\n",
      "   Avg policy loss:  0.6189733147621155\n",
      "   Avg total loss:   1.766176164150238\n",
      "Training [31104/107244] [2.546720e-04s per sample]\n",
      "   Avg value loss:   1.1109561920166016\n",
      "   Avg policy loss:  0.5859674215316772\n",
      "   Avg total loss:   1.6969236135482788\n",
      "Training [31232/107244] [2.072584e-04s per sample]\n",
      "   Avg value loss:   1.1229352951049805\n",
      "   Avg policy loss:  0.6526569724082947\n",
      "   Avg total loss:   1.7755922675132751\n",
      "Training [31360/107244] [2.089757e-04s per sample]\n",
      "   Avg value loss:   1.2224278450012207\n",
      "   Avg policy loss:  0.6130329370498657\n",
      "   Avg total loss:   1.8354607820510864\n",
      "Training [31488/107244] [2.059676e-04s per sample]\n",
      "   Avg value loss:   1.1355311870574951\n",
      "   Avg policy loss:  0.6355647444725037\n",
      "   Avg total loss:   1.7710959315299988\n",
      "Training [31616/107244] [2.153367e-04s per sample]\n",
      "   Avg value loss:   1.1422475576400757\n",
      "   Avg policy loss:  0.5914022922515869\n",
      "   Avg total loss:   1.7336498498916626\n",
      "Training [31744/107244] [2.081711e-04s per sample]\n",
      "   Avg value loss:   1.2313164472579956\n",
      "   Avg policy loss:  0.5787975192070007\n",
      "   Avg total loss:   1.8101139664649963\n",
      "Training [31872/107244] [2.056863e-04s per sample]\n",
      "   Avg value loss:   1.1308159828186035\n",
      "   Avg policy loss:  0.5737258791923523\n",
      "   Avg total loss:   1.7045418620109558\n",
      "Training [32000/107244] [2.143737e-04s per sample]\n",
      "   Avg value loss:   1.2008862495422363\n",
      "   Avg policy loss:  0.63761967420578\n",
      "   Avg total loss:   1.8385059237480164\n",
      "Training [32128/107244] [2.145078e-04s per sample]\n",
      "   Avg value loss:   1.140770435333252\n",
      "   Avg policy loss:  0.6222475171089172\n",
      "   Avg total loss:   1.7630179524421692\n",
      "Training [32256/107244] [2.111476e-04s per sample]\n",
      "   Avg value loss:   1.2528276443481445\n",
      "   Avg policy loss:  0.6213217377662659\n",
      "   Avg total loss:   1.8741493821144104\n",
      "Training [32384/107244] [2.082717e-04s per sample]\n",
      "   Avg value loss:   1.096273422241211\n",
      "   Avg policy loss:  0.6276810169219971\n",
      "   Avg total loss:   1.723954439163208\n",
      "Training [32512/107244] [2.136547e-04s per sample]\n",
      "   Avg value loss:   1.1813795566558838\n",
      "   Avg policy loss:  0.5992609262466431\n",
      "   Avg total loss:   1.7806404829025269\n",
      "Training [32640/107244] [2.249144e-04s per sample]\n",
      "   Avg value loss:   1.171433448791504\n",
      "   Avg policy loss:  0.6348376274108887\n",
      "   Avg total loss:   1.8062710762023926\n",
      "Training [32768/107244] [4.644915e-04s per sample]\n",
      "   Avg value loss:   1.1323225498199463\n",
      "   Avg policy loss:  0.6023799180984497\n",
      "   Avg total loss:   1.734702467918396\n",
      "Training [32896/107244] [2.131034e-04s per sample]\n",
      "   Avg value loss:   1.1296100616455078\n",
      "   Avg policy loss:  0.6090040802955627\n",
      "   Avg total loss:   1.7386141419410706\n",
      "Training [33024/107244] [2.115052e-04s per sample]\n",
      "   Avg value loss:   1.1061327457427979\n",
      "   Avg policy loss:  0.6174856424331665\n",
      "   Avg total loss:   1.7236183881759644\n",
      "Training [33152/107244] [2.175253e-04s per sample]\n",
      "   Avg value loss:   1.1883527040481567\n",
      "   Avg policy loss:  0.6468417644500732\n",
      "   Avg total loss:   1.83519446849823\n",
      "Training [33280/107244] [2.108980e-04s per sample]\n",
      "   Avg value loss:   1.0826935768127441\n",
      "   Avg policy loss:  0.6308742761611938\n",
      "   Avg total loss:   1.713567852973938\n",
      "Training [33408/107244] [2.265908e-04s per sample]\n",
      "   Avg value loss:   1.1560373306274414\n",
      "   Avg policy loss:  0.63426673412323\n",
      "   Avg total loss:   1.7903040647506714\n",
      "Training [33536/107244] [2.184603e-04s per sample]\n",
      "   Avg value loss:   1.2470424175262451\n",
      "   Avg policy loss:  0.5819641947746277\n",
      "   Avg total loss:   1.8290066123008728\n",
      "Training [33664/107244] [2.182014e-04s per sample]\n",
      "   Avg value loss:   1.1079790592193604\n",
      "   Avg policy loss:  0.5766240954399109\n",
      "   Avg total loss:   1.6846031546592712\n",
      "Training [33792/107244] [2.262034e-04s per sample]\n",
      "   Avg value loss:   1.1841943264007568\n",
      "   Avg policy loss:  0.5890005826950073\n",
      "   Avg total loss:   1.7731949090957642\n",
      "Training [33920/107244] [2.241880e-04s per sample]\n",
      "   Avg value loss:   1.2176563739776611\n",
      "   Avg policy loss:  0.6118488311767578\n",
      "   Avg total loss:   1.829505205154419\n",
      "Training [34048/107244] [2.170857e-04s per sample]\n",
      "   Avg value loss:   1.141953706741333\n",
      "   Avg policy loss:  0.6110950112342834\n",
      "   Avg total loss:   1.7530487179756165\n",
      "Training [34176/107244] [2.173670e-04s per sample]\n",
      "   Avg value loss:   1.1429603099822998\n",
      "   Avg policy loss:  0.626274824142456\n",
      "   Avg total loss:   1.7692351341247559\n",
      "Training [34304/107244] [2.246648e-04s per sample]\n",
      "   Avg value loss:   1.113800287246704\n",
      "   Avg policy loss:  0.5876123905181885\n",
      "   Avg total loss:   1.7014126777648926\n",
      "Training [34432/107244] [2.124198e-04s per sample]\n",
      "   Avg value loss:   1.2034521102905273\n",
      "   Avg policy loss:  0.6366763114929199\n",
      "   Avg total loss:   1.8401284217834473\n",
      "Training [34560/107244] [2.131332e-04s per sample]\n",
      "   Avg value loss:   1.2250949144363403\n",
      "   Avg policy loss:  0.642194390296936\n",
      "   Avg total loss:   1.8672893047332764\n",
      "Training [34688/107244] [2.176873e-04s per sample]\n",
      "   Avg value loss:   1.1260466575622559\n",
      "   Avg policy loss:  0.6188229322433472\n",
      "   Avg total loss:   1.744869589805603\n",
      "Training [34816/107244] [2.225004e-04s per sample]\n",
      "   Avg value loss:   1.1171789169311523\n",
      "   Avg policy loss:  0.5956637263298035\n",
      "   Avg total loss:   1.7128426432609558\n",
      "Training [34944/107244] [2.300330e-04s per sample]\n",
      "   Avg value loss:   1.1875935792922974\n",
      "   Avg policy loss:  0.618339478969574\n",
      "   Avg total loss:   1.8059330582618713\n",
      "Training [35072/107244] [2.199467e-04s per sample]\n",
      "   Avg value loss:   1.1778563261032104\n",
      "   Avg policy loss:  0.5986091494560242\n",
      "   Avg total loss:   1.7764654755592346\n",
      "Training [35200/107244] [2.159234e-04s per sample]\n",
      "   Avg value loss:   1.112431526184082\n",
      "   Avg policy loss:  0.6191525459289551\n",
      "   Avg total loss:   1.731584072113037\n",
      "Training [35328/107244] [2.081804e-04s per sample]\n",
      "   Avg value loss:   1.1229467391967773\n",
      "   Avg policy loss:  0.6305139660835266\n",
      "   Avg total loss:   1.753460705280304\n",
      "Training [35456/107244] [2.156664e-04s per sample]\n",
      "   Avg value loss:   1.1186482906341553\n",
      "   Avg policy loss:  0.632118284702301\n",
      "   Avg total loss:   1.7507665753364563\n",
      "Training [35584/107244] [2.109930e-04s per sample]\n",
      "   Avg value loss:   1.1488726139068604\n",
      "   Avg policy loss:  0.6169905066490173\n",
      "   Avg total loss:   1.7658631205558777\n",
      "Training [35712/107244] [2.111159e-04s per sample]\n",
      "   Avg value loss:   1.1214473247528076\n",
      "   Avg policy loss:  0.6298251152038574\n",
      "   Avg total loss:   1.751272439956665\n",
      "Training [35840/107244] [2.268907e-04s per sample]\n",
      "   Avg value loss:   1.1454797983169556\n",
      "   Avg policy loss:  0.5871444344520569\n",
      "   Avg total loss:   1.7326242327690125\n",
      "Training [35968/107244] [2.216324e-04s per sample]\n",
      "   Avg value loss:   1.233548641204834\n",
      "   Avg policy loss:  0.6384315490722656\n",
      "   Avg total loss:   1.8719801902770996\n",
      "Training [36096/107244] [2.157092e-04s per sample]\n",
      "   Avg value loss:   1.177262783050537\n",
      "   Avg policy loss:  0.6147363185882568\n",
      "   Avg total loss:   1.791999101638794\n",
      "Training [36224/107244] [2.224930e-04s per sample]\n",
      "   Avg value loss:   1.1309115886688232\n",
      "   Avg policy loss:  0.6316199898719788\n",
      "   Avg total loss:   1.762531578540802\n",
      "Training [36352/107244] [2.226420e-04s per sample]\n",
      "   Avg value loss:   1.1923927068710327\n",
      "   Avg policy loss:  0.6222449541091919\n",
      "   Avg total loss:   1.8146376609802246\n",
      "Training [36480/107244] [2.285242e-04s per sample]\n",
      "   Avg value loss:   1.1748673915863037\n",
      "   Avg policy loss:  0.6228181719779968\n",
      "   Avg total loss:   1.7976855635643005\n",
      "Training [36608/107244] [2.195947e-04s per sample]\n",
      "   Avg value loss:   1.1601027250289917\n",
      "   Avg policy loss:  0.6235849261283875\n",
      "   Avg total loss:   1.7836876511573792\n",
      "Training [36736/107244] [2.178978e-04s per sample]\n",
      "   Avg value loss:   1.175551176071167\n",
      "   Avg policy loss:  0.6014611721038818\n",
      "   Avg total loss:   1.7770123481750488\n",
      "Training [36864/107244] [2.175495e-04s per sample]\n",
      "   Avg value loss:   1.1162407398223877\n",
      "   Avg policy loss:  0.6118243336677551\n",
      "   Avg total loss:   1.7280650734901428\n",
      "Training [36992/107244] [2.168678e-04s per sample]\n",
      "   Avg value loss:   1.1391745805740356\n",
      "   Avg policy loss:  0.62249755859375\n",
      "   Avg total loss:   1.7616721391677856\n",
      "Training [37120/107244] [2.272204e-04s per sample]\n",
      "   Avg value loss:   1.1819562911987305\n",
      "   Avg policy loss:  0.6288717985153198\n",
      "   Avg total loss:   1.8108280897140503\n",
      "Training [37248/107244] [2.239291e-04s per sample]\n",
      "   Avg value loss:   1.20683753490448\n",
      "   Avg policy loss:  0.61907958984375\n",
      "   Avg total loss:   1.82591712474823\n",
      "Training [37376/107244] [2.204459e-04s per sample]\n",
      "   Avg value loss:   1.2775969505310059\n",
      "   Avg policy loss:  0.6084281802177429\n",
      "   Avg total loss:   1.8860251307487488\n",
      "Training [37504/107244] [2.095941e-04s per sample]\n",
      "   Avg value loss:   1.2119333744049072\n",
      "   Avg policy loss:  0.5982850193977356\n",
      "   Avg total loss:   1.8102183938026428\n",
      "Training [37632/107244] [2.108347e-04s per sample]\n",
      "   Avg value loss:   1.1870957612991333\n",
      "   Avg policy loss:  0.6217703819274902\n",
      "   Avg total loss:   1.8088661432266235\n",
      "Training [37760/107244] [2.312418e-04s per sample]\n",
      "   Avg value loss:   1.1618320941925049\n",
      "   Avg policy loss:  0.6101665496826172\n",
      "   Avg total loss:   1.771998643875122\n",
      "Training [37888/107244] [2.208594e-04s per sample]\n",
      "   Avg value loss:   1.0940685272216797\n",
      "   Avg policy loss:  0.6169739365577698\n",
      "   Avg total loss:   1.7110424637794495\n",
      "Training [38016/107244] [2.174228e-04s per sample]\n",
      "   Avg value loss:   1.1465461254119873\n",
      "   Avg policy loss:  0.594360888004303\n",
      "   Avg total loss:   1.7409070134162903\n",
      "Training [38144/107244] [2.179760e-04s per sample]\n",
      "   Avg value loss:   1.2055466175079346\n",
      "   Avg policy loss:  0.6416382193565369\n",
      "   Avg total loss:   1.8471848368644714\n",
      "Training [38272/107244] [2.335217e-04s per sample]\n",
      "   Avg value loss:   1.1329220533370972\n",
      "   Avg policy loss:  0.5938199758529663\n",
      "   Avg total loss:   1.7267420291900635\n",
      "Training [38400/107244] [2.135243e-04s per sample]\n",
      "   Avg value loss:   1.1246472597122192\n",
      "   Avg policy loss:  0.599212646484375\n",
      "   Avg total loss:   1.7238599061965942\n",
      "Training [38528/107244] [2.116486e-04s per sample]\n",
      "   Avg value loss:   1.0413882732391357\n",
      "   Avg policy loss:  0.614717960357666\n",
      "   Avg total loss:   1.6561062335968018\n",
      "Training [38656/107244] [2.179053e-04s per sample]\n",
      "   Avg value loss:   1.1504185199737549\n",
      "   Avg policy loss:  0.5945870876312256\n",
      "   Avg total loss:   1.7450056076049805\n",
      "Training [38784/107244] [2.222490e-04s per sample]\n",
      "   Avg value loss:   1.1597704887390137\n",
      "   Avg policy loss:  0.6320878863334656\n",
      "   Avg total loss:   1.7918583750724792\n",
      "Training [38912/107244] [2.274923e-04s per sample]\n",
      "   Avg value loss:   1.0792570114135742\n",
      "   Avg policy loss:  0.577739417552948\n",
      "   Avg total loss:   1.6569964289665222\n",
      "Training [39040/107244] [2.217330e-04s per sample]\n",
      "   Avg value loss:   1.1964658498764038\n",
      "   Avg policy loss:  0.6144477128982544\n",
      "   Avg total loss:   1.8109135627746582\n",
      "Training [39168/107244] [2.282988e-04s per sample]\n",
      "   Avg value loss:   1.2427387237548828\n",
      "   Avg policy loss:  0.6171728372573853\n",
      "   Avg total loss:   1.859911561012268\n",
      "Training [39296/107244] [2.188198e-04s per sample]\n",
      "   Avg value loss:   1.192245364189148\n",
      "   Avg policy loss:  0.5862675309181213\n",
      "   Avg total loss:   1.7785128951072693\n",
      "Training [39424/107244] [2.179835e-04s per sample]\n",
      "   Avg value loss:   1.1819188594818115\n",
      "   Avg policy loss:  0.6019298434257507\n",
      "   Avg total loss:   1.7838487029075623\n",
      "Training [39552/107244] [2.150685e-04s per sample]\n",
      "   Avg value loss:   1.1500910520553589\n",
      "   Avg policy loss:  0.610679030418396\n",
      "   Avg total loss:   1.7607700824737549\n",
      "Training [39680/107244] [2.104845e-04s per sample]\n",
      "   Avg value loss:   1.1755728721618652\n",
      "   Avg policy loss:  0.6008540391921997\n",
      "   Avg total loss:   1.776426911354065\n",
      "Training [39808/107244] [2.102572e-04s per sample]\n",
      "   Avg value loss:   1.198873519897461\n",
      "   Avg policy loss:  0.5966280102729797\n",
      "   Avg total loss:   1.7955015301704407\n",
      "Training [39936/107244] [2.187267e-04s per sample]\n",
      "   Avg value loss:   1.1613788604736328\n",
      "   Avg policy loss:  0.5762129426002502\n",
      "   Avg total loss:   1.737591803073883\n",
      "Training [40064/107244] [2.113897e-04s per sample]\n",
      "   Avg value loss:   1.1081304550170898\n",
      "   Avg policy loss:  0.5913373827934265\n",
      "   Avg total loss:   1.6994678378105164\n",
      "Training [40192/107244] [2.061091e-04s per sample]\n",
      "   Avg value loss:   1.1239005327224731\n",
      "   Avg policy loss:  0.6285865902900696\n",
      "   Avg total loss:   1.7524871230125427\n",
      "Training [40320/107244] [2.456307e-04s per sample]\n",
      "   Avg value loss:   1.1295301914215088\n",
      "   Avg policy loss:  0.5988754034042358\n",
      "   Avg total loss:   1.7284055948257446\n",
      "Training [40448/107244] [2.296716e-04s per sample]\n",
      "   Avg value loss:   1.0918233394622803\n",
      "   Avg policy loss:  0.5958822965621948\n",
      "   Avg total loss:   1.687705636024475\n",
      "Training [40576/107244] [2.203267e-04s per sample]\n",
      "   Avg value loss:   1.1751015186309814\n",
      "   Avg policy loss:  0.5957678556442261\n",
      "   Avg total loss:   1.7708693742752075\n",
      "Training [40704/107244] [2.212264e-04s per sample]\n",
      "   Avg value loss:   1.2192730903625488\n",
      "   Avg policy loss:  0.5988243818283081\n",
      "   Avg total loss:   1.818097472190857\n",
      "Training [40832/107244] [2.354514e-04s per sample]\n",
      "   Avg value loss:   1.1431540250778198\n",
      "   Avg policy loss:  0.6019310355186462\n",
      "   Avg total loss:   1.745085060596466\n",
      "Training [40960/107244] [2.158117e-04s per sample]\n",
      "   Avg value loss:   1.2356935739517212\n",
      "   Avg policy loss:  0.6490963697433472\n",
      "   Avg total loss:   1.8847899436950684\n",
      "Training [41088/107244] [2.171174e-04s per sample]\n",
      "   Avg value loss:   1.1858913898468018\n",
      "   Avg policy loss:  0.6437068581581116\n",
      "   Avg total loss:   1.8295982480049133\n",
      "Training [41216/107244] [2.167672e-04s per sample]\n",
      "   Avg value loss:   1.118931770324707\n",
      "   Avg policy loss:  0.630455732345581\n",
      "   Avg total loss:   1.749387502670288\n",
      "Training [41344/107244] [2.184305e-04s per sample]\n",
      "   Avg value loss:   1.1723995208740234\n",
      "   Avg policy loss:  0.5823767781257629\n",
      "   Avg total loss:   1.7547762989997864\n",
      "Training [41472/107244] [2.230611e-04s per sample]\n",
      "   Avg value loss:   1.0925248861312866\n",
      "   Avg policy loss:  0.6041473746299744\n",
      "   Avg total loss:   1.696672260761261\n",
      "Training [41600/107244] [2.209377e-04s per sample]\n",
      "   Avg value loss:   1.1364306211471558\n",
      "   Avg policy loss:  0.6239051222801208\n",
      "   Avg total loss:   1.7603357434272766\n",
      "Training [41728/107244] [2.196487e-04s per sample]\n",
      "   Avg value loss:   1.1354866027832031\n",
      "   Avg policy loss:  0.6186469793319702\n",
      "   Avg total loss:   1.7541335821151733\n",
      "Training [41856/107244] [2.132822e-04s per sample]\n",
      "   Avg value loss:   1.1759812831878662\n",
      "   Avg policy loss:  0.6020782589912415\n",
      "   Avg total loss:   1.7780595421791077\n",
      "Training [41984/107244] [2.156012e-04s per sample]\n",
      "   Avg value loss:   1.14801025390625\n",
      "   Avg policy loss:  0.6113830804824829\n",
      "   Avg total loss:   1.759393334388733\n",
      "Training [42112/107244] [2.305862e-04s per sample]\n",
      "   Avg value loss:   1.1585125923156738\n",
      "   Avg policy loss:  0.6286171674728394\n",
      "   Avg total loss:   1.7871297597885132\n",
      "Training [42240/107244] [2.219938e-04s per sample]\n",
      "   Avg value loss:   1.2376904487609863\n",
      "   Avg policy loss:  0.6305105686187744\n",
      "   Avg total loss:   1.8682010173797607\n",
      "Training [42368/107244] [2.281889e-04s per sample]\n",
      "   Avg value loss:   1.1068166494369507\n",
      "   Avg policy loss:  0.6274134516716003\n",
      "   Avg total loss:   1.734230101108551\n",
      "Training [42496/107244] [2.230555e-04s per sample]\n",
      "   Avg value loss:   1.1185414791107178\n",
      "   Avg policy loss:  0.6038553714752197\n",
      "   Avg total loss:   1.7223968505859375\n",
      "Training [42624/107244] [2.147723e-04s per sample]\n",
      "   Avg value loss:   1.1966694593429565\n",
      "   Avg policy loss:  0.6027041077613831\n",
      "   Avg total loss:   1.7993735671043396\n",
      "Training [42752/107244] [2.200548e-04s per sample]\n",
      "   Avg value loss:   1.0980621576309204\n",
      "   Avg policy loss:  0.6297982931137085\n",
      "   Avg total loss:   1.727860450744629\n",
      "Training [42880/107244] [2.282504e-04s per sample]\n",
      "   Avg value loss:   1.1619560718536377\n",
      "   Avg policy loss:  0.5970807671546936\n",
      "   Avg total loss:   1.7590368390083313\n",
      "Training [43008/107244] [2.133902e-04s per sample]\n",
      "   Avg value loss:   1.1452586650848389\n",
      "   Avg policy loss:  0.5887547135353088\n",
      "   Avg total loss:   1.7340133786201477\n",
      "Training [43136/107244] [2.088659e-04s per sample]\n",
      "   Avg value loss:   1.121618628501892\n",
      "   Avg policy loss:  0.6187664866447449\n",
      "   Avg total loss:   1.740385115146637\n",
      "Training [43264/107244] [2.197828e-04s per sample]\n",
      "   Avg value loss:   1.0881786346435547\n",
      "   Avg policy loss:  0.6258026957511902\n",
      "   Avg total loss:   1.7139813303947449\n",
      "Training [43392/107244] [2.221484e-04s per sample]\n",
      "   Avg value loss:   1.1531672477722168\n",
      "   Avg policy loss:  0.5854972004890442\n",
      "   Avg total loss:   1.738664448261261\n",
      "Training [43520/107244] [2.097804e-04s per sample]\n",
      "   Avg value loss:   1.1020493507385254\n",
      "   Avg policy loss:  0.6009259819984436\n",
      "   Avg total loss:   1.702975332736969\n",
      "Training [43648/107244] [2.077650e-04s per sample]\n",
      "   Avg value loss:   1.1134555339813232\n",
      "   Avg policy loss:  0.5837200880050659\n",
      "   Avg total loss:   1.6971756219863892\n",
      "Training [43776/107244] [2.070628e-04s per sample]\n",
      "   Avg value loss:   1.1502501964569092\n",
      "   Avg policy loss:  0.6013576984405518\n",
      "   Avg total loss:   1.751607894897461\n",
      "Training [43904/107244] [2.155695e-04s per sample]\n",
      "   Avg value loss:   1.1371885538101196\n",
      "   Avg policy loss:  0.6355387568473816\n",
      "   Avg total loss:   1.7727273106575012\n",
      "Training [44032/107244] [2.080556e-04s per sample]\n",
      "   Avg value loss:   1.1260489225387573\n",
      "   Avg policy loss:  0.625095009803772\n",
      "   Avg total loss:   1.7511439323425293\n",
      "Training [44160/107244] [2.054237e-04s per sample]\n",
      "   Avg value loss:   1.1149920225143433\n",
      "   Avg policy loss:  0.5917213559150696\n",
      "   Avg total loss:   1.7067133784294128\n",
      "Training [44288/107244] [2.054386e-04s per sample]\n",
      "   Avg value loss:   1.106964349746704\n",
      "   Avg policy loss:  0.6177218556404114\n",
      "   Avg total loss:   1.7246862053871155\n",
      "Training [44416/107244] [2.084598e-04s per sample]\n",
      "   Avg value loss:   1.142606496810913\n",
      "   Avg policy loss:  0.631744384765625\n",
      "   Avg total loss:   1.774350881576538\n",
      "Training [44544/107244] [2.183579e-04s per sample]\n",
      "   Avg value loss:   1.2411013841629028\n",
      "   Avg policy loss:  0.6037489175796509\n",
      "   Avg total loss:   1.8448503017425537\n",
      "Training [44672/107244] [2.109595e-04s per sample]\n",
      "   Avg value loss:   1.1574324369430542\n",
      "   Avg policy loss:  0.5880569219589233\n",
      "   Avg total loss:   1.7454893589019775\n",
      "Training [44800/107244] [2.085622e-04s per sample]\n",
      "   Avg value loss:   1.1485406160354614\n",
      "   Avg policy loss:  0.5866511464118958\n",
      "   Avg total loss:   1.7351917624473572\n",
      "Training [44928/107244] [2.079513e-04s per sample]\n",
      "   Avg value loss:   1.1168243885040283\n",
      "   Avg policy loss:  0.6258242130279541\n",
      "   Avg total loss:   1.7426486015319824\n",
      "Training [45056/107244] [2.145693e-04s per sample]\n",
      "   Avg value loss:   1.1596921682357788\n",
      "   Avg policy loss:  0.6082219481468201\n",
      "   Avg total loss:   1.7679141163825989\n",
      "Training [45184/107244] [2.314840e-04s per sample]\n",
      "   Avg value loss:   1.1116303205490112\n",
      "   Avg policy loss:  0.6113294363021851\n",
      "   Avg total loss:   1.7229597568511963\n",
      "Training [45312/107244] [2.126768e-04s per sample]\n",
      "   Avg value loss:   1.209839940071106\n",
      "   Avg policy loss:  0.6013774275779724\n",
      "   Avg total loss:   1.8112173676490784\n",
      "Training [45440/107244] [2.070572e-04s per sample]\n",
      "   Avg value loss:   1.0708904266357422\n",
      "   Avg policy loss:  0.6106410026550293\n",
      "   Avg total loss:   1.6815314292907715\n",
      "Training [45568/107244] [2.070162e-04s per sample]\n",
      "   Avg value loss:   1.1365238428115845\n",
      "   Avg policy loss:  0.5895227789878845\n",
      "   Avg total loss:   1.726046621799469\n",
      "Training [45696/107244] [2.295785e-04s per sample]\n",
      "   Avg value loss:   1.0998592376708984\n",
      "   Avg policy loss:  0.5987452268600464\n",
      "   Avg total loss:   1.6986044645309448\n",
      "Training [45824/107244] [2.167579e-04s per sample]\n",
      "   Avg value loss:   1.1546008586883545\n",
      "   Avg policy loss:  0.6006485819816589\n",
      "   Avg total loss:   1.7552494406700134\n",
      "Training [45952/107244] [2.237633e-04s per sample]\n",
      "   Avg value loss:   1.1538939476013184\n",
      "   Avg policy loss:  0.6259534955024719\n",
      "   Avg total loss:   1.7798474431037903\n",
      "Training [46080/107244] [2.007820e-04s per sample]\n",
      "   Avg value loss:   1.151752233505249\n",
      "   Avg policy loss:  0.6261509656906128\n",
      "   Avg total loss:   1.7779031991958618\n",
      "Training [46208/107244] [2.105944e-04s per sample]\n",
      "   Avg value loss:   1.0847445726394653\n",
      "   Avg policy loss:  0.6262178421020508\n",
      "   Avg total loss:   1.7109624147415161\n",
      "Training [46336/107244] [2.060086e-04s per sample]\n",
      "   Avg value loss:   1.1693813800811768\n",
      "   Avg policy loss:  0.6192743182182312\n",
      "   Avg total loss:   1.788655698299408\n",
      "Training [46464/107244] [2.123732e-04s per sample]\n",
      "   Avg value loss:   1.1494596004486084\n",
      "   Avg policy loss:  0.5916017293930054\n",
      "   Avg total loss:   1.7410613298416138\n",
      "Training [46592/107244] [2.088752e-04s per sample]\n",
      "   Avg value loss:   1.167698860168457\n",
      "   Avg policy loss:  0.6191615462303162\n",
      "   Avg total loss:   1.7868604063987732\n",
      "Training [46720/107244] [2.157893e-04s per sample]\n",
      "   Avg value loss:   1.09564208984375\n",
      "   Avg policy loss:  0.5841957926750183\n",
      "   Avg total loss:   1.6798378825187683\n",
      "Training [46848/107244] [2.225004e-04s per sample]\n",
      "   Avg value loss:   1.1907639503479004\n",
      "   Avg policy loss:  0.5909456014633179\n",
      "   Avg total loss:   1.7817095518112183\n",
      "Training [46976/107244] [2.070125e-04s per sample]\n",
      "   Avg value loss:   1.1138789653778076\n",
      "   Avg policy loss:  0.5921482443809509\n",
      "   Avg total loss:   1.7060272097587585\n",
      "Training [47104/107244] [2.047177e-04s per sample]\n",
      "   Avg value loss:   1.1698548793792725\n",
      "   Avg policy loss:  0.6135492324829102\n",
      "   Avg total loss:   1.7834041118621826\n",
      "Training [47232/107244] [2.218746e-04s per sample]\n",
      "   Avg value loss:   1.1760660409927368\n",
      "   Avg policy loss:  0.6157144904136658\n",
      "   Avg total loss:   1.7917805314064026\n",
      "Training [47360/107244] [2.203193e-04s per sample]\n",
      "   Avg value loss:   1.1396360397338867\n",
      "   Avg policy loss:  0.611762523651123\n",
      "   Avg total loss:   1.7513985633850098\n",
      "Training [47488/107244] [2.162736e-04s per sample]\n",
      "   Avg value loss:   1.1771340370178223\n",
      "   Avg policy loss:  0.6010280847549438\n",
      "   Avg total loss:   1.7781621217727661\n",
      "Training [47616/107244] [2.201330e-04s per sample]\n",
      "   Avg value loss:   1.2155171632766724\n",
      "   Avg policy loss:  0.6184899806976318\n",
      "   Avg total loss:   1.8340071439743042\n",
      "Training [47744/107244] [2.140533e-04s per sample]\n",
      "   Avg value loss:   1.1690545082092285\n",
      "   Avg policy loss:  0.6106452345848083\n",
      "   Avg total loss:   1.7796997427940369\n",
      "Training [47872/107244] [2.028048e-04s per sample]\n",
      "   Avg value loss:   1.2166365385055542\n",
      "   Avg policy loss:  0.601871907711029\n",
      "   Avg total loss:   1.8185084462165833\n",
      "Training [48000/107244] [2.286471e-04s per sample]\n",
      "   Avg value loss:   1.1733680963516235\n",
      "   Avg policy loss:  0.5875711441040039\n",
      "   Avg total loss:   1.7609392404556274\n",
      "Training [48128/107244] [2.351701e-04s per sample]\n",
      "   Avg value loss:   1.1945481300354004\n",
      "   Avg policy loss:  0.5955325961112976\n",
      "   Avg total loss:   1.790080726146698\n",
      "Training [48256/107244] [2.050325e-04s per sample]\n",
      "   Avg value loss:   1.2017818689346313\n",
      "   Avg policy loss:  0.6126253008842468\n",
      "   Avg total loss:   1.8144071698188782\n",
      "Training [48384/107244] [2.185851e-04s per sample]\n",
      "   Avg value loss:   1.1297695636749268\n",
      "   Avg policy loss:  0.5755342841148376\n",
      "   Avg total loss:   1.7053038477897644\n",
      "Training [48512/107244] [2.139471e-04s per sample]\n",
      "   Avg value loss:   1.1280279159545898\n",
      "   Avg policy loss:  0.6012076735496521\n",
      "   Avg total loss:   1.729235589504242\n",
      "Training [48640/107244] [2.270546e-04s per sample]\n",
      "   Avg value loss:   1.1427677869796753\n",
      "   Avg policy loss:  0.6219239234924316\n",
      "   Avg total loss:   1.764691710472107\n",
      "Training [48768/107244] [2.192818e-04s per sample]\n",
      "   Avg value loss:   1.154343605041504\n",
      "   Avg policy loss:  0.6259346008300781\n",
      "   Avg total loss:   1.780278205871582\n",
      "Training [48896/107244] [2.123192e-04s per sample]\n",
      "   Avg value loss:   1.2362278699874878\n",
      "   Avg policy loss:  0.635374128818512\n",
      "   Avg total loss:   1.8716019988059998\n",
      "Training [49024/107244] [2.238117e-04s per sample]\n",
      "   Avg value loss:   1.154022216796875\n",
      "   Avg policy loss:  0.6093389391899109\n",
      "   Avg total loss:   1.7633611559867859\n",
      "Training [49152/107244] [2.234988e-04s per sample]\n",
      "   Avg value loss:   1.1547356843948364\n",
      "   Avg policy loss:  0.5901151895523071\n",
      "   Avg total loss:   1.7448508739471436\n",
      "Training [49280/107244] [2.240092e-04s per sample]\n",
      "   Avg value loss:   1.1173325777053833\n",
      "   Avg policy loss:  0.5993296504020691\n",
      "   Avg total loss:   1.7166622281074524\n",
      "Training [49408/107244] [2.103727e-04s per sample]\n",
      "   Avg value loss:   1.1878620386123657\n",
      "   Avg policy loss:  0.6506782174110413\n",
      "   Avg total loss:   1.838540256023407\n",
      "Training [49536/107244] [2.115685e-04s per sample]\n",
      "   Avg value loss:   1.2252082824707031\n",
      "   Avg policy loss:  0.6227983236312866\n",
      "   Avg total loss:   1.8480066061019897\n",
      "Training [49664/107244] [2.049375e-04s per sample]\n",
      "   Avg value loss:   1.1141046285629272\n",
      "   Avg policy loss:  0.5816226005554199\n",
      "   Avg total loss:   1.6957272291183472\n",
      "Training [49792/107244] [2.157912e-04s per sample]\n",
      "   Avg value loss:   1.1333823204040527\n",
      "   Avg policy loss:  0.5872506499290466\n",
      "   Avg total loss:   1.7206329703330994\n",
      "Training [49920/107244] [2.081022e-04s per sample]\n",
      "   Avg value loss:   1.109476089477539\n",
      "   Avg policy loss:  0.5999947190284729\n",
      "   Avg total loss:   1.709470808506012\n",
      "Training [50048/107244] [2.104770e-04s per sample]\n",
      "   Avg value loss:   1.2221698760986328\n",
      "   Avg policy loss:  0.6023619174957275\n",
      "   Avg total loss:   1.8245317935943604\n",
      "Training [50176/107244] [2.061799e-04s per sample]\n",
      "   Avg value loss:   1.149911642074585\n",
      "   Avg policy loss:  0.5764577388763428\n",
      "   Avg total loss:   1.7263693809509277\n",
      "Training [50304/107244] [2.117213e-04s per sample]\n",
      "   Avg value loss:   1.225941777229309\n",
      "   Avg policy loss:  0.5935680270195007\n",
      "   Avg total loss:   1.8195098042488098\n",
      "Training [50432/107244] [2.083816e-04s per sample]\n",
      "   Avg value loss:   1.090489149093628\n",
      "   Avg policy loss:  0.5639729499816895\n",
      "   Avg total loss:   1.6544620990753174\n",
      "Training [50560/107244] [2.065301e-04s per sample]\n",
      "   Avg value loss:   1.1527602672576904\n",
      "   Avg policy loss:  0.633360743522644\n",
      "   Avg total loss:   1.7861210107803345\n",
      "Training [50688/107244] [2.047028e-04s per sample]\n",
      "   Avg value loss:   1.1479259729385376\n",
      "   Avg policy loss:  0.5886477828025818\n",
      "   Avg total loss:   1.7365737557411194\n",
      "Training [50816/107244] [2.108440e-04s per sample]\n",
      "   Avg value loss:   1.1537758111953735\n",
      "   Avg policy loss:  0.5898181200027466\n",
      "   Avg total loss:   1.7435939311981201\n",
      "Training [50944/107244] [2.102256e-04s per sample]\n",
      "   Avg value loss:   1.1054317951202393\n",
      "   Avg policy loss:  0.6046075224876404\n",
      "   Avg total loss:   1.7100393176078796\n",
      "Training [51072/107244] [2.042111e-04s per sample]\n",
      "   Avg value loss:   1.1700658798217773\n",
      "   Avg policy loss:  0.6168597936630249\n",
      "   Avg total loss:   1.7869256734848022\n",
      "Training [51200/107244] [1.979303e-04s per sample]\n",
      "   Avg value loss:   1.2148792743682861\n",
      "   Avg policy loss:  0.5979620218276978\n",
      "   Avg total loss:   1.8128412961959839\n",
      "Training [51328/107244] [2.011955e-04s per sample]\n",
      "   Avg value loss:   1.1504909992218018\n",
      "   Avg policy loss:  0.6141324043273926\n",
      "   Avg total loss:   1.7646234035491943\n",
      "Training [51456/107244] [2.050940e-04s per sample]\n",
      "   Avg value loss:   1.2479281425476074\n",
      "   Avg policy loss:  0.6100979447364807\n",
      "   Avg total loss:   1.8580260872840881\n",
      "Training [51584/107244] [1.966730e-04s per sample]\n",
      "   Avg value loss:   1.282031774520874\n",
      "   Avg policy loss:  0.5957083702087402\n",
      "   Avg total loss:   1.8777401447296143\n",
      "Training [51712/107244] [1.994614e-04s per sample]\n",
      "   Avg value loss:   1.1877707242965698\n",
      "   Avg policy loss:  0.5959507822990417\n",
      "   Avg total loss:   1.7837215065956116\n",
      "Training [51840/107244] [2.002418e-04s per sample]\n",
      "   Avg value loss:   1.026996374130249\n",
      "   Avg policy loss:  0.5943770408630371\n",
      "   Avg total loss:   1.6213734149932861\n",
      "Training [51968/107244] [2.313275e-04s per sample]\n",
      "   Avg value loss:   1.1378459930419922\n",
      "   Avg policy loss:  0.5826660394668579\n",
      "   Avg total loss:   1.72051203250885\n",
      "Training [52096/107244] [2.310611e-04s per sample]\n",
      "   Avg value loss:   1.1984533071517944\n",
      "   Avg policy loss:  0.6282092928886414\n",
      "   Avg total loss:   1.8266626000404358\n",
      "Training [52224/107244] [2.241936e-04s per sample]\n",
      "   Avg value loss:   1.1137408018112183\n",
      "   Avg policy loss:  0.6132394075393677\n",
      "   Avg total loss:   1.726980209350586\n",
      "Training [52352/107244] [2.149753e-04s per sample]\n",
      "   Avg value loss:   1.2023062705993652\n",
      "   Avg policy loss:  0.6500962376594543\n",
      "   Avg total loss:   1.8524025082588196\n",
      "Training [52480/107244] [2.202820e-04s per sample]\n",
      "   Avg value loss:   1.1181687116622925\n",
      "   Avg policy loss:  0.6089968085289001\n",
      "   Avg total loss:   1.7271655201911926\n",
      "Training [52608/107244] [2.197027e-04s per sample]\n",
      "   Avg value loss:   1.1247518062591553\n",
      "   Avg policy loss:  0.6037160158157349\n",
      "   Avg total loss:   1.7284678220748901\n",
      "Training [52736/107244] [2.214219e-04s per sample]\n",
      "   Avg value loss:   1.1555860042572021\n",
      "   Avg policy loss:  0.6243008375167847\n",
      "   Avg total loss:   1.7798868417739868\n",
      "Training [52864/107244] [2.148673e-04s per sample]\n",
      "   Avg value loss:   1.0880769491195679\n",
      "   Avg policy loss:  0.6101750731468201\n",
      "   Avg total loss:   1.698252022266388\n",
      "Training [52992/107244] [2.152883e-04s per sample]\n",
      "   Avg value loss:   1.1498944759368896\n",
      "   Avg policy loss:  0.6182780265808105\n",
      "   Avg total loss:   1.7681725025177002\n",
      "Training [53120/107244] [2.334770e-04s per sample]\n",
      "   Avg value loss:   1.1349974870681763\n",
      "   Avg policy loss:  0.604381799697876\n",
      "   Avg total loss:   1.7393792867660522\n",
      "Training [53248/107244] [2.197828e-04s per sample]\n",
      "   Avg value loss:   1.104169487953186\n",
      "   Avg policy loss:  0.567830502986908\n",
      "   Avg total loss:   1.671999990940094\n",
      "Training [53376/107244] [2.213418e-04s per sample]\n",
      "   Avg value loss:   1.2044979333877563\n",
      "   Avg policy loss:  0.6135112047195435\n",
      "   Avg total loss:   1.8180091381072998\n",
      "Training [53504/107244] [2.931729e-04s per sample]\n",
      "   Avg value loss:   1.1841323375701904\n",
      "   Avg policy loss:  0.6239847540855408\n",
      "   Avg total loss:   1.8081170916557312\n",
      "Training [53632/107244] [3.809873e-04s per sample]\n",
      "   Avg value loss:   1.1072633266448975\n",
      "   Avg policy loss:  0.5902023911476135\n",
      "   Avg total loss:   1.697465717792511\n",
      "Training [53760/107244] [2.215318e-04s per sample]\n",
      "   Avg value loss:   1.1439085006713867\n",
      "   Avg policy loss:  0.5788347721099854\n",
      "   Avg total loss:   1.722743272781372\n",
      "Training [53888/107244] [2.265312e-04s per sample]\n",
      "   Avg value loss:   1.1136174201965332\n",
      "   Avg policy loss:  0.603854238986969\n",
      "   Avg total loss:   1.7174716591835022\n",
      "Training [54016/107244] [2.256166e-04s per sample]\n",
      "   Avg value loss:   1.1140820980072021\n",
      "   Avg policy loss:  0.5919265151023865\n",
      "   Avg total loss:   1.7060086131095886\n",
      "Training [54144/107244] [2.179518e-04s per sample]\n",
      "   Avg value loss:   1.2472081184387207\n",
      "   Avg policy loss:  0.6621609926223755\n",
      "   Avg total loss:   1.9093691110610962\n",
      "Training [54272/107244] [2.285466e-04s per sample]\n",
      "   Avg value loss:   1.214345932006836\n",
      "   Avg policy loss:  0.5911957621574402\n",
      "   Avg total loss:   1.8055416941642761\n",
      "Training [54400/107244] [2.289061e-04s per sample]\n",
      "   Avg value loss:   1.2265506982803345\n",
      "   Avg policy loss:  0.6075068712234497\n",
      "   Avg total loss:   1.8340575695037842\n",
      "Training [54528/107244] [2.243910e-04s per sample]\n",
      "   Avg value loss:   1.1452076435089111\n",
      "   Avg policy loss:  0.56828773021698\n",
      "   Avg total loss:   1.7134953737258911\n",
      "Training [54656/107244] [2.112184e-04s per sample]\n",
      "   Avg value loss:   1.1877461671829224\n",
      "   Avg policy loss:  0.594028651714325\n",
      "   Avg total loss:   1.7817748188972473\n",
      "Training [54784/107244] [2.143737e-04s per sample]\n",
      "   Avg value loss:   1.2286932468414307\n",
      "   Avg policy loss:  0.6247721910476685\n",
      "   Avg total loss:   1.8534654378890991\n",
      "Training [54912/107244] [2.112258e-04s per sample]\n",
      "   Avg value loss:   1.1558432579040527\n",
      "   Avg policy loss:  0.6204743981361389\n",
      "   Avg total loss:   1.7763176560401917\n",
      "Training [55040/107244] [2.263989e-04s per sample]\n",
      "   Avg value loss:   1.1514027118682861\n",
      "   Avg policy loss:  0.6156492829322815\n",
      "   Avg total loss:   1.7670519948005676\n",
      "Training [55168/107244] [2.320707e-04s per sample]\n",
      "   Avg value loss:   1.1602296829223633\n",
      "   Avg policy loss:  0.6130910515785217\n",
      "   Avg total loss:   1.773320734500885\n",
      "Training [55296/107244] [2.648775e-04s per sample]\n",
      "   Avg value loss:   1.180426836013794\n",
      "   Avg policy loss:  0.6252720355987549\n",
      "   Avg total loss:   1.8056988716125488\n",
      "Training [55424/107244] [2.259444e-04s per sample]\n",
      "   Avg value loss:   1.2470039129257202\n",
      "   Avg policy loss:  0.6075304746627808\n",
      "   Avg total loss:   1.854534387588501\n",
      "Training [55552/107244] [2.157968e-04s per sample]\n",
      "   Avg value loss:   1.184723138809204\n",
      "   Avg policy loss:  0.6282954812049866\n",
      "   Avg total loss:   1.8130186200141907\n",
      "Training [55680/107244] [2.097506e-04s per sample]\n",
      "   Avg value loss:   1.2014777660369873\n",
      "   Avg policy loss:  0.6373831629753113\n",
      "   Avg total loss:   1.8388609290122986\n",
      "Training [55808/107244] [2.213996e-04s per sample]\n",
      "   Avg value loss:   1.1239476203918457\n",
      "   Avg policy loss:  0.632986843585968\n",
      "   Avg total loss:   1.7569344639778137\n",
      "Training [55936/107244] [2.069548e-04s per sample]\n",
      "   Avg value loss:   1.091275930404663\n",
      "   Avg policy loss:  0.6101133227348328\n",
      "   Avg total loss:   1.7013892531394958\n",
      "Training [56064/107244] [2.308432e-04s per sample]\n",
      "   Avg value loss:   1.1096270084381104\n",
      "   Avg policy loss:  0.5842509865760803\n",
      "   Avg total loss:   1.6938779950141907\n",
      "Training [56192/107244] [2.183523e-04s per sample]\n",
      "   Avg value loss:   1.2035332918167114\n",
      "   Avg policy loss:  0.5885826349258423\n",
      "   Avg total loss:   1.7921159267425537\n",
      "Training [56320/107244] [2.164766e-04s per sample]\n",
      "   Avg value loss:   1.1913959980010986\n",
      "   Avg policy loss:  0.6348273754119873\n",
      "   Avg total loss:   1.826223373413086\n",
      "Training [56448/107244] [2.167504e-04s per sample]\n",
      "   Avg value loss:   1.146884560585022\n",
      "   Avg policy loss:  0.5927909016609192\n",
      "   Avg total loss:   1.7396754622459412\n",
      "Training [56576/107244] [2.131555e-04s per sample]\n",
      "   Avg value loss:   1.1462905406951904\n",
      "   Avg policy loss:  0.582697331905365\n",
      "   Avg total loss:   1.7289878726005554\n",
      "Training [56704/107244] [2.134610e-04s per sample]\n",
      "   Avg value loss:   1.220712423324585\n",
      "   Avg policy loss:  0.6208276152610779\n",
      "   Avg total loss:   1.8415400385856628\n",
      "Training [56832/107244] [2.212878e-04s per sample]\n",
      "   Avg value loss:   1.202336311340332\n",
      "   Avg policy loss:  0.618355929851532\n",
      "   Avg total loss:   1.820692241191864\n",
      "Training [56960/107244] [2.159923e-04s per sample]\n",
      "   Avg value loss:   1.05189847946167\n",
      "   Avg policy loss:  0.5952222347259521\n",
      "   Avg total loss:   1.647120714187622\n",
      "Training [57088/107244] [2.207980e-04s per sample]\n",
      "   Avg value loss:   1.109144687652588\n",
      "   Avg policy loss:  0.5845038890838623\n",
      "   Avg total loss:   1.6936485767364502\n",
      "Training [57216/107244] [2.161562e-04s per sample]\n",
      "   Avg value loss:   1.1336475610733032\n",
      "   Avg policy loss:  0.5809622406959534\n",
      "   Avg total loss:   1.7146098017692566\n",
      "Training [57344/107244] [2.097823e-04s per sample]\n",
      "   Avg value loss:   1.1472171545028687\n",
      "   Avg policy loss:  0.5863828659057617\n",
      "   Avg total loss:   1.7336000204086304\n",
      "Training [57472/107244] [2.075788e-04s per sample]\n",
      "   Avg value loss:   1.0654915571212769\n",
      "   Avg policy loss:  0.6014947295188904\n",
      "   Avg total loss:   1.6669862866401672\n",
      "Training [57600/107244] [2.167020e-04s per sample]\n",
      "   Avg value loss:   1.1116825342178345\n",
      "   Avg policy loss:  0.6079837083816528\n",
      "   Avg total loss:   1.7196662425994873\n",
      "Training [57728/107244] [2.176166e-04s per sample]\n",
      "   Avg value loss:   1.1212977170944214\n",
      "   Avg policy loss:  0.6090176105499268\n",
      "   Avg total loss:   1.7303153276443481\n",
      "Training [57856/107244] [2.288483e-04s per sample]\n",
      "   Avg value loss:   1.1634953022003174\n",
      "   Avg policy loss:  0.6035937070846558\n",
      "   Avg total loss:   1.7670890092849731\n",
      "Training [57984/107244] [2.231430e-04s per sample]\n",
      "   Avg value loss:   1.2101284265518188\n",
      "   Avg policy loss:  0.6086978912353516\n",
      "   Avg total loss:   1.8188263177871704\n",
      "Training [58112/107244] [2.089925e-04s per sample]\n",
      "   Avg value loss:   1.231337070465088\n",
      "   Avg policy loss:  0.601318895816803\n",
      "   Avg total loss:   1.8326559662818909\n",
      "Training [58240/107244] [2.172515e-04s per sample]\n",
      "   Avg value loss:   1.1498301029205322\n",
      "   Avg policy loss:  0.6283999085426331\n",
      "   Avg total loss:   1.7782300114631653\n",
      "Training [58368/107244] [2.189782e-04s per sample]\n",
      "   Avg value loss:   1.1571791172027588\n",
      "   Avg policy loss:  0.6017115712165833\n",
      "   Avg total loss:   1.758890688419342\n",
      "Training [58496/107244] [2.041012e-04s per sample]\n",
      "   Avg value loss:   1.1290079355239868\n",
      "   Avg policy loss:  0.6072210669517517\n",
      "   Avg total loss:   1.7362290024757385\n",
      "Training [58624/107244] [2.215914e-04s per sample]\n",
      "   Avg value loss:   1.179648756980896\n",
      "   Avg policy loss:  0.5887545943260193\n",
      "   Avg total loss:   1.7684033513069153\n",
      "Training [58752/107244] [2.228748e-04s per sample]\n",
      "   Avg value loss:   1.1339181661605835\n",
      "   Avg policy loss:  0.6180932521820068\n",
      "   Avg total loss:   1.7520114183425903\n",
      "Training [58880/107244] [2.315864e-04s per sample]\n",
      "   Avg value loss:   1.122815489768982\n",
      "   Avg policy loss:  0.5943507552146912\n",
      "   Avg total loss:   1.717166244983673\n",
      "Training [59008/107244] [2.137031e-04s per sample]\n",
      "   Avg value loss:   1.0712686777114868\n",
      "   Avg policy loss:  0.5909977555274963\n",
      "   Avg total loss:   1.6622664332389832\n",
      "Training [59136/107244] [2.261084e-04s per sample]\n",
      "   Avg value loss:   1.2038074731826782\n",
      "   Avg policy loss:  0.6112304329872131\n",
      "   Avg total loss:   1.8150379061698914\n",
      "Training [59264/107244] [2.204217e-04s per sample]\n",
      "   Avg value loss:   1.1408531665802002\n",
      "   Avg policy loss:  0.574798583984375\n",
      "   Avg total loss:   1.7156517505645752\n",
      "Training [59392/107244] [2.247095e-04s per sample]\n",
      "   Avg value loss:   1.1569480895996094\n",
      "   Avg policy loss:  0.6071490049362183\n",
      "   Avg total loss:   1.7640970945358276\n",
      "Training [59520/107244] [2.206303e-04s per sample]\n",
      "   Avg value loss:   1.1401309967041016\n",
      "   Avg policy loss:  0.6180496215820312\n",
      "   Avg total loss:   1.7581806182861328\n",
      "Training [59648/107244] [2.163667e-04s per sample]\n",
      "   Avg value loss:   1.1974704265594482\n",
      "   Avg policy loss:  0.5963730812072754\n",
      "   Avg total loss:   1.7938435077667236\n",
      "Training [59776/107244] [2.144910e-04s per sample]\n",
      "   Avg value loss:   1.1741585731506348\n",
      "   Avg policy loss:  0.618898868560791\n",
      "   Avg total loss:   1.7930574417114258\n",
      "Training [59904/107244] [2.103280e-04s per sample]\n",
      "   Avg value loss:   1.1916052103042603\n",
      "   Avg policy loss:  0.6074135303497314\n",
      "   Avg total loss:   1.7990187406539917\n",
      "Training [60032/107244] [2.306700e-04s per sample]\n",
      "   Avg value loss:   1.1445024013519287\n",
      "   Avg policy loss:  0.6220681667327881\n",
      "   Avg total loss:   1.7665705680847168\n",
      "Training [60160/107244] [2.106391e-04s per sample]\n",
      "   Avg value loss:   1.1283378601074219\n",
      "   Avg policy loss:  0.6117074489593506\n",
      "   Avg total loss:   1.7400453090667725\n",
      "Training [60288/107244] [2.263822e-04s per sample]\n",
      "   Avg value loss:   1.1720037460327148\n",
      "   Avg policy loss:  0.5948576331138611\n",
      "   Avg total loss:   1.766861379146576\n",
      "Training [60416/107244] [2.048202e-04s per sample]\n",
      "   Avg value loss:   1.2199513912200928\n",
      "   Avg policy loss:  0.6076345443725586\n",
      "   Avg total loss:   1.8275859355926514\n",
      "Training [60544/107244] [2.255086e-04s per sample]\n",
      "   Avg value loss:   1.1462855339050293\n",
      "   Avg policy loss:  0.6142274737358093\n",
      "   Avg total loss:   1.7605130076408386\n",
      "Training [60672/107244] [2.095941e-04s per sample]\n",
      "   Avg value loss:   1.1086000204086304\n",
      "   Avg policy loss:  0.6133502721786499\n",
      "   Avg total loss:   1.7219502925872803\n",
      "Training [60800/107244] [2.100691e-04s per sample]\n",
      "   Avg value loss:   1.151172399520874\n",
      "   Avg policy loss:  0.5911567807197571\n",
      "   Avg total loss:   1.742329180240631\n",
      "Training [60928/107244] [2.150629e-04s per sample]\n",
      "   Avg value loss:   1.226017713546753\n",
      "   Avg policy loss:  0.5861538052558899\n",
      "   Avg total loss:   1.8121715188026428\n",
      "Training [61056/107244] [2.299845e-04s per sample]\n",
      "   Avg value loss:   1.0990601778030396\n",
      "   Avg policy loss:  0.5810770988464355\n",
      "   Avg total loss:   1.680137276649475\n",
      "Training [61184/107244] [2.197586e-04s per sample]\n",
      "   Avg value loss:   1.202953815460205\n",
      "   Avg policy loss:  0.6295703053474426\n",
      "   Avg total loss:   1.8325241208076477\n",
      "Training [61312/107244] [2.126954e-04s per sample]\n",
      "   Avg value loss:   1.121193766593933\n",
      "   Avg policy loss:  0.5955833792686462\n",
      "   Avg total loss:   1.7167771458625793\n",
      "Training [61440/107244] [2.161246e-04s per sample]\n",
      "   Avg value loss:   1.1094077825546265\n",
      "   Avg policy loss:  0.6095597147941589\n",
      "   Avg total loss:   1.7189674973487854\n",
      "Training [61568/107244] [2.184827e-04s per sample]\n",
      "   Avg value loss:   1.1831281185150146\n",
      "   Avg policy loss:  0.6239498853683472\n",
      "   Avg total loss:   1.8070780038833618\n",
      "Training [61696/107244] [2.132505e-04s per sample]\n",
      "   Avg value loss:   1.1536169052124023\n",
      "   Avg policy loss:  0.6332582831382751\n",
      "   Avg total loss:   1.7868751883506775\n",
      "Training [61824/107244] [2.013426e-04s per sample]\n",
      "   Avg value loss:   1.1958677768707275\n",
      "   Avg policy loss:  0.6208348870277405\n",
      "   Avg total loss:   1.816702663898468\n",
      "Training [61952/107244] [2.190415e-04s per sample]\n",
      "   Avg value loss:   1.1537092924118042\n",
      "   Avg policy loss:  0.5888231992721558\n",
      "   Avg total loss:   1.74253249168396\n",
      "Training [62080/107244] [2.112668e-04s per sample]\n",
      "   Avg value loss:   1.1168687343597412\n",
      "   Avg policy loss:  0.5896155834197998\n",
      "   Avg total loss:   1.706484317779541\n",
      "Training [62208/107244] [2.199300e-04s per sample]\n",
      "   Avg value loss:   1.086472988128662\n",
      "   Avg policy loss:  0.6061397194862366\n",
      "   Avg total loss:   1.6926127076148987\n",
      "Training [62336/107244] [2.220217e-04s per sample]\n",
      "   Avg value loss:   1.1133614778518677\n",
      "   Avg policy loss:  0.6015927791595459\n",
      "   Avg total loss:   1.7149542570114136\n",
      "Training [62464/107244] [2.055559e-04s per sample]\n",
      "   Avg value loss:   1.144904375076294\n",
      "   Avg policy loss:  0.5861374139785767\n",
      "   Avg total loss:   1.7310417890548706\n",
      "Training [62592/107244] [2.103187e-04s per sample]\n",
      "   Avg value loss:   1.0554832220077515\n",
      "   Avg policy loss:  0.5956018567085266\n",
      "   Avg total loss:   1.651085078716278\n",
      "Training [62720/107244] [2.063271e-04s per sample]\n",
      "   Avg value loss:   1.171303629875183\n",
      "   Avg policy loss:  0.5746508836746216\n",
      "   Avg total loss:   1.7459545135498047\n",
      "Training [62848/107244] [2.211798e-04s per sample]\n",
      "   Avg value loss:   1.1570429801940918\n",
      "   Avg policy loss:  0.6080352067947388\n",
      "   Avg total loss:   1.7650781869888306\n",
      "Training [62976/107244] [2.206024e-04s per sample]\n",
      "   Avg value loss:   1.1252161264419556\n",
      "   Avg policy loss:  0.5997599959373474\n",
      "   Avg total loss:   1.724976122379303\n",
      "Training [63104/107244] [2.246797e-04s per sample]\n",
      "   Avg value loss:   1.1294004917144775\n",
      "   Avg policy loss:  0.6081840395927429\n",
      "   Avg total loss:   1.7375845313072205\n",
      "Training [63232/107244] [2.160463e-04s per sample]\n",
      "   Avg value loss:   1.1537535190582275\n",
      "   Avg policy loss:  0.6007038950920105\n",
      "   Avg total loss:   1.754457414150238\n",
      "Training [63360/107244] [2.172496e-04s per sample]\n",
      "   Avg value loss:   1.1578586101531982\n",
      "   Avg policy loss:  0.5820515155792236\n",
      "   Avg total loss:   1.7399101257324219\n",
      "Training [63488/107244] [2.318360e-04s per sample]\n",
      "   Avg value loss:   1.1241960525512695\n",
      "   Avg policy loss:  0.6115265488624573\n",
      "   Avg total loss:   1.7357226014137268\n",
      "Training [63616/107244] [2.157707e-04s per sample]\n",
      "   Avg value loss:   1.0517394542694092\n",
      "   Avg policy loss:  0.5909206867218018\n",
      "   Avg total loss:   1.642660140991211\n",
      "Training [63744/107244] [2.279673e-04s per sample]\n",
      "   Avg value loss:   1.1709465980529785\n",
      "   Avg policy loss:  0.5900071859359741\n",
      "   Avg total loss:   1.7609537839889526\n",
      "Training [63872/107244] [2.286881e-04s per sample]\n",
      "   Avg value loss:   1.1512401103973389\n",
      "   Avg policy loss:  0.5901572704315186\n",
      "   Avg total loss:   1.7413973808288574\n",
      "Training [64000/107244] [2.352335e-04s per sample]\n",
      "   Avg value loss:   1.0823801755905151\n",
      "   Avg policy loss:  0.6043195128440857\n",
      "   Avg total loss:   1.6866996884346008\n",
      "Training [64128/107244] [2.218820e-04s per sample]\n",
      "   Avg value loss:   1.1072173118591309\n",
      "   Avg policy loss:  0.5781862735748291\n",
      "   Avg total loss:   1.68540358543396\n",
      "Training [64256/107244] [2.271589e-04s per sample]\n",
      "   Avg value loss:   1.1937744617462158\n",
      "   Avg policy loss:  0.6166894435882568\n",
      "   Avg total loss:   1.8104639053344727\n",
      "Training [64384/107244] [2.123676e-04s per sample]\n",
      "   Avg value loss:   1.1593255996704102\n",
      "   Avg policy loss:  0.649434506893158\n",
      "   Avg total loss:   1.8087601065635681\n",
      "Training [64512/107244] [2.210867e-04s per sample]\n",
      "   Avg value loss:   1.171037197113037\n",
      "   Avg policy loss:  0.5633281469345093\n",
      "   Avg total loss:   1.7343653440475464\n",
      "Training [64640/107244] [2.112351e-04s per sample]\n",
      "   Avg value loss:   1.115080714225769\n",
      "   Avg policy loss:  0.5904222130775452\n",
      "   Avg total loss:   1.7055029273033142\n",
      "Training [64768/107244] [2.184007e-04s per sample]\n",
      "   Avg value loss:   1.1267406940460205\n",
      "   Avg policy loss:  0.5686737895011902\n",
      "   Avg total loss:   1.6954144835472107\n",
      "Training [64896/107244] [2.191179e-04s per sample]\n",
      "   Avg value loss:   1.1569535732269287\n",
      "   Avg policy loss:  0.6182312369346619\n",
      "   Avg total loss:   1.7751848101615906\n",
      "Training [65024/107244] [2.120696e-04s per sample]\n",
      "   Avg value loss:   1.0953588485717773\n",
      "   Avg policy loss:  0.6118759512901306\n",
      "   Avg total loss:   1.707234799861908\n",
      "Training [65152/107244] [2.287123e-04s per sample]\n",
      "   Avg value loss:   1.0983688831329346\n",
      "   Avg policy loss:  0.5939552187919617\n",
      "   Avg total loss:   1.6923241019248962\n",
      "Training [65280/107244] [2.181232e-04s per sample]\n",
      "   Avg value loss:   1.1208194494247437\n",
      "   Avg policy loss:  0.5847357511520386\n",
      "   Avg total loss:   1.7055552005767822\n",
      "Training [65408/107244] [2.174824e-04s per sample]\n",
      "   Avg value loss:   1.124600887298584\n",
      "   Avg policy loss:  0.6028186082839966\n",
      "   Avg total loss:   1.7274194955825806\n",
      "Training [65536/107244] [2.175849e-04s per sample]\n",
      "   Avg value loss:   1.1904376745224\n",
      "   Avg policy loss:  0.585578203201294\n",
      "   Avg total loss:   1.7760158777236938\n",
      "Training [65664/107244] [2.253596e-04s per sample]\n",
      "   Avg value loss:   1.1852505207061768\n",
      "   Avg policy loss:  0.6168698668479919\n",
      "   Avg total loss:   1.8021203875541687\n",
      "Training [65792/107244] [2.070777e-04s per sample]\n",
      "   Avg value loss:   1.154413104057312\n",
      "   Avg policy loss:  0.6299532055854797\n",
      "   Avg total loss:   1.7843663096427917\n",
      "Training [65920/107244] [2.171230e-04s per sample]\n",
      "   Avg value loss:   1.1685740947723389\n",
      "   Avg policy loss:  0.6244210004806519\n",
      "   Avg total loss:   1.7929950952529907\n",
      "Training [66048/107244] [2.318975e-04s per sample]\n",
      "   Avg value loss:   1.1702462434768677\n",
      "   Avg policy loss:  0.6094457507133484\n",
      "   Avg total loss:   1.779691994190216\n",
      "Training [66176/107244] [2.229847e-04s per sample]\n",
      "   Avg value loss:   1.150945782661438\n",
      "   Avg policy loss:  0.5757005214691162\n",
      "   Avg total loss:   1.7266463041305542\n",
      "Training [66304/107244] [2.175551e-04s per sample]\n",
      "   Avg value loss:   1.1885402202606201\n",
      "   Avg policy loss:  0.5616406798362732\n",
      "   Avg total loss:   1.7501809000968933\n",
      "Training [66432/107244] [2.135932e-04s per sample]\n",
      "   Avg value loss:   1.1405620574951172\n",
      "   Avg policy loss:  0.6216963529586792\n",
      "   Avg total loss:   1.7622584104537964\n",
      "Training [66560/107244] [2.124757e-04s per sample]\n",
      "   Avg value loss:   1.0830433368682861\n",
      "   Avg policy loss:  0.5612992644309998\n",
      "   Avg total loss:   1.6443426012992859\n",
      "Training [66688/107244] [2.215151e-04s per sample]\n",
      "   Avg value loss:   1.1500639915466309\n",
      "   Avg policy loss:  0.61212158203125\n",
      "   Avg total loss:   1.7621855735778809\n",
      "Training [66816/107244] [2.208352e-04s per sample]\n",
      "   Avg value loss:   1.0047338008880615\n",
      "   Avg policy loss:  0.5859012007713318\n",
      "   Avg total loss:   1.5906350016593933\n",
      "Training [66944/107244] [2.122819e-04s per sample]\n",
      "   Avg value loss:   1.1264171600341797\n",
      "   Avg policy loss:  0.5926693081855774\n",
      "   Avg total loss:   1.719086468219757\n",
      "Training [67072/107244] [2.104752e-04s per sample]\n",
      "   Avg value loss:   1.2015131711959839\n",
      "   Avg policy loss:  0.5906441807746887\n",
      "   Avg total loss:   1.7921573519706726\n",
      "Training [67200/107244] [2.100933e-04s per sample]\n",
      "   Avg value loss:   1.0913094282150269\n",
      "   Avg policy loss:  0.5781493782997131\n",
      "   Avg total loss:   1.66945880651474\n",
      "Training [67328/107244] [2.468135e-04s per sample]\n",
      "   Avg value loss:   1.1223094463348389\n",
      "   Avg policy loss:  0.5927249193191528\n",
      "   Avg total loss:   1.7150343656539917\n",
      "Training [67456/107244] [2.247579e-04s per sample]\n",
      "   Avg value loss:   1.224327564239502\n",
      "   Avg policy loss:  0.6064802408218384\n",
      "   Avg total loss:   1.8308078050613403\n",
      "Training [67584/107244] [2.124459e-04s per sample]\n",
      "   Avg value loss:   1.1189204454421997\n",
      "   Avg policy loss:  0.5887362360954285\n",
      "   Avg total loss:   1.7076566815376282\n",
      "Training [67712/107244] [2.077818e-04s per sample]\n",
      "   Avg value loss:   1.116569995880127\n",
      "   Avg policy loss:  0.5726616382598877\n",
      "   Avg total loss:   1.6892316341400146\n",
      "Training [67840/107244] [2.196729e-04s per sample]\n",
      "   Avg value loss:   1.1365281343460083\n",
      "   Avg policy loss:  0.5892566442489624\n",
      "   Avg total loss:   1.7257847785949707\n",
      "Training [67968/107244] [2.229922e-04s per sample]\n",
      "   Avg value loss:   1.137817144393921\n",
      "   Avg policy loss:  0.5743656158447266\n",
      "   Avg total loss:   1.7121827602386475\n",
      "Training [68096/107244] [2.191793e-04s per sample]\n",
      "   Avg value loss:   1.2098963260650635\n",
      "   Avg policy loss:  0.6323114037513733\n",
      "   Avg total loss:   1.8422077298164368\n",
      "Training [68224/107244] [2.030786e-04s per sample]\n",
      "   Avg value loss:   1.132421612739563\n",
      "   Avg policy loss:  0.5946515798568726\n",
      "   Avg total loss:   1.7270731925964355\n",
      "Training [68352/107244] [2.073850e-04s per sample]\n",
      "   Avg value loss:   1.2168595790863037\n",
      "   Avg policy loss:  0.5762319564819336\n",
      "   Avg total loss:   1.7930915355682373\n",
      "Training [68480/107244] [2.126731e-04s per sample]\n",
      "   Avg value loss:   1.0854556560516357\n",
      "   Avg policy loss:  0.612038791179657\n",
      "   Avg total loss:   1.6974944472312927\n",
      "Training [68608/107244] [2.273936e-04s per sample]\n",
      "   Avg value loss:   1.0672099590301514\n",
      "   Avg policy loss:  0.5843547582626343\n",
      "   Avg total loss:   1.6515647172927856\n",
      "Training [68736/107244] [2.121646e-04s per sample]\n",
      "   Avg value loss:   1.1481235027313232\n",
      "   Avg policy loss:  0.6019877195358276\n",
      "   Avg total loss:   1.7501112222671509\n",
      "Training [68864/107244] [2.104230e-04s per sample]\n",
      "   Avg value loss:   1.173265814781189\n",
      "   Avg policy loss:  0.6120904684066772\n",
      "   Avg total loss:   1.7853562831878662\n",
      "Training [68992/107244] [2.105162e-04s per sample]\n",
      "   Avg value loss:   1.0919685363769531\n",
      "   Avg policy loss:  0.6156600117683411\n",
      "   Avg total loss:   1.7076285481452942\n",
      "Training [69120/107244] [2.258681e-04s per sample]\n",
      "   Avg value loss:   1.2211700677871704\n",
      "   Avg policy loss:  0.6187501549720764\n",
      "   Avg total loss:   1.8399202227592468\n",
      "Training [69248/107244] [2.212580e-04s per sample]\n",
      "   Avg value loss:   1.1052325963974\n",
      "   Avg policy loss:  0.5985152125358582\n",
      "   Avg total loss:   1.703747808933258\n",
      "Training [69376/107244] [2.048109e-04s per sample]\n",
      "   Avg value loss:   1.121352195739746\n",
      "   Avg policy loss:  0.5783318281173706\n",
      "   Avg total loss:   1.6996840238571167\n",
      "Training [69504/107244] [2.061557e-04s per sample]\n",
      "   Avg value loss:   1.1003267765045166\n",
      "   Avg policy loss:  0.5929948091506958\n",
      "   Avg total loss:   1.6933215856552124\n",
      "Training [69632/107244] [2.169292e-04s per sample]\n",
      "   Avg value loss:   1.1944818496704102\n",
      "   Avg policy loss:  0.5914022326469421\n",
      "   Avg total loss:   1.7858840823173523\n",
      "Training [69760/107244] [2.270639e-04s per sample]\n",
      "   Avg value loss:   1.1613409519195557\n",
      "   Avg policy loss:  0.5983543992042542\n",
      "   Avg total loss:   1.7596953511238098\n",
      "Training [69888/107244] [2.140012e-04s per sample]\n",
      "   Avg value loss:   1.1039705276489258\n",
      "   Avg policy loss:  0.5967027544975281\n",
      "   Avg total loss:   1.7006732821464539\n",
      "Training [70016/107244] [2.095941e-04s per sample]\n",
      "   Avg value loss:   1.1789469718933105\n",
      "   Avg policy loss:  0.609508752822876\n",
      "   Avg total loss:   1.7884557247161865\n",
      "Training [70144/107244] [2.190787e-04s per sample]\n",
      "   Avg value loss:   1.14530611038208\n",
      "   Avg policy loss:  0.6018418669700623\n",
      "   Avg total loss:   1.7471479773521423\n",
      "Training [70272/107244] [2.230462e-04s per sample]\n",
      "   Avg value loss:   1.1820850372314453\n",
      "   Avg policy loss:  0.5615620613098145\n",
      "   Avg total loss:   1.7436470985412598\n",
      "Training [70400/107244] [2.183281e-04s per sample]\n",
      "   Avg value loss:   1.1991910934448242\n",
      "   Avg policy loss:  0.5889717936515808\n",
      "   Avg total loss:   1.788162887096405\n",
      "Training [70528/107244] [2.110768e-04s per sample]\n",
      "   Avg value loss:   1.238830327987671\n",
      "   Avg policy loss:  0.6265358328819275\n",
      "   Avg total loss:   1.8653661608695984\n",
      "Training [70656/107244] [2.074391e-04s per sample]\n",
      "   Avg value loss:   1.1067653894424438\n",
      "   Avg policy loss:  0.568567156791687\n",
      "   Avg total loss:   1.6753325462341309\n",
      "Training [70784/107244] [2.134312e-04s per sample]\n",
      "   Avg value loss:   1.1209535598754883\n",
      "   Avg policy loss:  0.576378583908081\n",
      "   Avg total loss:   1.6973321437835693\n",
      "Training [70912/107244] [2.235211e-04s per sample]\n",
      "   Avg value loss:   1.1373395919799805\n",
      "   Avg policy loss:  0.6032572388648987\n",
      "   Avg total loss:   1.7405968308448792\n",
      "Training [71040/107244] [2.155229e-04s per sample]\n",
      "   Avg value loss:   1.194258213043213\n",
      "   Avg policy loss:  0.6077882647514343\n",
      "   Avg total loss:   1.8020464777946472\n",
      "Training [71168/107244] [2.162904e-04s per sample]\n",
      "   Avg value loss:   1.20955491065979\n",
      "   Avg policy loss:  0.6130648851394653\n",
      "   Avg total loss:   1.8226197957992554\n",
      "Training [71296/107244] [2.106968e-04s per sample]\n",
      "   Avg value loss:   1.1247258186340332\n",
      "   Avg policy loss:  0.6103882789611816\n",
      "   Avg total loss:   1.7351140975952148\n",
      "Training [71424/107244] [2.237577e-04s per sample]\n",
      "   Avg value loss:   1.1448845863342285\n",
      "   Avg policy loss:  0.623339831829071\n",
      "   Avg total loss:   1.7682244181632996\n",
      "Training [71552/107244] [2.240408e-04s per sample]\n",
      "   Avg value loss:   1.1561201810836792\n",
      "   Avg policy loss:  0.5985791087150574\n",
      "   Avg total loss:   1.7546992897987366\n",
      "Training [71680/107244] [2.101492e-04s per sample]\n",
      "   Avg value loss:   1.16558837890625\n",
      "   Avg policy loss:  0.5779829621315002\n",
      "   Avg total loss:   1.7435713410377502\n",
      "Training [71808/107244] [2.196562e-04s per sample]\n",
      "   Avg value loss:   1.2894721031188965\n",
      "   Avg policy loss:  0.5943301916122437\n",
      "   Avg total loss:   1.8838022947311401\n",
      "Training [71936/107244] [2.163276e-04s per sample]\n",
      "   Avg value loss:   1.1020686626434326\n",
      "   Avg policy loss:  0.5649983286857605\n",
      "   Avg total loss:   1.6670669913291931\n",
      "Training [72064/107244] [2.109539e-04s per sample]\n",
      "   Avg value loss:   1.19664466381073\n",
      "   Avg policy loss:  0.5817834734916687\n",
      "   Avg total loss:   1.7784281373023987\n",
      "Training [72192/107244] [2.113283e-04s per sample]\n",
      "   Avg value loss:   1.122908592224121\n",
      "   Avg policy loss:  0.5786322951316833\n",
      "   Avg total loss:   1.7015408873558044\n",
      "Training [72320/107244] [2.207421e-04s per sample]\n",
      "   Avg value loss:   1.1150403022766113\n",
      "   Avg policy loss:  0.6202658414840698\n",
      "   Avg total loss:   1.7353061437606812\n",
      "Training [72448/107244] [2.137087e-04s per sample]\n",
      "   Avg value loss:   1.1530934572219849\n",
      "   Avg policy loss:  0.6036673188209534\n",
      "   Avg total loss:   1.7567607760429382\n",
      "Training [72576/107244] [2.180152e-04s per sample]\n",
      "   Avg value loss:   1.1222561597824097\n",
      "   Avg policy loss:  0.5873686671257019\n",
      "   Avg total loss:   1.7096248269081116\n",
      "Training [72704/107244] [2.183747e-04s per sample]\n",
      "   Avg value loss:   1.180589199066162\n",
      "   Avg policy loss:  0.5968620181083679\n",
      "   Avg total loss:   1.77745121717453\n",
      "Training [72832/107244] [2.245698e-04s per sample]\n",
      "   Avg value loss:   1.1621047258377075\n",
      "   Avg policy loss:  0.5849558115005493\n",
      "   Avg total loss:   1.7470605373382568\n",
      "Training [72960/107244] [2.189837e-04s per sample]\n",
      "   Avg value loss:   1.1037259101867676\n",
      "   Avg policy loss:  0.5969428420066833\n",
      "   Avg total loss:   1.700668752193451\n",
      "Training [73088/107244] [2.156030e-04s per sample]\n",
      "   Avg value loss:   1.1600974798202515\n",
      "   Avg policy loss:  0.5923373103141785\n",
      "   Avg total loss:   1.75243479013443\n",
      "Training [73216/107244] [2.094842e-04s per sample]\n",
      "   Avg value loss:   1.1389498710632324\n",
      "   Avg policy loss:  0.610856831073761\n",
      "   Avg total loss:   1.7498067021369934\n",
      "Training [73344/107244] [2.082717e-04s per sample]\n",
      "   Avg value loss:   1.1784319877624512\n",
      "   Avg policy loss:  0.5840103030204773\n",
      "   Avg total loss:   1.7624422907829285\n",
      "Training [73472/107244] [2.288502e-04s per sample]\n",
      "   Avg value loss:   1.1144156455993652\n",
      "   Avg policy loss:  0.6130397319793701\n",
      "   Avg total loss:   1.7274553775787354\n",
      "Training [73600/107244] [2.113655e-04s per sample]\n",
      "   Avg value loss:   1.2470011711120605\n",
      "   Avg policy loss:  0.5836024284362793\n",
      "   Avg total loss:   1.8306035995483398\n",
      "Training [73728/107244] [2.224781e-04s per sample]\n",
      "   Avg value loss:   1.189403772354126\n",
      "   Avg policy loss:  0.6424182057380676\n",
      "   Avg total loss:   1.8318219780921936\n",
      "Training [73856/107244] [2.234764e-04s per sample]\n",
      "   Avg value loss:   1.1541451215744019\n",
      "   Avg policy loss:  0.5973265767097473\n",
      "   Avg total loss:   1.7514716982841492\n",
      "Training [73984/107244] [2.127662e-04s per sample]\n",
      "   Avg value loss:   1.1095476150512695\n",
      "   Avg policy loss:  0.5848537683486938\n",
      "   Avg total loss:   1.6944013833999634\n",
      "Training [74112/107244] [2.108291e-04s per sample]\n",
      "   Avg value loss:   1.2188408374786377\n",
      "   Avg policy loss:  0.604446530342102\n",
      "   Avg total loss:   1.8232873678207397\n",
      "Training [74240/107244] [2.141017e-04s per sample]\n",
      "   Avg value loss:   1.1637706756591797\n",
      "   Avg policy loss:  0.6067431569099426\n",
      "   Avg total loss:   1.7705138325691223\n",
      "Training [74368/107244] [2.055764e-04s per sample]\n",
      "   Avg value loss:   1.2334531545639038\n",
      "   Avg policy loss:  0.609469473361969\n",
      "   Avg total loss:   1.8429226279258728\n",
      "Training [74496/107244] [2.133045e-04s per sample]\n",
      "   Avg value loss:   1.087276816368103\n",
      "   Avg policy loss:  0.5650482773780823\n",
      "   Avg total loss:   1.6523250937461853\n",
      "Training [74624/107244] [2.165157e-04s per sample]\n",
      "   Avg value loss:   1.1768375635147095\n",
      "   Avg policy loss:  0.60978102684021\n",
      "   Avg total loss:   1.7866185903549194\n",
      "Training [74752/107244] [2.158433e-04s per sample]\n",
      "   Avg value loss:   1.1533070802688599\n",
      "   Avg policy loss:  0.5908828377723694\n",
      "   Avg total loss:   1.7441899180412292\n",
      "Training [74880/107244] [2.071410e-04s per sample]\n",
      "   Avg value loss:   1.0788304805755615\n",
      "   Avg policy loss:  0.5918623208999634\n",
      "   Avg total loss:   1.670692801475525\n",
      "Training [75008/107244] [2.092104e-04s per sample]\n",
      "   Avg value loss:   1.1255457401275635\n",
      "   Avg policy loss:  0.6015635132789612\n",
      "   Avg total loss:   1.7271092534065247\n",
      "Training [75136/107244] [2.074931e-04s per sample]\n",
      "   Avg value loss:   1.1413739919662476\n",
      "   Avg policy loss:  0.6012136340141296\n",
      "   Avg total loss:   1.7425876259803772\n",
      "Training [75264/107244] [2.064053e-04s per sample]\n",
      "   Avg value loss:   1.1568214893341064\n",
      "   Avg policy loss:  0.6059481501579285\n",
      "   Avg total loss:   1.762769639492035\n",
      "Training [75392/107244] [2.154615e-04s per sample]\n",
      "   Avg value loss:   1.1521544456481934\n",
      "   Avg policy loss:  0.6385871767997742\n",
      "   Avg total loss:   1.7907416224479675\n",
      "Training [75520/107244] [2.143607e-04s per sample]\n",
      "   Avg value loss:   1.223758578300476\n",
      "   Avg policy loss:  0.6152461767196655\n",
      "   Avg total loss:   1.8390047550201416\n",
      "Training [75648/107244] [2.122167e-04s per sample]\n",
      "   Avg value loss:   1.1684682369232178\n",
      "   Avg policy loss:  0.6287446022033691\n",
      "   Avg total loss:   1.797212839126587\n",
      "Training [75776/107244] [2.244059e-04s per sample]\n",
      "   Avg value loss:   1.150691270828247\n",
      "   Avg policy loss:  0.6017210483551025\n",
      "   Avg total loss:   1.7524123191833496\n",
      "Training [75904/107244] [2.284516e-04s per sample]\n",
      "   Avg value loss:   1.1338974237442017\n",
      "   Avg policy loss:  0.5850076675415039\n",
      "   Avg total loss:   1.7189050912857056\n",
      "Training [76032/107244] [2.250466e-04s per sample]\n",
      "   Avg value loss:   1.205277442932129\n",
      "   Avg policy loss:  0.6270278692245483\n",
      "   Avg total loss:   1.8323053121566772\n",
      "Training [76160/107244] [2.280772e-04s per sample]\n",
      "   Avg value loss:   1.1115833520889282\n",
      "   Avg policy loss:  0.5663148164749146\n",
      "   Avg total loss:   1.6778981685638428\n",
      "Training [76288/107244] [2.106652e-04s per sample]\n",
      "   Avg value loss:   1.1480474472045898\n",
      "   Avg policy loss:  0.5986008644104004\n",
      "   Avg total loss:   1.7466483116149902\n",
      "Training [76416/107244] [2.101250e-04s per sample]\n",
      "   Avg value loss:   1.1730881929397583\n",
      "   Avg policy loss:  0.565492570400238\n",
      "   Avg total loss:   1.7385807633399963\n",
      "Training [76544/107244] [2.120938e-04s per sample]\n",
      "   Avg value loss:   1.1297775506973267\n",
      "   Avg policy loss:  0.611034095287323\n",
      "   Avg total loss:   1.7408116459846497\n",
      "Training [76672/107244] [2.317969e-04s per sample]\n",
      "   Avg value loss:   1.140399694442749\n",
      "   Avg policy loss:  0.6164525151252747\n",
      "   Avg total loss:   1.7568522095680237\n",
      "Training [76800/107244] [2.133120e-04s per sample]\n",
      "   Avg value loss:   1.1498388051986694\n",
      "   Avg policy loss:  0.6124534606933594\n",
      "   Avg total loss:   1.7622922658920288\n",
      "Training [76928/107244] [2.094768e-04s per sample]\n",
      "   Avg value loss:   1.1322999000549316\n",
      "   Avg policy loss:  0.6216813325881958\n",
      "   Avg total loss:   1.7539812326431274\n",
      "Training [77056/107244] [2.165847e-04s per sample]\n",
      "   Avg value loss:   1.1229971647262573\n",
      "   Avg policy loss:  0.5749407410621643\n",
      "   Avg total loss:   1.6979379057884216\n",
      "Training [77184/107244] [2.133437e-04s per sample]\n",
      "   Avg value loss:   1.145444631576538\n",
      "   Avg policy loss:  0.5651691555976868\n",
      "   Avg total loss:   1.7106137871742249\n",
      "Training [77312/107244] [2.066791e-04s per sample]\n",
      "   Avg value loss:   1.1565709114074707\n",
      "   Avg policy loss:  0.5703129768371582\n",
      "   Avg total loss:   1.726883888244629\n",
      "Training [77440/107244] [2.317820e-04s per sample]\n",
      "   Avg value loss:   1.1609156131744385\n",
      "   Avg policy loss:  0.5857289433479309\n",
      "   Avg total loss:   1.7466445565223694\n",
      "Training [77568/107244] [2.250317e-04s per sample]\n",
      "   Avg value loss:   1.1154299974441528\n",
      "   Avg policy loss:  0.5818589925765991\n",
      "   Avg total loss:   1.697288990020752\n",
      "Training [77696/107244] [2.501942e-04s per sample]\n",
      "   Avg value loss:   1.0560765266418457\n",
      "   Avg policy loss:  0.6049193739891052\n",
      "   Avg total loss:   1.660995900630951\n",
      "Training [77824/107244] [2.185795e-04s per sample]\n",
      "   Avg value loss:   1.0475578308105469\n",
      "   Avg policy loss:  0.6004080176353455\n",
      "   Avg total loss:   1.6479658484458923\n",
      "Training [77952/107244] [2.059527e-04s per sample]\n",
      "   Avg value loss:   1.1615943908691406\n",
      "   Avg policy loss:  0.6128045320510864\n",
      "   Avg total loss:   1.774398922920227\n",
      "Training [78080/107244] [2.196878e-04s per sample]\n",
      "   Avg value loss:   1.1205428838729858\n",
      "   Avg policy loss:  0.5710929036140442\n",
      "   Avg total loss:   1.69163578748703\n",
      "Training [78208/107244] [2.167579e-04s per sample]\n",
      "   Avg value loss:   1.1041158437728882\n",
      "   Avg policy loss:  0.6000354886054993\n",
      "   Avg total loss:   1.7041513323783875\n",
      "Training [78336/107244] [2.287496e-04s per sample]\n",
      "   Avg value loss:   1.150865912437439\n",
      "   Avg policy loss:  0.5765954852104187\n",
      "   Avg total loss:   1.7274613976478577\n",
      "Training [78464/107244] [2.246331e-04s per sample]\n",
      "   Avg value loss:   1.1587107181549072\n",
      "   Avg policy loss:  0.5921059846878052\n",
      "   Avg total loss:   1.7508167028427124\n",
      "Training [78592/107244] [2.195090e-04s per sample]\n",
      "   Avg value loss:   1.2298924922943115\n",
      "   Avg policy loss:  0.6304143667221069\n",
      "   Avg total loss:   1.8603068590164185\n",
      "Training [78720/107244] [2.188124e-04s per sample]\n",
      "   Avg value loss:   1.1357231140136719\n",
      "   Avg policy loss:  0.5692950487136841\n",
      "   Avg total loss:   1.705018162727356\n",
      "Training [78848/107244] [2.251491e-04s per sample]\n",
      "   Avg value loss:   1.187782645225525\n",
      "   Avg policy loss:  0.6013447046279907\n",
      "   Avg total loss:   1.7891273498535156\n",
      "Training [78976/107244] [2.264380e-04s per sample]\n",
      "   Avg value loss:   1.183397889137268\n",
      "   Avg policy loss:  0.6019315123558044\n",
      "   Avg total loss:   1.7853294014930725\n",
      "Training [79104/107244] [2.298206e-04s per sample]\n",
      "   Avg value loss:   1.1492033004760742\n",
      "   Avg policy loss:  0.6209684610366821\n",
      "   Avg total loss:   1.7701717615127563\n",
      "Training [79232/107244] [2.136789e-04s per sample]\n",
      "   Avg value loss:   1.0794930458068848\n",
      "   Avg policy loss:  0.6014576554298401\n",
      "   Avg total loss:   1.6809507012367249\n",
      "Training [79360/107244] [2.126023e-04s per sample]\n",
      "   Avg value loss:   1.1343238353729248\n",
      "   Avg policy loss:  0.5927338004112244\n",
      "   Avg total loss:   1.7270576357841492\n",
      "Training [79488/107244] [2.190005e-04s per sample]\n",
      "   Avg value loss:   1.1424038410186768\n",
      "   Avg policy loss:  0.6102558970451355\n",
      "   Avg total loss:   1.7526597380638123\n",
      "Training [79616/107244] [2.071634e-04s per sample]\n",
      "   Avg value loss:   1.151080846786499\n",
      "   Avg policy loss:  0.5920195579528809\n",
      "   Avg total loss:   1.7431004047393799\n",
      "Training [79744/107244] [2.117418e-04s per sample]\n",
      "   Avg value loss:   1.153796672821045\n",
      "   Avg policy loss:  0.5956211686134338\n",
      "   Avg total loss:   1.7494178414344788\n",
      "Training [79872/107244] [2.075247e-04s per sample]\n",
      "   Avg value loss:   1.1796497106552124\n",
      "   Avg policy loss:  0.5929489731788635\n",
      "   Avg total loss:   1.772598683834076\n",
      "Training [80000/107244] [2.148766e-04s per sample]\n",
      "   Avg value loss:   1.1000336408615112\n",
      "   Avg policy loss:  0.627052366733551\n",
      "   Avg total loss:   1.7270860075950623\n",
      "Training [80128/107244] [2.243649e-04s per sample]\n",
      "   Avg value loss:   1.100707769393921\n",
      "   Avg policy loss:  0.601439356803894\n",
      "   Avg total loss:   1.702147126197815\n",
      "Training [80256/107244] [2.205931e-04s per sample]\n",
      "   Avg value loss:   1.1693588495254517\n",
      "   Avg policy loss:  0.6016642451286316\n",
      "   Avg total loss:   1.7710230946540833\n",
      "Training [80384/107244] [2.120715e-04s per sample]\n",
      "   Avg value loss:   1.1934642791748047\n",
      "   Avg policy loss:  0.5681263208389282\n",
      "   Avg total loss:   1.761590600013733\n",
      "Training [80512/107244] [2.062581e-04s per sample]\n",
      "   Avg value loss:   1.0911577939987183\n",
      "   Avg policy loss:  0.5715033411979675\n",
      "   Avg total loss:   1.6626611351966858\n",
      "Training [80640/107244] [2.214704e-04s per sample]\n",
      "   Avg value loss:   1.1967616081237793\n",
      "   Avg policy loss:  0.6096120476722717\n",
      "   Avg total loss:   1.806373655796051\n",
      "Training [80768/107244] [2.212450e-04s per sample]\n",
      "   Avg value loss:   1.1090161800384521\n",
      "   Avg policy loss:  0.6088337898254395\n",
      "   Avg total loss:   1.7178499698638916\n",
      "Training [80896/107244] [2.207756e-04s per sample]\n",
      "   Avg value loss:   1.0798710584640503\n",
      "   Avg policy loss:  0.6049273014068604\n",
      "   Avg total loss:   1.6847983598709106\n",
      "Training [81024/107244] [2.243817e-04s per sample]\n",
      "   Avg value loss:   1.2434114217758179\n",
      "   Avg policy loss:  0.5788227319717407\n",
      "   Avg total loss:   1.8222341537475586\n",
      "Training [81152/107244] [2.152119e-04s per sample]\n",
      "   Avg value loss:   1.0763814449310303\n",
      "   Avg policy loss:  0.6002483367919922\n",
      "   Avg total loss:   1.6766297817230225\n",
      "Training [81280/107244] [2.197009e-04s per sample]\n",
      "   Avg value loss:   1.1008700132369995\n",
      "   Avg policy loss:  0.6225848197937012\n",
      "   Avg total loss:   1.7234548330307007\n",
      "Training [81408/107244] [2.124235e-04s per sample]\n",
      "   Avg value loss:   1.1796460151672363\n",
      "   Avg policy loss:  0.6096456050872803\n",
      "   Avg total loss:   1.7892916202545166\n",
      "Training [81536/107244] [2.131555e-04s per sample]\n",
      "   Avg value loss:   1.1332354545593262\n",
      "   Avg policy loss:  0.5928723812103271\n",
      "   Avg total loss:   1.7261078357696533\n",
      "Training [81664/107244] [2.178028e-04s per sample]\n",
      "   Avg value loss:   1.1937344074249268\n",
      "   Avg policy loss:  0.5872191786766052\n",
      "   Avg total loss:   1.780953586101532\n",
      "Training [81792/107244] [2.251323e-04s per sample]\n",
      "   Avg value loss:   1.1065099239349365\n",
      "   Avg policy loss:  0.5990275144577026\n",
      "   Avg total loss:   1.7055374383926392\n",
      "Training [81920/107244] [2.211090e-04s per sample]\n",
      "   Avg value loss:   1.1315546035766602\n",
      "   Avg policy loss:  0.597415030002594\n",
      "   Avg total loss:   1.7289696335792542\n",
      "Training [82048/107244] [2.150778e-04s per sample]\n",
      "   Avg value loss:   1.1510645151138306\n",
      "   Avg policy loss:  0.5769931077957153\n",
      "   Avg total loss:   1.728057622909546\n",
      "Training [82176/107244] [2.126638e-04s per sample]\n",
      "   Avg value loss:   1.1576286554336548\n",
      "   Avg policy loss:  0.6044131517410278\n",
      "   Avg total loss:   1.7620418071746826\n",
      "Training [82304/107244] [2.198927e-04s per sample]\n",
      "   Avg value loss:   1.1621553897857666\n",
      "   Avg policy loss:  0.6427122950553894\n",
      "   Avg total loss:   1.804867684841156\n",
      "Training [82432/107244] [2.135076e-04s per sample]\n",
      "   Avg value loss:   1.0449591875076294\n",
      "   Avg policy loss:  0.6024258732795715\n",
      "   Avg total loss:   1.647385060787201\n",
      "Training [82560/107244] [2.086479e-04s per sample]\n",
      "   Avg value loss:   1.1565459966659546\n",
      "   Avg policy loss:  0.5824428796768188\n",
      "   Avg total loss:   1.7389888763427734\n",
      "Training [82688/107244] [2.061632e-04s per sample]\n",
      "   Avg value loss:   1.1212691068649292\n",
      "   Avg policy loss:  0.629834771156311\n",
      "   Avg total loss:   1.7511038780212402\n",
      "Training [82816/107244] [2.055150e-04s per sample]\n",
      "   Avg value loss:   1.1192642450332642\n",
      "   Avg policy loss:  0.6104612946510315\n",
      "   Avg total loss:   1.7297255396842957\n",
      "Training [82944/107244] [2.127662e-04s per sample]\n",
      "   Avg value loss:   1.1551923751831055\n",
      "   Avg policy loss:  0.6009243726730347\n",
      "   Avg total loss:   1.7561167478561401\n",
      "Training [83072/107244] [2.247095e-04s per sample]\n",
      "   Avg value loss:   1.0792890787124634\n",
      "   Avg policy loss:  0.5885139107704163\n",
      "   Avg total loss:   1.6678029894828796\n",
      "Training [83200/107244] [2.110768e-04s per sample]\n",
      "   Avg value loss:   1.1033947467803955\n",
      "   Avg policy loss:  0.5742248892784119\n",
      "   Avg total loss:   1.6776196360588074\n",
      "Training [83328/107244] [2.238359e-04s per sample]\n",
      "   Avg value loss:   1.122231364250183\n",
      "   Avg policy loss:  0.6066493988037109\n",
      "   Avg total loss:   1.728880763053894\n",
      "Training [83456/107244] [2.202652e-04s per sample]\n",
      "   Avg value loss:   1.149986743927002\n",
      "   Avg policy loss:  0.6086223721504211\n",
      "   Avg total loss:   1.758609116077423\n",
      "Training [83584/107244] [2.087131e-04s per sample]\n",
      "   Avg value loss:   1.1863949298858643\n",
      "   Avg policy loss:  0.5947031378746033\n",
      "   Avg total loss:   1.7810980677604675\n",
      "Training [83712/107244] [2.067108e-04s per sample]\n",
      "   Avg value loss:   1.134521722793579\n",
      "   Avg policy loss:  0.5964879989624023\n",
      "   Avg total loss:   1.7310097217559814\n",
      "Training [83840/107244] [1.985617e-04s per sample]\n",
      "   Avg value loss:   1.1954379081726074\n",
      "   Avg policy loss:  0.5969858169555664\n",
      "   Avg total loss:   1.7924237251281738\n",
      "Training [83968/107244] [2.030004e-04s per sample]\n",
      "   Avg value loss:   1.1618754863739014\n",
      "   Avg policy loss:  0.5747062563896179\n",
      "   Avg total loss:   1.7365817427635193\n",
      "Training [84096/107244] [2.177656e-04s per sample]\n",
      "   Avg value loss:   1.2016801834106445\n",
      "   Avg policy loss:  0.626027524471283\n",
      "   Avg total loss:   1.8277077078819275\n",
      "Training [84224/107244] [2.008304e-04s per sample]\n",
      "   Avg value loss:   1.144834041595459\n",
      "   Avg policy loss:  0.6036617159843445\n",
      "   Avg total loss:   1.7484957575798035\n",
      "Training [84352/107244] [2.083350e-04s per sample]\n",
      "   Avg value loss:   1.1066224575042725\n",
      "   Avg policy loss:  0.5913935899734497\n",
      "   Avg total loss:   1.6980160474777222\n",
      "Training [84480/107244] [2.087727e-04s per sample]\n",
      "   Avg value loss:   1.171291708946228\n",
      "   Avg policy loss:  0.5964764356613159\n",
      "   Avg total loss:   1.767768144607544\n",
      "Training [84608/107244] [2.038348e-04s per sample]\n",
      "   Avg value loss:   1.1645134687423706\n",
      "   Avg policy loss:  0.5879996418952942\n",
      "   Avg total loss:   1.7525131106376648\n",
      "Training [84736/107244] [2.112202e-04s per sample]\n",
      "   Avg value loss:   1.115276575088501\n",
      "   Avg policy loss:  0.591474711894989\n",
      "   Avg total loss:   1.70675128698349\n",
      "Training [84864/107244] [2.055541e-04s per sample]\n",
      "   Avg value loss:   1.1857335567474365\n",
      "   Avg policy loss:  0.6071212887763977\n",
      "   Avg total loss:   1.7928548455238342\n",
      "Training [84992/107244] [2.065059e-04s per sample]\n",
      "   Avg value loss:   1.1586307287216187\n",
      "   Avg policy loss:  0.5720068216323853\n",
      "   Avg total loss:   1.730637550354004\n",
      "Training [85120/107244] [2.067331e-04s per sample]\n",
      "   Avg value loss:   1.093078374862671\n",
      "   Avg policy loss:  0.5645865797996521\n",
      "   Avg total loss:   1.657664954662323\n",
      "Training [85248/107244] [2.127420e-04s per sample]\n",
      "   Avg value loss:   1.1482279300689697\n",
      "   Avg policy loss:  0.5809253454208374\n",
      "   Avg total loss:   1.7291532754898071\n",
      "Training [85376/107244] [2.057515e-04s per sample]\n",
      "   Avg value loss:   1.1622326374053955\n",
      "   Avg policy loss:  0.6045929193496704\n",
      "   Avg total loss:   1.766825556755066\n",
      "Training [85504/107244] [2.080221e-04s per sample]\n",
      "   Avg value loss:   1.088901162147522\n",
      "   Avg policy loss:  0.5721745491027832\n",
      "   Avg total loss:   1.6610757112503052\n",
      "Training [85632/107244] [2.056323e-04s per sample]\n",
      "   Avg value loss:   1.1597403287887573\n",
      "   Avg policy loss:  0.5823438763618469\n",
      "   Avg total loss:   1.7420842051506042\n",
      "Training [85760/107244] [2.244841e-04s per sample]\n",
      "   Avg value loss:   1.1708791255950928\n",
      "   Avg policy loss:  0.5423749089241028\n",
      "   Avg total loss:   1.7132540345191956\n",
      "Training [85888/107244] [2.317168e-04s per sample]\n",
      "   Avg value loss:   1.1514415740966797\n",
      "   Avg policy loss:  0.5869408845901489\n",
      "   Avg total loss:   1.7383824586868286\n",
      "Training [86016/107244] [2.144929e-04s per sample]\n",
      "   Avg value loss:   1.19159996509552\n",
      "   Avg policy loss:  0.5775178074836731\n",
      "   Avg total loss:   1.7691177725791931\n",
      "Training [86144/107244] [2.089851e-04s per sample]\n",
      "   Avg value loss:   1.1938016414642334\n",
      "   Avg policy loss:  0.5782508254051208\n",
      "   Avg total loss:   1.7720524668693542\n",
      "Training [86272/107244] [2.077799e-04s per sample]\n",
      "   Avg value loss:   1.1468435525894165\n",
      "   Avg policy loss:  0.5617539882659912\n",
      "   Avg total loss:   1.7085975408554077\n",
      "Training [86400/107244] [2.261028e-04s per sample]\n",
      "   Avg value loss:   1.107021689414978\n",
      "   Avg policy loss:  0.5873348116874695\n",
      "   Avg total loss:   1.6943565011024475\n",
      "Training [86528/107244] [2.136957e-04s per sample]\n",
      "   Avg value loss:   1.2087353467941284\n",
      "   Avg policy loss:  0.5854250192642212\n",
      "   Avg total loss:   1.7941603660583496\n",
      "Training [86656/107244] [2.054460e-04s per sample]\n",
      "   Avg value loss:   1.149778127670288\n",
      "   Avg policy loss:  0.5881868600845337\n",
      "   Avg total loss:   1.7379649877548218\n",
      "Training [86784/107244] [2.020393e-04s per sample]\n",
      "   Avg value loss:   1.238692045211792\n",
      "   Avg policy loss:  0.5706109404563904\n",
      "   Avg total loss:   1.8093029856681824\n",
      "Training [86912/107244] [2.450403e-04s per sample]\n",
      "   Avg value loss:   1.2144713401794434\n",
      "   Avg policy loss:  0.6079290509223938\n",
      "   Avg total loss:   1.8224003911018372\n",
      "Training [87040/107244] [2.150163e-04s per sample]\n",
      "   Avg value loss:   1.130435585975647\n",
      "   Avg policy loss:  0.5786572098731995\n",
      "   Avg total loss:   1.7090927958488464\n",
      "Training [87168/107244] [2.069455e-04s per sample]\n",
      "   Avg value loss:   1.093780279159546\n",
      "   Avg policy loss:  0.5821618437767029\n",
      "   Avg total loss:   1.6759421229362488\n",
      "Training [87296/107244] [2.027266e-04s per sample]\n",
      "   Avg value loss:   1.2941036224365234\n",
      "   Avg policy loss:  0.5747089982032776\n",
      "   Avg total loss:   1.868812620639801\n",
      "Training [87424/107244] [2.136715e-04s per sample]\n",
      "   Avg value loss:   1.1114436388015747\n",
      "   Avg policy loss:  0.5995587110519409\n",
      "   Avg total loss:   1.7110023498535156\n",
      "Training [87552/107244] [2.195463e-04s per sample]\n",
      "   Avg value loss:   1.2423033714294434\n",
      "   Avg policy loss:  0.5766085982322693\n",
      "   Avg total loss:   1.8189119696617126\n",
      "Training [87680/107244] [2.214536e-04s per sample]\n",
      "   Avg value loss:   1.2492125034332275\n",
      "   Avg policy loss:  0.5888576507568359\n",
      "   Avg total loss:   1.8380701541900635\n",
      "Training [87808/107244] [2.140552e-04s per sample]\n",
      "   Avg value loss:   1.1880323886871338\n",
      "   Avg policy loss:  0.5972633957862854\n",
      "   Avg total loss:   1.7852957844734192\n",
      "Training [87936/107244] [2.103988e-04s per sample]\n",
      "   Avg value loss:   1.1851017475128174\n",
      "   Avg policy loss:  0.5771312713623047\n",
      "   Avg total loss:   1.762233018875122\n",
      "Training [88064/107244] [2.167169e-04s per sample]\n",
      "   Avg value loss:   1.1487338542938232\n",
      "   Avg policy loss:  0.6156215071678162\n",
      "   Avg total loss:   1.7643553614616394\n",
      "Training [88192/107244] [2.247971e-04s per sample]\n",
      "   Avg value loss:   1.1796014308929443\n",
      "   Avg policy loss:  0.6054222583770752\n",
      "   Avg total loss:   1.7850236892700195\n",
      "Training [88320/107244] [2.258513e-04s per sample]\n",
      "   Avg value loss:   1.1744115352630615\n",
      "   Avg policy loss:  0.6057540774345398\n",
      "   Avg total loss:   1.7801656126976013\n",
      "Training [88448/107244] [2.085306e-04s per sample]\n",
      "   Avg value loss:   1.0908417701721191\n",
      "   Avg policy loss:  0.5854678153991699\n",
      "   Avg total loss:   1.676309585571289\n",
      "Training [88576/107244] [2.045780e-04s per sample]\n",
      "   Avg value loss:   1.166432499885559\n",
      "   Avg policy loss:  0.6110195517539978\n",
      "   Avg total loss:   1.7774520516395569\n",
      "Training [88704/107244] [2.196413e-04s per sample]\n",
      "   Avg value loss:   1.1622402667999268\n",
      "   Avg policy loss:  0.5941828489303589\n",
      "   Avg total loss:   1.7564231157302856\n",
      "Training [88832/107244] [2.100691e-04s per sample]\n",
      "   Avg value loss:   1.19762122631073\n",
      "   Avg policy loss:  0.5865508913993835\n",
      "   Avg total loss:   1.7841721177101135\n",
      "Training [88960/107244] [2.078917e-04s per sample]\n",
      "   Avg value loss:   1.0738348960876465\n",
      "   Avg policy loss:  0.59461510181427\n",
      "   Avg total loss:   1.6684499979019165\n",
      "Training [89088/107244] [2.060402e-04s per sample]\n",
      "   Avg value loss:   1.0958194732666016\n",
      "   Avg policy loss:  0.5973040461540222\n",
      "   Avg total loss:   1.6931235194206238\n",
      "Training [89216/107244] [2.212580e-04s per sample]\n",
      "   Avg value loss:   1.165153980255127\n",
      "   Avg policy loss:  0.6323899626731873\n",
      "   Avg total loss:   1.7975439429283142\n",
      "Training [89344/107244] [2.199672e-04s per sample]\n",
      "   Avg value loss:   1.1450049877166748\n",
      "   Avg policy loss:  0.5990887880325317\n",
      "   Avg total loss:   1.7440937757492065\n",
      "Training [89472/107244] [2.032258e-04s per sample]\n",
      "   Avg value loss:   1.067882776260376\n",
      "   Avg policy loss:  0.5735509395599365\n",
      "   Avg total loss:   1.6414337158203125\n",
      "Training [89600/107244] [2.085697e-04s per sample]\n",
      "   Avg value loss:   1.1561236381530762\n",
      "   Avg policy loss:  0.5951231122016907\n",
      "   Avg total loss:   1.7512467503547668\n",
      "Training [89728/107244] [2.010465e-04s per sample]\n",
      "   Avg value loss:   1.160565972328186\n",
      "   Avg policy loss:  0.6023454666137695\n",
      "   Avg total loss:   1.7629114389419556\n",
      "Training [89856/107244] [2.230462e-04s per sample]\n",
      "   Avg value loss:   1.1164970397949219\n",
      "   Avg policy loss:  0.583877682685852\n",
      "   Avg total loss:   1.700374722480774\n",
      "Training [89984/107244] [2.060365e-04s per sample]\n",
      "   Avg value loss:   1.1588690280914307\n",
      "   Avg policy loss:  0.6083360910415649\n",
      "   Avg total loss:   1.7672051191329956\n",
      "Training [90112/107244] [2.217889e-04s per sample]\n",
      "   Avg value loss:   1.156514048576355\n",
      "   Avg policy loss:  0.6287316679954529\n",
      "   Avg total loss:   1.7852457165718079\n",
      "Training [90240/107244] [2.166945e-04s per sample]\n",
      "   Avg value loss:   1.0641372203826904\n",
      "   Avg policy loss:  0.56304931640625\n",
      "   Avg total loss:   1.6271865367889404\n",
      "Training [90368/107244] [2.139919e-04s per sample]\n",
      "   Avg value loss:   1.2034456729888916\n",
      "   Avg policy loss:  0.6176132559776306\n",
      "   Avg total loss:   1.8210589289665222\n",
      "Training [90496/107244] [2.176091e-04s per sample]\n",
      "   Avg value loss:   1.1360557079315186\n",
      "   Avg policy loss:  0.617195188999176\n",
      "   Avg total loss:   1.7532508969306946\n",
      "Training [90624/107244] [2.062172e-04s per sample]\n",
      "   Avg value loss:   1.142394781112671\n",
      "   Avg policy loss:  0.5873998403549194\n",
      "   Avg total loss:   1.7297946214675903\n",
      "Training [90752/107244] [2.091639e-04s per sample]\n",
      "   Avg value loss:   1.1513481140136719\n",
      "   Avg policy loss:  0.5373002886772156\n",
      "   Avg total loss:   1.6886484026908875\n",
      "Training [90880/107244] [2.066027e-04s per sample]\n",
      "   Avg value loss:   1.228663682937622\n",
      "   Avg policy loss:  0.5878889560699463\n",
      "   Avg total loss:   1.8165526390075684\n",
      "Training [91008/107244] [2.222974e-04s per sample]\n",
      "   Avg value loss:   1.1120779514312744\n",
      "   Avg policy loss:  0.5997249484062195\n",
      "   Avg total loss:   1.711802899837494\n",
      "Training [91136/107244] [2.154149e-04s per sample]\n",
      "   Avg value loss:   1.1716336011886597\n",
      "   Avg policy loss:  0.6246770024299622\n",
      "   Avg total loss:   1.7963106036186218\n",
      "Training [91264/107244] [2.064835e-04s per sample]\n",
      "   Avg value loss:   1.121652364730835\n",
      "   Avg policy loss:  0.5928171277046204\n",
      "   Avg total loss:   1.7144694924354553\n",
      "Training [91392/107244] [1.990069e-04s per sample]\n",
      "   Avg value loss:   1.1340655088424683\n",
      "   Avg policy loss:  0.61399906873703\n",
      "   Avg total loss:   1.7480645775794983\n",
      "Training [91520/107244] [2.112333e-04s per sample]\n",
      "   Avg value loss:   1.2483654022216797\n",
      "   Avg policy loss:  0.6171563863754272\n",
      "   Avg total loss:   1.865521788597107\n",
      "Training [91648/107244] [2.130624e-04s per sample]\n",
      "   Avg value loss:   1.1741443872451782\n",
      "   Avg policy loss:  0.5791487693786621\n",
      "   Avg total loss:   1.7532931566238403\n",
      "Training [91776/107244] [2.039839e-04s per sample]\n",
      "   Avg value loss:   1.179945707321167\n",
      "   Avg policy loss:  0.5731324553489685\n",
      "   Avg total loss:   1.7530781626701355\n",
      "Training [91904/107244] [2.026949e-04s per sample]\n",
      "   Avg value loss:   1.1899150609970093\n",
      "   Avg policy loss:  0.5957359075546265\n",
      "   Avg total loss:   1.7856509685516357\n",
      "Training [92032/107244] [2.051163e-04s per sample]\n",
      "   Avg value loss:   1.0987390279769897\n",
      "   Avg policy loss:  0.6110145449638367\n",
      "   Avg total loss:   1.7097535729408264\n",
      "Training [92160/107244] [2.292413e-04s per sample]\n",
      "   Avg value loss:   1.1916098594665527\n",
      "   Avg policy loss:  0.6125379800796509\n",
      "   Avg total loss:   1.8041478395462036\n",
      "Training [92288/107244] [2.237502e-04s per sample]\n",
      "   Avg value loss:   1.130104422569275\n",
      "   Avg policy loss:  0.5762697458267212\n",
      "   Avg total loss:   1.706374168395996\n",
      "Training [92416/107244] [2.078917e-04s per sample]\n",
      "   Avg value loss:   1.132083773612976\n",
      "   Avg policy loss:  0.6256559491157532\n",
      "   Avg total loss:   1.7577397227287292\n",
      "Training [92544/107244] [2.105944e-04s per sample]\n",
      "   Avg value loss:   1.1398298740386963\n",
      "   Avg policy loss:  0.6012663245201111\n",
      "   Avg total loss:   1.7410961985588074\n",
      "Training [92672/107244] [2.255943e-04s per sample]\n",
      "   Avg value loss:   1.122687816619873\n",
      "   Avg policy loss:  0.600466787815094\n",
      "   Avg total loss:   1.723154604434967\n",
      "Training [92800/107244] [2.117790e-04s per sample]\n",
      "   Avg value loss:   1.1785863637924194\n",
      "   Avg policy loss:  0.587334156036377\n",
      "   Avg total loss:   1.7659205198287964\n",
      "Training [92928/107244] [2.057031e-04s per sample]\n",
      "   Avg value loss:   1.1435991525650024\n",
      "   Avg policy loss:  0.5915865302085876\n",
      "   Avg total loss:   1.73518568277359\n",
      "Training [93056/107244] [2.138354e-04s per sample]\n",
      "   Avg value loss:   1.2348170280456543\n",
      "   Avg policy loss:  0.6213691234588623\n",
      "   Avg total loss:   1.8561861515045166\n",
      "Training [93184/107244] [2.054758e-04s per sample]\n",
      "   Avg value loss:   1.1539130210876465\n",
      "   Avg policy loss:  0.6112106442451477\n",
      "   Avg total loss:   1.7651236653327942\n",
      "Training [93312/107244] [2.177823e-04s per sample]\n",
      "   Avg value loss:   1.149660587310791\n",
      "   Avg policy loss:  0.5967437624931335\n",
      "   Avg total loss:   1.7464043498039246\n",
      "Training [93440/107244] [2.276972e-04s per sample]\n",
      "   Avg value loss:   1.062844157218933\n",
      "   Avg policy loss:  0.5751267075538635\n",
      "   Avg total loss:   1.6379708647727966\n",
      "Training [93568/107244] [2.246555e-04s per sample]\n",
      "   Avg value loss:   1.1260546445846558\n",
      "   Avg policy loss:  0.599824070930481\n",
      "   Avg total loss:   1.7258787155151367\n",
      "Training [93696/107244] [2.096947e-04s per sample]\n",
      "   Avg value loss:   1.1708343029022217\n",
      "   Avg policy loss:  0.5827628374099731\n",
      "   Avg total loss:   1.7535971403121948\n",
      "Training [93824/107244] [2.119690e-04s per sample]\n",
      "   Avg value loss:   1.2144763469696045\n",
      "   Avg policy loss:  0.5569639205932617\n",
      "   Avg total loss:   1.7714402675628662\n",
      "Training [93952/107244] [2.069380e-04s per sample]\n",
      "   Avg value loss:   1.1536962985992432\n",
      "   Avg policy loss:  0.5817327499389648\n",
      "   Avg total loss:   1.735429048538208\n",
      "Training [94080/107244] [2.022982e-04s per sample]\n",
      "   Avg value loss:   1.085447072982788\n",
      "   Avg policy loss:  0.5974173545837402\n",
      "   Avg total loss:   1.6828644275665283\n",
      "Training [94208/107244] [2.046321e-04s per sample]\n",
      "   Avg value loss:   1.148476243019104\n",
      "   Avg policy loss:  0.6053469181060791\n",
      "   Avg total loss:   1.753823161125183\n",
      "Training [94336/107244] [2.031345e-04s per sample]\n",
      "   Avg value loss:   1.062088966369629\n",
      "   Avg policy loss:  0.5752735733985901\n",
      "   Avg total loss:   1.637362539768219\n",
      "Training [94464/107244] [2.257749e-04s per sample]\n",
      "   Avg value loss:   1.1825542449951172\n",
      "   Avg policy loss:  0.6460055708885193\n",
      "   Avg total loss:   1.8285598158836365\n",
      "Training [94592/107244] [2.134275e-04s per sample]\n",
      "   Avg value loss:   1.0779584646224976\n",
      "   Avg policy loss:  0.6044131517410278\n",
      "   Avg total loss:   1.6823716163635254\n",
      "Training [94720/107244] [2.159849e-04s per sample]\n",
      "   Avg value loss:   1.1270551681518555\n",
      "   Avg policy loss:  0.5882688760757446\n",
      "   Avg total loss:   1.7153240442276\n",
      "Training [94848/107244] [2.237819e-04s per sample]\n",
      "   Avg value loss:   1.145165205001831\n",
      "   Avg policy loss:  0.5864472389221191\n",
      "   Avg total loss:   1.7316124439239502\n",
      "Training [94976/107244] [2.417676e-04s per sample]\n",
      "   Avg value loss:   1.1672186851501465\n",
      "   Avg policy loss:  0.5878087878227234\n",
      "   Avg total loss:   1.7550274729728699\n",
      "Training [95104/107244] [2.113227e-04s per sample]\n",
      "   Avg value loss:   1.17215895652771\n",
      "   Avg policy loss:  0.6150705218315125\n",
      "   Avg total loss:   1.7872294783592224\n",
      "Training [95232/107244] [2.004988e-04s per sample]\n",
      "   Avg value loss:   1.1362086534500122\n",
      "   Avg policy loss:  0.6210107803344727\n",
      "   Avg total loss:   1.7572194337844849\n",
      "Training [95360/107244] [2.061240e-04s per sample]\n",
      "   Avg value loss:   1.1230041980743408\n",
      "   Avg policy loss:  0.6147544384002686\n",
      "   Avg total loss:   1.7377586364746094\n",
      "Training [95488/107244] [2.088211e-04s per sample]\n",
      "   Avg value loss:   1.1535987854003906\n",
      "   Avg policy loss:  0.5867837071418762\n",
      "   Avg total loss:   1.7403824925422668\n",
      "Training [95616/107244] [2.164226e-04s per sample]\n",
      "   Avg value loss:   1.2155394554138184\n",
      "   Avg policy loss:  0.6146524548530579\n",
      "   Avg total loss:   1.8301919102668762\n",
      "Training [95744/107244] [2.112016e-04s per sample]\n",
      "   Avg value loss:   1.1748111248016357\n",
      "   Avg policy loss:  0.552091121673584\n",
      "   Avg total loss:   1.7269022464752197\n",
      "Training [95872/107244] [2.002008e-04s per sample]\n",
      "   Avg value loss:   1.1864001750946045\n",
      "   Avg policy loss:  0.5810660123825073\n",
      "   Avg total loss:   1.7674661874771118\n",
      "Training [96000/107244] [2.113581e-04s per sample]\n",
      "   Avg value loss:   1.1687754392623901\n",
      "   Avg policy loss:  0.5621141791343689\n",
      "   Avg total loss:   1.730889618396759\n",
      "Training [96128/107244] [2.129786e-04s per sample]\n",
      "   Avg value loss:   1.1210601329803467\n",
      "   Avg policy loss:  0.5392510890960693\n",
      "   Avg total loss:   1.660311222076416\n",
      "Training [96256/107244] [2.164748e-04s per sample]\n",
      "   Avg value loss:   1.1250044107437134\n",
      "   Avg policy loss:  0.5753841400146484\n",
      "   Avg total loss:   1.7003885507583618\n",
      "Training [96384/107244] [2.079047e-04s per sample]\n",
      "   Avg value loss:   1.1468677520751953\n",
      "   Avg policy loss:  0.5938465595245361\n",
      "   Avg total loss:   1.7407143115997314\n",
      "Training [96512/107244] [2.079215e-04s per sample]\n",
      "   Avg value loss:   1.0842058658599854\n",
      "   Avg policy loss:  0.6025056838989258\n",
      "   Avg total loss:   1.6867115497589111\n",
      "Training [96640/107244] [2.010409e-04s per sample]\n",
      "   Avg value loss:   1.19874906539917\n",
      "   Avg policy loss:  0.5829014182090759\n",
      "   Avg total loss:   1.7816504836082458\n",
      "Training [96768/107244] [2.251435e-04s per sample]\n",
      "   Avg value loss:   1.0527769327163696\n",
      "   Avg policy loss:  0.5927618741989136\n",
      "   Avg total loss:   1.6455388069152832\n",
      "Training [96896/107244] [2.145078e-04s per sample]\n",
      "   Avg value loss:   1.0756442546844482\n",
      "   Avg policy loss:  0.5949913263320923\n",
      "   Avg total loss:   1.6706355810165405\n",
      "Training [97024/107244] [2.060458e-04s per sample]\n",
      "   Avg value loss:   1.1363575458526611\n",
      "   Avg policy loss:  0.6225450038909912\n",
      "   Avg total loss:   1.7589025497436523\n",
      "Training [97152/107244] [2.231784e-04s per sample]\n",
      "   Avg value loss:   1.09263014793396\n",
      "   Avg policy loss:  0.6081425547599792\n",
      "   Avg total loss:   1.7007727026939392\n",
      "Training [97280/107244] [2.230871e-04s per sample]\n",
      "   Avg value loss:   1.0839415788650513\n",
      "   Avg policy loss:  0.5938171148300171\n",
      "   Avg total loss:   1.6777586936950684\n",
      "Training [97408/107244] [2.162587e-04s per sample]\n",
      "   Avg value loss:   1.1017165184020996\n",
      "   Avg policy loss:  0.6117517948150635\n",
      "   Avg total loss:   1.713468313217163\n",
      "Training [97536/107244] [2.093688e-04s per sample]\n",
      "   Avg value loss:   1.050431251525879\n",
      "   Avg policy loss:  0.5718606114387512\n",
      "   Avg total loss:   1.6222918629646301\n",
      "Training [97664/107244] [2.130400e-04s per sample]\n",
      "   Avg value loss:   1.125427007675171\n",
      "   Avg policy loss:  0.5849180221557617\n",
      "   Avg total loss:   1.7103450298309326\n",
      "Training [97792/107244] [2.075415e-04s per sample]\n",
      "   Avg value loss:   1.241307258605957\n",
      "   Avg policy loss:  0.6048315763473511\n",
      "   Avg total loss:   1.846138834953308\n",
      "Training [97920/107244] [2.077334e-04s per sample]\n",
      "   Avg value loss:   1.1672043800354004\n",
      "   Avg policy loss:  0.5781137347221375\n",
      "   Avg total loss:   1.7453181147575378\n",
      "Training [98048/107244] [1.994353e-04s per sample]\n",
      "   Avg value loss:   1.122009038925171\n",
      "   Avg policy loss:  0.6033821105957031\n",
      "   Avg total loss:   1.725391149520874\n",
      "Training [98176/107244] [2.015084e-04s per sample]\n",
      "   Avg value loss:   1.1060173511505127\n",
      "   Avg policy loss:  0.6056365966796875\n",
      "   Avg total loss:   1.7116539478302002\n",
      "Training [98304/107244] [2.080705e-04s per sample]\n",
      "   Avg value loss:   1.0462733507156372\n",
      "   Avg policy loss:  0.5832218527793884\n",
      "   Avg total loss:   1.6294952034950256\n",
      "Training [98432/107244] [2.013445e-04s per sample]\n",
      "   Avg value loss:   1.190595269203186\n",
      "   Avg policy loss:  0.5740888714790344\n",
      "   Avg total loss:   1.7646841406822205\n",
      "Training [98560/107244] [1.991559e-04s per sample]\n",
      "   Avg value loss:   1.0927759408950806\n",
      "   Avg policy loss:  0.5923977494239807\n",
      "   Avg total loss:   1.6851736903190613\n",
      "Training [98688/107244] [2.008900e-04s per sample]\n",
      "   Avg value loss:   1.241215705871582\n",
      "   Avg policy loss:  0.5831418037414551\n",
      "   Avg total loss:   1.824357509613037\n",
      "Training [98816/107244] [2.030618e-04s per sample]\n",
      "   Avg value loss:   1.1073858737945557\n",
      "   Avg policy loss:  0.5563682317733765\n",
      "   Avg total loss:   1.6637541055679321\n",
      "Training [98944/107244] [2.089217e-04s per sample]\n",
      "   Avg value loss:   1.1062949895858765\n",
      "   Avg policy loss:  0.5645096302032471\n",
      "   Avg total loss:   1.6708046197891235\n",
      "Training [99072/107244] [3.009383e-04s per sample]\n",
      "   Avg value loss:   1.1673789024353027\n",
      "   Avg policy loss:  0.5680558085441589\n",
      "   Avg total loss:   1.7354347109794617\n",
      "Training [99200/107244] [2.052728e-04s per sample]\n",
      "   Avg value loss:   1.1073118448257446\n",
      "   Avg policy loss:  0.573422908782959\n",
      "   Avg total loss:   1.6807347536087036\n",
      "Training [99328/107244] [2.028421e-04s per sample]\n",
      "   Avg value loss:   1.174119472503662\n",
      "   Avg policy loss:  0.605370283126831\n",
      "   Avg total loss:   1.7794897556304932\n",
      "Training [99456/107244] [2.070852e-04s per sample]\n",
      "   Avg value loss:   1.1849312782287598\n",
      "   Avg policy loss:  0.5713487863540649\n",
      "   Avg total loss:   1.7562800645828247\n",
      "Training [99584/107244] [2.170242e-04s per sample]\n",
      "   Avg value loss:   1.2236106395721436\n",
      "   Avg policy loss:  0.6043220162391663\n",
      "   Avg total loss:   1.8279326558113098\n",
      "Training [99712/107244] [2.306551e-04s per sample]\n",
      "   Avg value loss:   1.1222971677780151\n",
      "   Avg policy loss:  0.6089403033256531\n",
      "   Avg total loss:   1.7312374711036682\n",
      "Training [99840/107244] [2.308451e-04s per sample]\n",
      "   Avg value loss:   1.0808501243591309\n",
      "   Avg policy loss:  0.5720957517623901\n",
      "   Avg total loss:   1.652945876121521\n",
      "Training [99968/107244] [2.129208e-04s per sample]\n",
      "   Avg value loss:   1.136836051940918\n",
      "   Avg policy loss:  0.5881013870239258\n",
      "   Avg total loss:   1.7249374389648438\n",
      "Training [100096/107244] [2.171248e-04s per sample]\n",
      "   Avg value loss:   1.1404062509536743\n",
      "   Avg policy loss:  0.56895911693573\n",
      "   Avg total loss:   1.7093653678894043\n",
      "Training [100224/107244] [2.179462e-04s per sample]\n",
      "   Avg value loss:   1.0823824405670166\n",
      "   Avg policy loss:  0.5619260668754578\n",
      "   Avg total loss:   1.6443085074424744\n",
      "Training [100352/107244] [2.074372e-04s per sample]\n",
      "   Avg value loss:   1.1746840476989746\n",
      "   Avg policy loss:  0.5844966173171997\n",
      "   Avg total loss:   1.7591806650161743\n",
      "Training [100480/107244] [2.044085e-04s per sample]\n",
      "   Avg value loss:   1.1014740467071533\n",
      "   Avg policy loss:  0.5826488137245178\n",
      "   Avg total loss:   1.6841228604316711\n",
      "Training [100608/107244] [2.244599e-04s per sample]\n",
      "   Avg value loss:   1.2377040386199951\n",
      "   Avg policy loss:  0.5940128564834595\n",
      "   Avg total loss:   1.8317168951034546\n",
      "Training [100736/107244] [2.174228e-04s per sample]\n",
      "   Avg value loss:   1.1691324710845947\n",
      "   Avg policy loss:  0.5759893655776978\n",
      "   Avg total loss:   1.7451218366622925\n",
      "Training [100864/107244] [2.058689e-04s per sample]\n",
      "   Avg value loss:   1.167779803276062\n",
      "   Avg policy loss:  0.5936015844345093\n",
      "   Avg total loss:   1.7613813877105713\n",
      "Training [100992/107244] [2.066884e-04s per sample]\n",
      "   Avg value loss:   1.1666924953460693\n",
      "   Avg policy loss:  0.5908346772193909\n",
      "   Avg total loss:   1.7575271725654602\n",
      "Training [101120/107244] [2.040304e-04s per sample]\n",
      "   Avg value loss:   1.1684569120407104\n",
      "   Avg policy loss:  0.5806845426559448\n",
      "   Avg total loss:   1.7491414546966553\n",
      "Training [101248/107244] [2.012327e-04s per sample]\n",
      "   Avg value loss:   1.0690481662750244\n",
      "   Avg policy loss:  0.5664882063865662\n",
      "   Avg total loss:   1.6355363726615906\n",
      "Training [101376/107244] [2.187490e-04s per sample]\n",
      "   Avg value loss:   1.1527807712554932\n",
      "   Avg policy loss:  0.6181713938713074\n",
      "   Avg total loss:   1.7709521651268005\n",
      "Training [101504/107244] [2.031885e-04s per sample]\n",
      "   Avg value loss:   1.2299338579177856\n",
      "   Avg policy loss:  0.5775716304779053\n",
      "   Avg total loss:   1.807505488395691\n",
      "Training [101632/107244] [2.021734e-04s per sample]\n",
      "   Avg value loss:   1.1377454996109009\n",
      "   Avg policy loss:  0.5762439370155334\n",
      "   Avg total loss:   1.7139894366264343\n",
      "Training [101760/107244] [2.230871e-04s per sample]\n",
      "   Avg value loss:   1.1069300174713135\n",
      "   Avg policy loss:  0.5825497508049011\n",
      "   Avg total loss:   1.6894797682762146\n",
      "Training [101888/107244] [2.158675e-04s per sample]\n",
      "   Avg value loss:   1.1282368898391724\n",
      "   Avg policy loss:  0.5975190997123718\n",
      "   Avg total loss:   1.7257559895515442\n",
      "Training [102016/107244] [2.091639e-04s per sample]\n",
      "   Avg value loss:   1.1769448518753052\n",
      "   Avg policy loss:  0.581027626991272\n",
      "   Avg total loss:   1.7579724788665771\n",
      "Training [102144/107244] [2.062880e-04s per sample]\n",
      "   Avg value loss:   1.147217035293579\n",
      "   Avg policy loss:  0.6239001750946045\n",
      "   Avg total loss:   1.7711172103881836\n",
      "Training [102272/107244] [2.019536e-04s per sample]\n",
      "   Avg value loss:   1.1544044017791748\n",
      "   Avg policy loss:  0.586007297039032\n",
      "   Avg total loss:   1.7404116988182068\n",
      "Training [102400/107244] [2.113990e-04s per sample]\n",
      "   Avg value loss:   1.1360588073730469\n",
      "   Avg policy loss:  0.6142725348472595\n",
      "   Avg total loss:   1.7503313422203064\n",
      "Training [102528/107244] [2.125092e-04s per sample]\n",
      "   Avg value loss:   1.0965901613235474\n",
      "   Avg policy loss:  0.5914828777313232\n",
      "   Avg total loss:   1.6880730390548706\n",
      "Training [102656/107244] [2.012886e-04s per sample]\n",
      "   Avg value loss:   1.086193323135376\n",
      "   Avg policy loss:  0.5854239463806152\n",
      "   Avg total loss:   1.6716172695159912\n",
      "Training [102784/107244] [2.096873e-04s per sample]\n",
      "   Avg value loss:   1.0646131038665771\n",
      "   Avg policy loss:  0.5750905275344849\n",
      "   Avg total loss:   1.639703631401062\n",
      "Training [102912/107244] [2.165865e-04s per sample]\n",
      "   Avg value loss:   1.155360221862793\n",
      "   Avg policy loss:  0.5581068992614746\n",
      "   Avg total loss:   1.7134671211242676\n",
      "Training [103040/107244] [2.268292e-04s per sample]\n",
      "   Avg value loss:   1.1548585891723633\n",
      "   Avg policy loss:  0.5787903070449829\n",
      "   Avg total loss:   1.7336488962173462\n",
      "Training [103168/107244] [2.123527e-04s per sample]\n",
      "   Avg value loss:   1.1906678676605225\n",
      "   Avg policy loss:  0.6165028214454651\n",
      "   Avg total loss:   1.8071706891059875\n",
      "Training [103296/107244] [2.087094e-04s per sample]\n",
      "   Avg value loss:   1.1713629961013794\n",
      "   Avg policy loss:  0.5880261063575745\n",
      "   Avg total loss:   1.7593891024589539\n",
      "Training [103424/107244] [2.084915e-04s per sample]\n",
      "   Avg value loss:   1.1224174499511719\n",
      "   Avg policy loss:  0.5922619700431824\n",
      "   Avg total loss:   1.7146794199943542\n",
      "Training [103552/107244] [2.126005e-04s per sample]\n",
      "   Avg value loss:   1.1085416078567505\n",
      "   Avg policy loss:  0.5724937319755554\n",
      "   Avg total loss:   1.681035339832306\n",
      "Training [103680/107244] [2.198499e-04s per sample]\n",
      "   Avg value loss:   1.1517579555511475\n",
      "   Avg policy loss:  0.6095016002655029\n",
      "   Avg total loss:   1.7612595558166504\n",
      "Training [103808/107244] [2.040453e-04s per sample]\n",
      "   Avg value loss:   1.168636679649353\n",
      "   Avg policy loss:  0.5982013940811157\n",
      "   Avg total loss:   1.7668380737304688\n",
      "Training [103936/107244] [2.095085e-04s per sample]\n",
      "   Avg value loss:   1.1931663751602173\n",
      "   Avg policy loss:  0.5750415921211243\n",
      "   Avg total loss:   1.7682079672813416\n",
      "Training [104064/107244] [2.018753e-04s per sample]\n",
      "   Avg value loss:   1.2196141481399536\n",
      "   Avg policy loss:  0.5987721681594849\n",
      "   Avg total loss:   1.8183863162994385\n",
      "Training [104192/107244] [2.216101e-04s per sample]\n",
      "   Avg value loss:   1.1753160953521729\n",
      "   Avg policy loss:  0.59670090675354\n",
      "   Avg total loss:   1.772017002105713\n",
      "Training [104320/107244] [2.142414e-04s per sample]\n",
      "   Avg value loss:   1.1648709774017334\n",
      "   Avg policy loss:  0.5644481182098389\n",
      "   Avg total loss:   1.7293190956115723\n",
      "Training [104448/107244] [2.136864e-04s per sample]\n",
      "   Avg value loss:   1.1562495231628418\n",
      "   Avg policy loss:  0.5978435277938843\n",
      "   Avg total loss:   1.754093050956726\n",
      "Training [104576/107244] [2.110228e-04s per sample]\n",
      "   Avg value loss:   1.1163959503173828\n",
      "   Avg policy loss:  0.5548434257507324\n",
      "   Avg total loss:   1.6712393760681152\n",
      "Training [104704/107244] [2.061110e-04s per sample]\n",
      "   Avg value loss:   1.1327309608459473\n",
      "   Avg policy loss:  0.5748119950294495\n",
      "   Avg total loss:   1.7075429558753967\n",
      "Training [104832/107244] [2.160482e-04s per sample]\n",
      "   Avg value loss:   1.16070556640625\n",
      "   Avg policy loss:  0.573208212852478\n",
      "   Avg total loss:   1.733913779258728\n",
      "Training [104960/107244] [2.143364e-04s per sample]\n",
      "   Avg value loss:   1.1170504093170166\n",
      "   Avg policy loss:  0.5981486439704895\n",
      "   Avg total loss:   1.715199053287506\n",
      "Training [105088/107244] [2.135243e-04s per sample]\n",
      "   Avg value loss:   1.2327091693878174\n",
      "   Avg policy loss:  0.6110204458236694\n",
      "   Avg total loss:   1.8437296152114868\n",
      "Training [105216/107244] [2.094917e-04s per sample]\n",
      "   Avg value loss:   1.095292329788208\n",
      "   Avg policy loss:  0.590310275554657\n",
      "   Avg total loss:   1.685602605342865\n",
      "Training [105344/107244] [2.159681e-04s per sample]\n",
      "   Avg value loss:   1.155125617980957\n",
      "   Avg policy loss:  0.565838634967804\n",
      "   Avg total loss:   1.720964252948761\n",
      "Training [105472/107244] [2.108775e-04s per sample]\n",
      "   Avg value loss:   1.0601580142974854\n",
      "   Avg policy loss:  0.6045036315917969\n",
      "   Avg total loss:   1.6646616458892822\n",
      "Training [105600/107244] [2.188347e-04s per sample]\n",
      "   Avg value loss:   1.091979742050171\n",
      "   Avg policy loss:  0.5471320152282715\n",
      "   Avg total loss:   1.6391117572784424\n",
      "Training [105728/107244] [2.126191e-04s per sample]\n",
      "   Avg value loss:   1.1839228868484497\n",
      "   Avg policy loss:  0.6047568917274475\n",
      "   Avg total loss:   1.7886797785758972\n",
      "Training [105856/107244] [2.071727e-04s per sample]\n",
      "   Avg value loss:   1.160365343093872\n",
      "   Avg policy loss:  0.5896188020706177\n",
      "   Avg total loss:   1.7499841451644897\n",
      "Training [105984/107244] [2.259761e-04s per sample]\n",
      "   Avg value loss:   1.188197374343872\n",
      "   Avg policy loss:  0.5884673595428467\n",
      "   Avg total loss:   1.7766647338867188\n",
      "Training [106112/107244] [2.047122e-04s per sample]\n",
      "   Avg value loss:   1.1262545585632324\n",
      "   Avg policy loss:  0.5851914882659912\n",
      "   Avg total loss:   1.7114460468292236\n",
      "Training [106240/107244] [2.371259e-04s per sample]\n",
      "   Avg value loss:   1.1046732664108276\n",
      "   Avg policy loss:  0.591685950756073\n",
      "   Avg total loss:   1.6963592171669006\n",
      "Training [106368/107244] [2.092794e-04s per sample]\n",
      "   Avg value loss:   1.2355425357818604\n",
      "   Avg policy loss:  0.5928518772125244\n",
      "   Avg total loss:   1.8283944129943848\n",
      "Training [106496/107244] [2.323762e-04s per sample]\n",
      "   Avg value loss:   1.2435686588287354\n",
      "   Avg policy loss:  0.6128484606742859\n",
      "   Avg total loss:   1.8564171195030212\n",
      "Training [106624/107244] [2.231412e-04s per sample]\n",
      "   Avg value loss:   1.206437349319458\n",
      "   Avg policy loss:  0.5983563661575317\n",
      "   Avg total loss:   1.8047937154769897\n",
      "Training [106752/107244] [2.071243e-04s per sample]\n",
      "   Avg value loss:   1.0851616859436035\n",
      "   Avg policy loss:  0.6183599829673767\n",
      "   Avg total loss:   1.7035216689109802\n",
      "Training [106880/107244] [2.104305e-04s per sample]\n",
      "   Avg value loss:   1.1127822399139404\n",
      "   Avg policy loss:  0.5948957204818726\n",
      "   Avg total loss:   1.707677960395813\n",
      "Training [107008/107244] [2.114922e-04s per sample]\n",
      "   Avg value loss:   1.1371794939041138\n",
      "   Avg policy loss:  0.5759423971176147\n",
      "   Avg total loss:   1.7131218910217285\n",
      "Training [107136/107244] [2.148133e-04s per sample]\n",
      "   Avg value loss:   1.147061824798584\n",
      "   Avg policy loss:  0.5950847268104553\n",
      "   Avg total loss:   1.7421465516090393\n",
      "Training [90504/107244] [2.475911e-04s per sample]\n",
      "   Avg value loss:   1.126315951347351\n",
      "   Avg policy loss:  0.5764843225479126\n",
      "   Avg total loss:   1.7028002738952637\n",
      "Test Error:\n",
      "   Avg value loss:   1.259014021539568\n",
      "   Avg policy loss:  0.6248875311821873\n",
      "   Avg total loss:   1.8839015527217553\n",
      "Smart accuracy:  0.4590260285474391\n",
      "Stupid accuracy:  0.4767422334172964\n"
     ]
    }
   ],
   "source": [
    "epochs = 1\n",
    "test_value_losses = []\n",
    "test_policy_losses = []\n",
    "train_value_losses = []\n",
    "train_policy_losses = []\n",
    "\n",
    "try:\n",
    "    for t in range(epochs):\n",
    "        print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "        _train(train_dataloader, optimizer, model, train_value_losses, train_policy_losses)\n",
    "        _test(test_dataloader, model, test_value_losses, test_policy_losses)\n",
    "except KeyboardInterrupt:\n",
    "    print(\"Training interrupted.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error:\n",
      "   Avg value loss:   1.2244624101445016\n",
      "   Avg policy loss:  0.688874736737524\n",
      "   Avg total loss:   1.9133371468820255\n",
      "Smart accuracy:  0.4673383711167087\n",
      "Stupid accuracy:  0.4767422334172964\n"
     ]
    }
   ],
   "source": [
    "_test(test_dataloader, model, [], [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.17109723 0.2796838  0.2755903  0.2736287 ]]\n",
      "tensor([0., 1., 0., 0.])\n"
     ]
    }
   ],
   "source": [
    "boards, policies, values = test_data\n",
    "\n",
    "# 1000 - pretty good, happy with red, shows green definitely is losing, etc\n",
    "\n",
    "index = 400\n",
    "board, policies, values = boards[index], policies[index], values[index]\n",
    "\n",
    "display = Display(board, overlay_dots=MOVES[\"new_occupieds\"][6188])\n",
    "display.show()\n",
    "\n",
    "values_logits_tensor, policy_logits_tensor = model(board.unsqueeze(0).to(\"mps\"))\n",
    "eval_values = torch.softmax(values_logits_tensor, dim=1).detach().cpu().numpy()\n",
    "policy_logits = policy_logits_tensor.detach().cpu().numpy()\n",
    "\n",
    "print(eval_values)\n",
    "print(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.3196774e-01, 1.7016253e-04, 5.4287713e-02, 1.3574358e-02]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
