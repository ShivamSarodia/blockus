{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded config:  {\"development\": {\"debug_mode\": true, \"profile\": false, \"runtime\": 72000, \"display_logs_in_console\": false, \"output_directory\": \"data/2024-11-24_00-18-45-literatist\"}, \"logging\": {\"save_interval\": 3600, \"mcts_report_fraction\": 0, \"ucb_report\": false, \"gpu_evaluation\": true, \"made_move\": true}, \"game\": {\"board_size\": 10, \"num_moves\": 6233, \"moves_directory\": \"../data/moves_10\"}, \"architecture\": {\"gameplay_processes\": 6, \"coroutines_per_process\": 256, \"game_flush_threshold\": 200}, \"training\": {\"run\": true, \"network_name\": \"default\", \"batch_size\": 64, \"policy_loss_weight\": 0.158, \"learning_rate\": 0.001, \"sample_window\": 50000, \"samples_per_generation\": 10000, \"sampling_ratio\": 1.0, \"sampling_delay\": 10000, \"new_data_check_interval\": 30}, \"networks\": {\"default\": {\"main_body_channels\": 64, \"value_head_channels\": 16, \"value_head_flat_layer_width\": 64, \"policy_head_channels\": 64, \"residual_blocks\": 8, \"model_path\": \"\", \"model_directory\": \"data/2024-11-24_00-18-45-literatist/models/\", \"new_model_check_interval\": 120, \"batch_size\": 128}}, \"agents\": [{\"type\": \"mcts\", \"network\": \"default\", \"full_move_probability\": 0.2, \"full_move_rollouts\": 500, \"fast_move_rollouts\": 100, \"ucb_exploration\": 1.4, \"total_dirichlet_alpha\": 10.83, \"root_exploration_fraction\": 0.25, \"name\": \"default\"}, {\"type\": \"mcts\", \"network\": \"default\", \"full_move_probability\": 0.2, \"full_move_rollouts\": 500, \"fast_move_rollouts\": 100, \"ucb_exploration\": 1.4, \"total_dirichlet_alpha\": 10.83, \"root_exploration_fraction\": 0.25, \"name\": \"default\"}, {\"type\": \"mcts\", \"network\": \"default\", \"full_move_probability\": 0.2, \"full_move_rollouts\": 500, \"fast_move_rollouts\": 100, \"ucb_exploration\": 1.4, \"total_dirichlet_alpha\": 10.83, \"root_exploration_fraction\": 0.25, \"name\": \"default\"}, {\"type\": \"mcts\", \"network\": \"default\", \"full_move_probability\": 0.2, \"full_move_rollouts\": 500, \"fast_move_rollouts\": 100, \"ucb_exploration\": 1.4, \"total_dirichlet_alpha\": 10.83, \"root_exploration_fraction\": 0.25, \"name\": \"default\"}]}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import aim\n",
    "\n",
    "os.environ[\"CONFIG_PATHS\"] = \"../configs/self_play.yaml\"\n",
    "os.environ[\"CONFIG_OVERRIDES\"] = 'game.moves_directory=\"../data/moves_10\"'\n",
    "sys.path.append(\"../src\")\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from display import Display\n",
    "from configuration import moves_data, config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neural_net import NeuralNet\n",
    "from training.load_games import load_old_format_games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading file: piece_indices\n",
      "Loading file: rotation_mapping\n",
      "Loading file: new_occupieds\n",
      "Loading file: moves_ruled_out_for_all\n",
      "Loading file: scores\n",
      "Loading file: moves_ruled_out_for_player\n",
      "Loading file: moves_enabled_for_player\n",
      "Loading file: new_adjacents\n",
      "Loading file: new_corners\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 64\n",
    "DEVICE = \"mps\"\n",
    "MOVES = moves_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "GAMES_DIR = \"../data/2024-11-23_00-37-50-doublehandedness/games\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "game_paths = [\n",
    "    os.path.join(GAMES_DIR, f)\n",
    "    for f in os.listdir(GAMES_DIR)\n",
    "]\n",
    "\n",
    "# Train on first 3/4, test on last 1/4.\n",
    "train_path_index_cutoff = 3 * len(game_paths) // 4\n",
    "\n",
    "train_paths = sorted(game_paths)[:train_path_index_cutoff]\n",
    "test_paths = sorted(game_paths)[train_path_index_cutoff:]\n",
    "\n",
    "def paths_to_dataloader(paths):\n",
    "    boards, policies, values = load_old_format_games(paths)\n",
    "    dataset = TensorDataset(\n",
    "        torch.Tensor(boards),\n",
    "        torch.Tensor(policies),\n",
    "        torch.Tensor(values),\n",
    "    )\n",
    "    return DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "train_dataloader = paths_to_dataloader(train_paths)\n",
    "test_dataloader = paths_to_dataloader(test_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run = aim.Run(repo='/tmp/.aim')\n",
    "\n",
    "model = NeuralNet(config()[\"networks\"][\"default\"]).to(DEVICE)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "for batch_index, (boards, policies, values) in tqdm(enumerate(train_dataloader)):\n",
    "    boards = boards.to(DEVICE)\n",
    "    policies = policies.to(DEVICE)\n",
    "    values = values.to(DEVICE)\n",
    "\n",
    "    pred_values, pred_policy = model(boards)\n",
    "    value_loss = nn.CrossEntropyLoss()(\n",
    "        pred_values,\n",
    "        values,\n",
    "    )\n",
    "    policy_loss = 0.158 * nn.CrossEntropyLoss()(\n",
    "        pred_policy,\n",
    "        policies,\n",
    "    )\n",
    "    loss = value_loss + policy_loss\n",
    "\n",
    "    run.track(\n",
    "        value_loss.item(),\n",
    "        name=\"value_loss\",\n",
    "        step=batch_index,\n",
    "    )\n",
    "    run.track(\n",
    "        policy_loss.item(),\n",
    "        name=\"policy_loss\",\n",
    "        step=batch_index,\n",
    "    )\n",
    "    run.track(\n",
    "        loss.item(),\n",
    "        name=\"total_loss\",\n",
    "        step=batch_index,\n",
    "    )\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "run.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5316it [00:47, 112.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9206433480421882\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "value_losses = []\n",
    "policy_losses = []\n",
    "total_losses = []\n",
    "\n",
    "for batch_index, (boards, policies, values) in tqdm(enumerate(test_dataloader)):\n",
    "    pred_values, pred_policy = model(boards)\n",
    "    value_loss = nn.CrossEntropyLoss()(\n",
    "        pred_values,\n",
    "        values,\n",
    "    )\n",
    "    policy_loss = 0.158 * nn.CrossEntropyLoss()(\n",
    "        pred_policy,\n",
    "        policies,\n",
    "    )\n",
    "    loss = value_loss + policy_loss\n",
    "\n",
    "    value_losses.append(value_loss.item())\n",
    "    policy_losses.append(policy_loss.item())\n",
    "    total_losses.append(loss.item())\n",
    "\n",
    "print(\"Average value loss: \", sum(value_losses) / len(value_losses))\n",
    "print(\"Average policy loss: \", sum(policy_losses) / len(policy_losses))\n",
    "print(\"Average total loss: \", sum(total_losses) / len(total_losses))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
