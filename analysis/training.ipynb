{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded config:  {\"development\": {\"debug_mode\": true, \"profile\": false, \"runtime\": 0, \"display_logs_in_console\": false, \"output_directory\": \"data/2024-12-06_00-09-14-self-play-for-policy-weight-one\"}, \"logging\": {\"save_interval\": 3600, \"mcts_report_fraction\": 0, \"ucb_report\": false, \"gpu_evaluation\": true, \"made_move\": true}, \"game\": {\"board_size\": 10, \"num_moves\": 6233, \"num_pieces\": 21, \"moves_directory\": \"../data/moves_10\"}, \"architecture\": {\"gameplay_processes\": 6, \"coroutines_per_process\": 256, \"game_flush_threshold\": 200}, \"training\": {\"run\": true, \"network_name\": \"default\", \"batch_size\": 64, \"policy_loss_weight\": 1.0, \"learning_rate\": 0.001, \"sample_window\": 50000, \"samples_per_generation\": 10000, \"sampling_ratio\": 2.0, \"minimum_window_size\": 10000, \"new_data_check_interval\": 60}, \"networks\": {\"default\": {\"main_body_channels\": 64, \"value_head_channels\": 16, \"value_head_flat_layer_width\": 64, \"policy_head_channels\": 64, \"residual_blocks\": 8, \"model_path\": \"\", \"model_directory\": \"data/2024-12-06_00-09-14-self-play-for-policy-weight-one/models/\", \"new_model_check_interval\": 120, \"batch_size\": 128}}, \"agents\": [{\"type\": \"mcts\", \"network\": \"default\", \"full_move_probability\": 0.2, \"full_move_rollouts\": 500, \"fast_move_rollouts\": 100, \"ucb_exploration\": 1.4, \"total_dirichlet_alpha\": 10.83, \"root_exploration_fraction\": 0.25, \"move_selection_temperature\": 1.0, \"name\": \"default\"}, {\"type\": \"mcts\", \"network\": \"default\", \"full_move_probability\": 0.2, \"full_move_rollouts\": 500, \"fast_move_rollouts\": 100, \"ucb_exploration\": 1.4, \"total_dirichlet_alpha\": 10.83, \"root_exploration_fraction\": 0.25, \"move_selection_temperature\": 1.0, \"name\": \"default\"}, {\"type\": \"mcts\", \"network\": \"default\", \"full_move_probability\": 0.2, \"full_move_rollouts\": 500, \"fast_move_rollouts\": 100, \"ucb_exploration\": 1.4, \"total_dirichlet_alpha\": 10.83, \"root_exploration_fraction\": 0.25, \"move_selection_temperature\": 1.0, \"name\": \"default\"}, {\"type\": \"mcts\", \"network\": \"default\", \"full_move_probability\": 0.2, \"full_move_rollouts\": 500, \"fast_move_rollouts\": 100, \"ucb_exploration\": 1.4, \"total_dirichlet_alpha\": 10.83, \"root_exploration_fraction\": 0.25, \"move_selection_temperature\": 1.0, \"name\": \"default\"}]}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import aim\n",
    "\n",
    "os.environ[\"CONFIG_PATHS\"] = \"../configs/self_play.yaml\"\n",
    "os.environ[\"CONFIG_OVERRIDES\"] = 'game.moves_directory=\"../data/moves_10\"'\n",
    "sys.path.append(\"../src\")\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from tqdm import tqdm\n",
    "import glob\n",
    "import time\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from display import Display\n",
    "from configuration import moves_data, config\n",
    "from training.actor import TrainingActor\n",
    "import training.helpers\n",
    "from training.load_games import load_games_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neural_net import NeuralNet\n",
    "from training.game_data_manager import GameDataManager, DirectoryGameDataPathFetcher, CustomGameDataPathFetcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "NETWORK_CONFIG = config()[\"networks\"][\"default\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading file: piece_indices\n",
      "Loading file: rotation_mapping\n",
      "Loading file: new_occupieds\n",
      "Loading file: moves_ruled_out_for_all\n",
      "Loading file: scores\n",
      "Loading file: moves_ruled_out_for_player\n",
      "Loading file: moves_enabled_for_player\n",
      "Loading file: new_adjacents\n",
      "Loading file: new_corners\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 64\n",
    "DEVICE = \"mps\"\n",
    "MOVES = moves_data()\n",
    "GAMES_DIR = \"../data/2024-11-23_00-37-50-doublehandedness/games\"\n",
    "WINDOW_SIZE = 50000\n",
    "MINIMUM_WINDOW_SIZE = 10000\n",
    "POLICY_LOSS_WEIGHT = 0.158\n",
    "LEARNING_RATE = 1e-3\n",
    "SAMPLING_RATIO = 2.0\n",
    "SAMPLES_PER_GENERATION = 100000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "gamedata_path_fetcher = DirectoryGameDataPathFetcher(GAMES_DIR)\n",
    "game_data_manager = GameDataManager(gamedata_path_fetcher, 50000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NeuralNet(NETWORK_CONFIG)\n",
    "model.to(DEVICE)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Window size:  10000\n",
      "Cumulative window fed:  10000\n"
     ]
    }
   ],
   "source": [
    "training.helpers.feed_window_until_amount(\n",
    "    game_data_manager,\n",
    "    MINIMUM_WINDOW_SIZE,\n",
    "    1e6,\n",
    ")\n",
    "print(\"Window size: \", game_data_manager.current_window_size())\n",
    "print(\"Cumulative window fed: \", game_data_manager.cumulative_window_fed())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(cumulative_window_fed, model):\n",
    "    model_name = str(cumulative_window_fed).zfill(9)\n",
    "    model_path = os.path.join(\n",
    "        \"/Users/shivamsarodia/Dev/blockus/data/2024-12-02_21-22-57-notebook-models/sample_ratio_two_partials/\",\n",
    "        f\"{model_name}.pt\",\n",
    "    )\n",
    "    torch.save(model.state_dict(), model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 1490016/1500000 [49:52<00:20, 497.88it/s] \n"
     ]
    }
   ],
   "source": [
    "max_samples_to_train_on = 1500000\n",
    "\n",
    "run = aim.Run(repo='/tmp/.aim')\n",
    "pbar = tqdm(total=max_samples_to_train_on)\n",
    "\n",
    "model.train()\n",
    "\n",
    "previous_cumulative_window_fed = game_data_manager.cumulative_window_fed()\n",
    "\n",
    "batch_index = 0\n",
    "while True:\n",
    "    # if batch_index % 100 == 0:\n",
    "    #     print(f\"Batch {batch_index}, window size {game_data_manager.current_window_size()}, cumulative window fed {game_data_manager.cumulative_window_fed()}\")\n",
    "\n",
    "    training_result = training.helpers.loop_iteration(\n",
    "        model,\n",
    "        optimizer,\n",
    "        game_data_manager,\n",
    "        device=DEVICE,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        sampling_ratio=SAMPLING_RATIO,\n",
    "        policy_loss_weight=POLICY_LOSS_WEIGHT,\n",
    "    )\n",
    "    if not training_result:\n",
    "        break\n",
    "\n",
    "    pbar.update(training_result[\"ingestion_count\"])\n",
    "\n",
    "    for key, value in training_result.items():\n",
    "        run.track(\n",
    "            value,\n",
    "            name=key,\n",
    "            step=batch_index,\n",
    "        )\n",
    "    batch_index += 1\n",
    "\n",
    "    cumulative_window_fed = training_result[\"cumulative_window_fed\"]\n",
    "    if cumulative_window_fed > max_samples_to_train_on:\n",
    "        break\n",
    "\n",
    "    if cumulative_window_fed // SAMPLES_PER_GENERATION > previous_cumulative_window_fed // SAMPLES_PER_GENERATION:\n",
    "        save_model(cumulative_window_fed, model)\n",
    "\n",
    "    previous_cumulative_window_fed = cumulative_window_fed\n",
    "\n",
    "save_model(cumulative_window_fed, model)\n",
    "\n",
    "pbar.close()\n",
    "run.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(model.state_dict(), \"../data/2024-12-02_21-22-57-notebook-models/sample_ratio_two_2.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pbar.close()\n",
    "run.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load models\n",
    "def load_model(path):\n",
    "    model = NeuralNet(NETWORK_CONFIG)\n",
    "    model.load_state_dict(torch.load(path, weights_only=True))\n",
    "    model.to(DEVICE)\n",
    "    return model\n",
    "\n",
    "# base_model_1 = load_model(\"/Users/shivamsarodia/Dev/blockus/data/2024-12-02_21-22-57-notebook-models/base_in_notebook_1.pt\")\n",
    "base_model_2 = load_model(\"/Users/shivamsarodia/Dev/blockus/data/2024-12-02_21-22-57-notebook-models/base_in_notebook_2.pt\")\n",
    "# ratio_two_model_1 = load_model(\"/Users/shivamsarodia/Dev/blockus/data/2024-12-02_21-22-57-notebook-models/sample_ratio_two_1.pt\")\n",
    "ratio_two_model_2 = load_model(\"/Users/shivamsarodia/Dev/blockus/data/2024-12-02_21-22-57-notebook-models/sample_ratio_two_2.pt\")\n",
    "\n",
    "# print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 276/276 [00:05<00:00, 47.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting to tensors...\n"
     ]
    }
   ],
   "source": [
    "test_game_files = glob.glob(\"/Users/shivamsarodia/Dev/blockus/data/2024-11-23_00-37-50-doublehandedness/more_games_we_didnt_train_on/*.npz\")\n",
    "test_gamedata = load_games_new(test_game_files, with_tqdm=True)\n",
    "\n",
    "print(\"Converting to tensors...\")\n",
    "\n",
    "# Convert numpy arrays to torch tensors\n",
    "boards_tensor = torch.from_numpy(test_gamedata[\"boards\"]).to(dtype=torch.float, device=\"mps\")\n",
    "policies_tensor = torch.from_numpy(test_gamedata[\"policies\"]).to(dtype=torch.float, device=\"mps\")\n",
    "values_tensor = torch.from_numpy(test_gamedata[\"values\"]).to(dtype=torch.float, device=\"mps\")\n",
    "valid_moves = torch.from_numpy(test_gamedata[\"valid_moves\"]).to(dtype=torch.bool, device=\"mps\")\n",
    "\n",
    "dataset = torch.utils.data.TensorDataset(boards_tensor, policies_tensor, values_tensor, valid_moves)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_losses(model):\n",
    "    batch_size = 64\n",
    "    dataloader = torch.utils.data.DataLoader(\n",
    "        dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "    )\n",
    "    model.eval()\n",
    "\n",
    "    results = {\n",
    "        \"loss_total\": 0,\n",
    "        \"loss_value\": 0,\n",
    "        \"loss_policy\": 0,\n",
    "        \"value_max_correct\": 0,\n",
    "        \"policy_max_correct\": 0,\n",
    "    }\n",
    "\n",
    "    total_sample_count = 0\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        for batch_index, (boards, policies, values, valid_moves) in enumerate(tqdm(dataloader)):\n",
    "            pred_values, pred_policy_logits = model(boards.to(dtype=torch.float32))\n",
    "            value_loss = nn.CrossEntropyLoss()(\n",
    "                pred_values,\n",
    "                values,\n",
    "            )\n",
    "\n",
    "            policy_loss = nn.CrossEntropyLoss()(\n",
    "                pred_policy_logits,\n",
    "                policies,\n",
    "            )\n",
    "            loss = value_loss + POLICY_LOSS_WEIGHT * policy_loss\n",
    "\n",
    "            results[\"loss_total\"] += loss.item()\n",
    "            results[\"loss_value\"] += value_loss.item()\n",
    "            results[\"loss_policy\"] += policy_loss.item()\n",
    "            results[\"value_max_correct\"] += (pred_values.argmax(dim=1) == values.argmax(dim=1)).sum().item()\n",
    "            results[\"policy_max_correct\"] += (pred_policy_logits.argmax(dim=1) == policies.argmax(dim=1)).sum().item()\n",
    "\n",
    "            total_sample_count += len(boards)\n",
    "\n",
    "    results[\"loss_total\"] /= total_sample_count\n",
    "    results[\"loss_value\"] /= total_sample_count\n",
    "    results[\"loss_policy\"] /= total_sample_count\n",
    "    results[\"value_max_correct\"] /= total_sample_count\n",
    "    results[\"policy_max_correct\"] /= total_sample_count\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5261/5261 [00:52<00:00, 100.32it/s]\n",
      "100%|██████████| 5261/5261 [00:52<00:00, 100.31it/s]\n"
     ]
    }
   ],
   "source": [
    "# base_model_1_test_result = get_test_losses(base_model_1)\n",
    "base_model_2_test_result = get_test_losses(base_model_2)\n",
    "# ratio_two_model_1_test_result = get_test_losses(ratio_two_model_1)\n",
    "ratio_two_model_2_test_result = get_test_losses(ratio_two_model_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "241365"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_gamedata[\"boards\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1078038"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "241365 + 336673 + 500000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss_total': 0.019015346798564505,\n",
       " 'loss_value': 0.015089419780530288,\n",
       " 'loss_policy': 0.024847638171400108,\n",
       " 'value_max_correct': 0.5920462882381421,\n",
       " 'policy_max_correct': 0.7863327323545398}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_model_2_test_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss_total': 0.019214975594640738,\n",
       " 'loss_value': 0.015309898972442953,\n",
       " 'loss_policy': 0.02471567374811644,\n",
       " 'value_max_correct': 0.5672061614682496,\n",
       " 'policy_max_correct': 0.7846664270672136}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratio_two_model_2_test_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def range_of_boolean_var(p):\n",
    "    standard_error = np.sqrt(p * (1 - p) / len(dataset))\n",
    "    return p + 2 * standard_error, p - 2 * standard_error\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create figure with two subplots\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(10, 8))\n",
    "\n",
    "models = ['Base 1', 'Base 2', 'Ratio Two 1', 'Ratio Two 2']\n",
    "\n",
    "# Value accuracy plot\n",
    "value_accuracies = [\n",
    "    base_model_1_test_result[\"value_max_correct\"],\n",
    "    base_model_2_test_result[\"value_max_correct\"], \n",
    "    ratio_two_model_1_test_result[\"value_max_correct\"],\n",
    "    ratio_two_model_2_test_result[\"value_max_correct\"]\n",
    "]\n",
    "value_errors = [range_of_boolean_var(acc) for acc in value_accuracies]\n",
    "value_upper = [err[0] - acc for acc, err in zip(value_accuracies, value_errors)]\n",
    "value_lower = [acc - err[1] for acc, err in zip(value_accuracies, value_errors)]\n",
    "\n",
    "ax1.bar(models, value_accuracies, yerr=[value_lower, value_upper], capsize=5)\n",
    "ax1.set_title('Value Prediction Accuracy')\n",
    "ax1.set_ylabel('Accuracy')\n",
    "ax1.set_ylim(bottom=min(value_accuracies) * 0.95)  # Set bottom to 95% of minimum value\n",
    "\n",
    "# Policy accuracy plot  \n",
    "policy_accuracies = [\n",
    "    base_model_1_test_result[\"policy_max_correct\"],\n",
    "    base_model_2_test_result[\"policy_max_correct\"],\n",
    "    ratio_two_model_1_test_result[\"policy_max_correct\"], \n",
    "    ratio_two_model_2_test_result[\"policy_max_correct\"]\n",
    "]\n",
    "policy_errors = [range_of_boolean_var(acc) for acc in policy_accuracies]\n",
    "policy_upper = [err[0] - acc for acc, err in zip(policy_accuracies, policy_errors)]\n",
    "policy_lower = [acc - err[1] for acc, err in zip(policy_accuracies, policy_errors)]\n",
    "\n",
    "ax2.bar(models, policy_accuracies, yerr=[policy_lower, policy_upper], capsize=5)\n",
    "ax2.set_title('Policy Prediction Accuracy')\n",
    "ax2.set_ylabel('Accuracy')\n",
    "ax2.set_ylim(bottom=min(policy_accuracies) * 0.95)  # Set bottom to 95% of minimum value\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Base model 1\")\n",
    "print(base_model_1_test_result)\n",
    "print(\"Base model 2\")\n",
    "print(base_model_2_test_result)\n",
    "print(\"Ratio two model 1\")\n",
    "print(ratio_two_model_1_test_result)\n",
    "print(\"Ratio two model 2\")\n",
    "print(ratio_two_model_2_test_result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
