{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded config:  {\"development\": {\"debug_mode\": true, \"profile\": false, \"runtime\": 0, \"display_logs_in_console\": false, \"output_directory\": \"data/2024-11-23_00-37-50-doublehandedness\"}, \"logging\": {\"save_interval\": 3600, \"mcts_report_fraction\": 0, \"ucb_report\": false, \"gpu_evaluation\": true, \"made_move\": true}, \"game\": {\"board_size\": 10, \"num_moves\": 6233, \"num_pieces\": 21, \"moves_directory\": \"../data/moves_10\"}, \"architecture\": {\"gameplay_processes\": 6, \"coroutines_per_process\": 256, \"game_flush_threshold\": 200}, \"training\": {\"run\": true, \"network_name\": \"default\", \"batch_size\": 64, \"policy_loss_weight\": 0.158, \"learning_rate\": 0.001, \"sample_window\": 50000, \"samples_per_generation\": 10000, \"sampling_ratio\": 1.0, \"minimum_window_size\": 10000, \"new_data_check_interval\": 60}, \"networks\": {\"default\": {\"main_body_channels\": 64, \"value_head_channels\": 16, \"value_head_flat_layer_width\": 64, \"policy_head_channels\": 64, \"residual_blocks\": 8, \"model_path\": \"\", \"model_directory\": \"data/2024-11-23_00-37-50-doublehandedness/models/\", \"new_model_check_interval\": 120, \"batch_size\": 128}}, \"agents\": [{\"type\": \"mcts\", \"network\": \"default\", \"full_move_probability\": 0.2, \"full_move_rollouts\": 500, \"fast_move_rollouts\": 100, \"ucb_exploration\": 1.4, \"total_dirichlet_alpha\": 10.83, \"root_exploration_fraction\": 0.25, \"name\": \"default\"}, {\"type\": \"mcts\", \"network\": \"default\", \"full_move_probability\": 0.2, \"full_move_rollouts\": 500, \"fast_move_rollouts\": 100, \"ucb_exploration\": 1.4, \"total_dirichlet_alpha\": 10.83, \"root_exploration_fraction\": 0.25, \"name\": \"default\"}, {\"type\": \"mcts\", \"network\": \"default\", \"full_move_probability\": 0.2, \"full_move_rollouts\": 500, \"fast_move_rollouts\": 100, \"ucb_exploration\": 1.4, \"total_dirichlet_alpha\": 10.83, \"root_exploration_fraction\": 0.25, \"name\": \"default\"}, {\"type\": \"mcts\", \"network\": \"default\", \"full_move_probability\": 0.2, \"full_move_rollouts\": 500, \"fast_move_rollouts\": 100, \"ucb_exploration\": 1.4, \"total_dirichlet_alpha\": 10.83, \"root_exploration_fraction\": 0.25, \"name\": \"default\"}]}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import aim\n",
    "\n",
    "os.environ[\"CONFIG_PATHS\"] = \"../configs/self_play.yaml\"\n",
    "os.environ[\"CONFIG_OVERRIDES\"] = 'game.moves_directory=\"../data/moves_10\"'\n",
    "sys.path.append(\"../src\")\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from tqdm import tqdm\n",
    "import glob\n",
    "import time\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from display import Display\n",
    "from configuration import moves_data, config\n",
    "from training.actor import TrainingActor\n",
    "import training.helpers\n",
    "from training.load_games import load_games_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neural_net import NeuralNet\n",
    "from training.game_data_manager import GameDataManager, DirectoryGameDataPathFetcher, CustomGameDataPathFetcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "NETWORK_CONFIG = config()[\"networks\"][\"default\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading file: piece_indices\n",
      "Loading file: rotation_mapping\n",
      "Loading file: new_occupieds\n",
      "Loading file: moves_ruled_out_for_all\n",
      "Loading file: scores\n",
      "Loading file: moves_ruled_out_for_player\n",
      "Loading file: moves_enabled_for_player\n",
      "Loading file: new_adjacents\n",
      "Loading file: new_corners\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 64\n",
    "DEVICE = \"mps\"\n",
    "MOVES = moves_data()\n",
    "GAMES_DIR = \"../data/2024-11-23_00-37-50-doublehandedness/games\"\n",
    "WINDOW_SIZE = 50000\n",
    "MINIMUM_WINDOW_SIZE = 10000\n",
    "POLICY_LOSS_WEIGHT = 0.158\n",
    "LEARNING_RATE = 1e-3\n",
    "SAMPLING_RATIO = 2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "gamedata_path_fetcher = DirectoryGameDataPathFetcher(GAMES_DIR)\n",
    "game_data_manager = GameDataManager(gamedata_path_fetcher, 50000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NeuralNet(NETWORK_CONFIG)\n",
    "model.to(DEVICE)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Window size:  10000\n",
      "Cumulative window fed:  10000\n"
     ]
    }
   ],
   "source": [
    "training.helpers.feed_window_until_amount(\n",
    "    game_data_manager,\n",
    "    MINIMUM_WINDOW_SIZE,\n",
    "    1e6,\n",
    ")\n",
    "print(\"Window size: \", game_data_manager.current_window_size())\n",
    "print(\"Cumulative window fed: \", game_data_manager.cumulative_window_fed())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2195712it [1:10:52, 516.39it/s]                             \n"
     ]
    }
   ],
   "source": [
    "run = aim.Run(repo='/tmp/.aim')\n",
    "pbar = tqdm(total=2190000)\n",
    "\n",
    "model.train()\n",
    "\n",
    "batch_index = 0\n",
    "while True:\n",
    "    # if batch_index % 100 == 0:\n",
    "    #     print(f\"Batch {batch_index}, window size {game_data_manager.current_window_size()}, cumulative window fed {game_data_manager.cumulative_window_fed()}\")\n",
    "\n",
    "    training_result = training.helpers.loop_iteration(\n",
    "        model,\n",
    "        optimizer,\n",
    "        game_data_manager,\n",
    "        device=DEVICE,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        sampling_ratio=SAMPLING_RATIO,\n",
    "        policy_loss_weight=POLICY_LOSS_WEIGHT,\n",
    "    )\n",
    "    if not training_result:\n",
    "        break\n",
    "\n",
    "    pbar.update(training_result[\"ingestion_count\"])\n",
    "\n",
    "    for key, value in training_result.items():\n",
    "        run.track(\n",
    "            value,\n",
    "            name=key,\n",
    "            step=batch_index,\n",
    "        )\n",
    "    batch_index += 1\n",
    "\n",
    "pbar.close()\n",
    "run.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"../data/2024-12-02_21-22-57-notebook-models/sample_ratio_two_2.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pbar.close()\n",
    "run.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load models\n",
    "def load_model(path):\n",
    "    model = NeuralNet(NETWORK_CONFIG)\n",
    "    model.load_state_dict(torch.load(path, weights_only=True))\n",
    "    model.to(DEVICE)\n",
    "    return model\n",
    "\n",
    "# base_model = load_model(\"/Users/shivamsarodia/Dev/blockus/data/2024-12-02_21-22-57-notebook-models/base_in_notebook_1.pt\")\n",
    "\n",
    "# policy_weight_one_model = NeuralNet(NETWORK_CONFIG)\n",
    "# policy_weight_one_model.load_state_dict(torch.load(\"/Users/shivamsarodia/Dev/blockus/data/2024-12-02_21-22-57-notebook-models/policy_weight_of_one_1.pt\", weights_only=True))\n",
    "# policy_weight_one_model.to(DEVICE)\n",
    "\n",
    "# print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 384/384 [00:08<00:00, 47.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting to tensors...\n"
     ]
    }
   ],
   "source": [
    "test_game_files = glob.glob(\"/Users/shivamsarodia/Dev/blockus/data/2024-11-23_00-37-50-doublehandedness/games_we_didnt_train_on/*.npz\")\n",
    "test_gamedata = load_games_new(test_game_files, with_tqdm=True)\n",
    "\n",
    "print(\"Converting to tensors...\")\n",
    "\n",
    "# Convert numpy arrays to torch tensors\n",
    "boards_tensor = torch.from_numpy(test_gamedata[\"boards\"]).to(dtype=torch.float, device=\"mps\")\n",
    "policies_tensor = torch.from_numpy(test_gamedata[\"policies\"]).to(dtype=torch.float, device=\"mps\")\n",
    "values_tensor = torch.from_numpy(test_gamedata[\"values\"]).to(dtype=torch.float, device=\"mps\")\n",
    "valid_moves = torch.from_numpy(test_gamedata[\"valid_moves\"]).to(dtype=torch.bool, device=\"mps\")\n",
    "\n",
    "dataset = torch.utils.data.TensorDataset(boards_tensor, policies_tensor, values_tensor, valid_moves)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_losses(model):\n",
    "    batch_size = 64\n",
    "    dataloader = torch.utils.data.DataLoader(\n",
    "        dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "    )\n",
    "    model.eval()\n",
    "\n",
    "    losses = {\n",
    "        \"total\": 0,\n",
    "        \"value\": 0,\n",
    "        \"policy\": 0,\n",
    "    }\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        for batch_index, (boards, policies, values, valid_moves) in enumerate(tqdm(dataloader)):\n",
    "            pred_values, pred_policy_logits = model(boards)\n",
    "            value_loss = nn.CrossEntropyLoss()(\n",
    "                pred_values,\n",
    "                values,\n",
    "            )\n",
    "\n",
    "            policy_loss = nn.CrossEntropyLoss()(\n",
    "                pred_policy_logits,\n",
    "                policies,\n",
    "            )\n",
    "            loss = value_loss + POLICY_LOSS_WEIGHT * policy_loss\n",
    "\n",
    "            losses[\"total\"] += loss.item()\n",
    "            losses[\"value\"] += value_loss.item()\n",
    "            losses[\"policy\"] += policy_loss.item()\n",
    "\n",
    "    return losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5261/5261 [01:22<00:00, 63.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'total': 6469.176969707012, 'value': 5154.445533156395, 'policy': 8321.084671974182}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "print(get_test_losses(model))\n",
    "# print(get_test_losses(load_model(\"/Users/shivamsarodia/Dev/blockus/data/2024-12-02_21-22-57-notebook-models/base_in_notebook_1.pt\")))\n",
    "# print(get_test_losses(load_model(\"/Users/shivamsarodia/Dev/blockus/data/2024-12-02_21-22-57-notebook-models/base_in_notebook_2.pt\")))\n",
    "# print(get_test_losses(load_model(\"/Users/shivamsarodia/Dev/blockus/data/2024-12-02_21-22-57-notebook-models/base_in_notebook_3.pt\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.2501, device='mps:0')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adj_pred_policy_logits = torch.ones_like(pred_policy_logits) * -500\n",
    "adj_pred_policy_logits[valid_moves] = pred_policy_logits[valid_moves]\n",
    "\n",
    "POLICY_LOSS_WEIGHT * nn.CrossEntropyLoss(reduction=\"mean\")(\n",
    "    adj_pred_policy_logits,\n",
    "    policies,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
