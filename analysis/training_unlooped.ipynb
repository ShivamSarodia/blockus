{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import aim\n",
    "import glob\n",
    "import random\n",
    "\n",
    "os.environ[\"CONFIG_PATHS\"] = \"../configs/training_unlooped.yaml\"\n",
    "os.environ[\"CONFIG_OVERRIDES\"] = 'game.moves_directory=\"../data/moves_10\"'\n",
    "sys.path.append(\"../src\")\n",
    "\n",
    "import numpy as np\n",
    "import torch \n",
    "from torch import nn\n",
    "from tqdm import tqdm\n",
    "from torch.amp import GradScaler, autocast\n",
    "import glob\n",
    "import time\n",
    "from configuration import moves_data, config\n",
    "from training.load_games import load_games_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded config:  {\"game\": {\"board_size\": 10, \"num_moves\": 6233, \"num_pieces\": 21, \"moves_directory\": \"../data/moves_10\"}, \"training\": {\"batch_size\": 128, \"policy_loss_weight\": 0.158, \"learning_rate\": 0.001}, \"networks\": {\"default\": {\"main_body_channels\": 64, \"value_head_channels\": 16, \"value_head_flat_layer_width\": 64, \"policy_head_channels\": 64, \"residual_blocks\": 8}}, \"agents\": []}\n"
     ]
    }
   ],
   "source": [
    "from neural_net import NeuralNet\n",
    "from training.game_data_manager import GameDataManager, DirectoryGameDataPathFetcher, CustomGameDataPathFetcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "NETWORK_CONFIG = config()[\"networks\"][\"default\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading file: piece_indices\n",
      "Loading file: rotation_mapping\n",
      "Loading file: new_occupieds\n",
      "Loading file: moves_ruled_out_for_all\n",
      "Loading file: scores\n",
      "Loading file: moves_ruled_out_for_player\n",
      "Loading file: moves_enabled_for_player\n",
      "Loading file: new_adjacents\n",
      "Loading file: new_corners\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 128\n",
    "DEVICE = \"cpu\"\n",
    "MOVES = moves_data()\n",
    "GAMES_DIR = \"../data/2024-11-23_00-37-50-doublehandedness/games\"\n",
    "POLICY_LOSS_WEIGHT = 0.158\n",
    "LEARNING_RATE = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NeuralNet(NETWORK_CONFIG)\n",
    "model.to(DEVICE)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_losses(model, test_dataset):\n",
    "    dataloader = torch.utils.data.DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=True,\n",
    "    )\n",
    "    model.eval()\n",
    "\n",
    "    results = {\n",
    "        \"total_loss\": 0,\n",
    "        \"value_loss\": 0,\n",
    "        \"policy_loss\": 0,\n",
    "        \"value_max_correct\": 0,\n",
    "        \"policy_max_correct\": 0,\n",
    "    }\n",
    "\n",
    "    total_sample_count = 0\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        for boards, policies, values in dataloader:\n",
    "            boards = boards.to(dtype=torch.float32, device=DEVICE)\n",
    "            policies = policies.to(dtype=torch.float32, device=DEVICE)\n",
    "            values = values.to(dtype=torch.float32, device=DEVICE)\n",
    "\n",
    "            pred_values, pred_policy_logits = model(boards)\n",
    "\n",
    "            value_loss = nn.CrossEntropyLoss(reduction=\"sum\")(\n",
    "                pred_values,\n",
    "                values,\n",
    "            )\n",
    "            policy_loss = nn.CrossEntropyLoss(reduction=\"sum\")(\n",
    "                pred_policy_logits,\n",
    "                policies,\n",
    "            )\n",
    "            loss = value_loss + POLICY_LOSS_WEIGHT * policy_loss\n",
    "\n",
    "            results[\"total_loss\"] += loss.item()\n",
    "            results[\"value_loss\"] += value_loss.item()\n",
    "            results[\"policy_loss\"] += policy_loss.item()\n",
    "            results[\"value_max_correct\"] += (pred_values.argmax(dim=1) == values.argmax(dim=1)).sum().item()\n",
    "            results[\"policy_max_correct\"] += (pred_policy_logits.argmax(dim=1) == policies.argmax(dim=1)).sum().item()\n",
    "\n",
    "            total_sample_count += len(boards)\n",
    "\n",
    "    results[\"total_loss\"] /= total_sample_count\n",
    "    results[\"value_loss\"] /= total_sample_count\n",
    "    results[\"policy_loss\"] /= total_sample_count\n",
    "    results[\"value_max_correct\"] /= total_sample_count\n",
    "    results[\"policy_max_correct\"] /= total_sample_count\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 180/180 [00:03<00:00, 48.25it/s]\n",
      "100%|██████████| 20/20 [00:00<00:00, 55.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num train samples: 158528\n",
      "Num test samples: 17737\n"
     ]
    }
   ],
   "source": [
    "TRAIN_TEST_SPLIT = 0.9\n",
    "\n",
    "def get_dataset(game_files):\n",
    "    gamedata = load_games_new(game_files, with_tqdm=True)\n",
    "    boards_tensor = torch.from_numpy(gamedata[\"boards\"]).to(dtype=torch.float)\n",
    "    policies_tensor = torch.from_numpy(gamedata[\"policies\"]).to(dtype=torch.float)\n",
    "    values_tensor = torch.from_numpy(gamedata[\"values\"]).to(dtype=torch.float)\n",
    "    return torch.utils.data.TensorDataset(boards_tensor, policies_tensor, values_tensor)\n",
    "\n",
    "file_paths = glob.glob(\"/Users/shivamsarodia/Dev/blockus/data/2024-11-23_00-37-50-doublehandedness/untrained_games_*/*.npz\")\n",
    "\n",
    "random.seed(20554)\n",
    "random.shuffle(file_paths)\n",
    "\n",
    "# Truncate the to 200 for testing\n",
    "file_paths = file_paths[:200]\n",
    "\n",
    "num_train_games = int(len(file_paths) * TRAIN_TEST_SPLIT)\n",
    "train_file_paths = file_paths[:num_train_games]\n",
    "test_file_paths = file_paths[num_train_games:]\n",
    "\n",
    "train_dataset = get_dataset(train_file_paths)\n",
    "test_dataset = get_dataset(test_file_paths)\n",
    "\n",
    "print(\"Num train samples:\", len(train_dataset))\n",
    "print(\"Num test samples:\", len(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_losses(model):\n",
    "    dataloader = torch.utils.data.DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=True,\n",
    "    )\n",
    "    model.eval()\n",
    "\n",
    "    results = {\n",
    "        \"total_loss\": 0,\n",
    "        \"value_loss\": 0,\n",
    "        \"policy_loss\": 0,\n",
    "        \"value_max_correct\": 0,\n",
    "        \"policy_max_correct\": 0,\n",
    "    }\n",
    "\n",
    "    total_sample_count = 0\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        for boards, policies, values in dataloader:\n",
    "            boards = boards.to(dtype=torch.float32, device=DEVICE)\n",
    "            policies = policies.to(dtype=torch.float32, device=DEVICE)\n",
    "            values = values.to(dtype=torch.float32, device=DEVICE)\n",
    "\n",
    "            pred_values, pred_policy_logits = model(boards.to(dtype=torch.float32, device=DEVICE))\n",
    "            value_loss = nn.CrossEntropyLoss(reduction=\"sum\")(\n",
    "                pred_values,\n",
    "                values,\n",
    "            )\n",
    "            policy_loss = nn.CrossEntropyLoss(reduction=\"sum\")(\n",
    "                pred_policy_logits,\n",
    "                policies,\n",
    "            )\n",
    "            loss = value_loss + POLICY_LOSS_WEIGHT * policy_loss\n",
    "\n",
    "            results[\"total_loss\"] += loss.item()\n",
    "            results[\"value_loss\"] += value_loss.item()\n",
    "            results[\"policy_loss\"] += policy_loss.item()\n",
    "            results[\"value_max_correct\"] += (pred_values.argmax(dim=1) == values.argmax(dim=1)).sum().item()\n",
    "            results[\"policy_max_correct\"] += (pred_policy_logits.argmax(dim=1) == policies.argmax(dim=1)).sum().item()\n",
    "\n",
    "            total_sample_count += len(boards)\n",
    "\n",
    "    results[\"total_loss\"] /= total_sample_count\n",
    "    results[\"value_loss\"] /= total_sample_count\n",
    "    results[\"policy_loss\"] /= total_sample_count\n",
    "    results[\"value_max_correct\"] /= total_sample_count\n",
    "    results[\"policy_max_correct\"] /= total_sample_count\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1239 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "NotImplementedError",
     "evalue": "The operator 'aten::_amp_foreach_non_finite_check_and_unscale_' is not currently implemented for the MPS device. If you want this op to be added in priority during the prototype phase of this feature, please comment on https://github.com/pytorch/pytorch/issues/77764. As a temporary fix, you can set the environment variable `PYTORCH_ENABLE_MPS_FALLBACK=1` to use the CPU as a fallback for this op. WARNING: this will be slower than running natively on MPS.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 39\u001b[0m\n\u001b[1;32m     36\u001b[0m     loss \u001b[38;5;241m=\u001b[39m value_loss \u001b[38;5;241m+\u001b[39m POLICY_LOSS_WEIGHT \u001b[38;5;241m*\u001b[39m policy_loss\n\u001b[1;32m     38\u001b[0m scaler\u001b[38;5;241m.\u001b[39mscale(loss)\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m---> 39\u001b[0m \u001b[43mscaler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     40\u001b[0m scaler\u001b[38;5;241m.\u001b[39mupdate()\n\u001b[1;32m     42\u001b[0m \u001b[38;5;66;03m# loss.backward()\u001b[39;00m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;66;03m# optimizer.step()\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.3/lib/python3.11/site-packages/torch/amp/grad_scaler.py:455\u001b[0m, in \u001b[0;36mGradScaler.step\u001b[0;34m(self, optimizer, *args, **kwargs)\u001b[0m\n\u001b[1;32m    452\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m retval\n\u001b[1;32m    454\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m optimizer_state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstage\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;129;01mis\u001b[39;00m OptState\u001b[38;5;241m.\u001b[39mREADY:\n\u001b[0;32m--> 455\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munscale_\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    457\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m (\n\u001b[1;32m    458\u001b[0m     \u001b[38;5;28mlen\u001b[39m(optimizer_state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfound_inf_per_device\u001b[39m\u001b[38;5;124m\"\u001b[39m]) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    459\u001b[0m ), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo inf checks were recorded for this optimizer.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    461\u001b[0m retval \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_opt_step(optimizer, optimizer_state, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.3/lib/python3.11/site-packages/torch/amp/grad_scaler.py:342\u001b[0m, in \u001b[0;36mGradScaler.unscale_\u001b[0;34m(self, optimizer)\u001b[0m\n\u001b[1;32m    339\u001b[0m     inv_scale \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_scale\u001b[38;5;241m.\u001b[39mdouble()\u001b[38;5;241m.\u001b[39mreciprocal()\u001b[38;5;241m.\u001b[39mfloat()\n\u001b[1;32m    340\u001b[0m found_inf \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfull((), \u001b[38;5;241m0.0\u001b[39m, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_scale\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m--> 342\u001b[0m optimizer_state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfound_inf_per_device\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_unscale_grads_\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    343\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minv_scale\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[1;32m    344\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    345\u001b[0m optimizer_state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstage\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m OptState\u001b[38;5;241m.\u001b[39mUNSCALED\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.3/lib/python3.11/site-packages/torch/amp/grad_scaler.py:279\u001b[0m, in \u001b[0;36mGradScaler._unscale_grads_\u001b[0;34m(self, optimizer, inv_scale, found_inf, allow_fp16)\u001b[0m\n\u001b[1;32m    277\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m device, per_dtype_grads \u001b[38;5;129;01min\u001b[39;00m per_device_and_dtype_grads\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m    278\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m grads \u001b[38;5;129;01min\u001b[39;00m per_dtype_grads\u001b[38;5;241m.\u001b[39mvalues():\n\u001b[0;32m--> 279\u001b[0m             \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_amp_foreach_non_finite_check_and_unscale_\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    280\u001b[0m \u001b[43m                \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    281\u001b[0m \u001b[43m                \u001b[49m\u001b[43mper_device_found_inf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    282\u001b[0m \u001b[43m                \u001b[49m\u001b[43mper_device_inv_scale\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    283\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    285\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m per_device_found_inf\u001b[38;5;241m.\u001b[39m_per_device_tensors\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: The operator 'aten::_amp_foreach_non_finite_check_and_unscale_' is not currently implemented for the MPS device. If you want this op to be added in priority during the prototype phase of this feature, please comment on https://github.com/pytorch/pytorch/issues/77764. As a temporary fix, you can set the environment variable `PYTORCH_ENABLE_MPS_FALLBACK=1` to use the CPU as a fallback for this op. WARNING: this will be slower than running natively on MPS."
     ]
    }
   ],
   "source": [
    "train_dataloader = torch.utils.data.DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    ")\n",
    "\n",
    "run = aim.Run(repo='/Users/shivamsarodia/Dev/blockus/')\n",
    "run[\"hparams\"] = {\n",
    "    \"batch_size\": BATCH_SIZE,\n",
    "    \"learning_rate\": LEARNING_RATE,\n",
    "    \"policy_loss_weight\": POLICY_LOSS_WEIGHT,\n",
    "}\n",
    "\n",
    "scaler = GradScaler(device=DEVICE)\n",
    "\n",
    "model.train()\n",
    "\n",
    "batch_index = 0\n",
    "for epoch in range(1):\n",
    "    for boards, policies, values in tqdm(train_dataloader):\n",
    "        boards = boards.to(dtype=torch.float32, device=DEVICE)\n",
    "        policies = policies.to(dtype=torch.float32, device=DEVICE)\n",
    "        values = values.to(dtype=torch.float32, device=DEVICE)\n",
    "\n",
    "        with autocast(device_type=DEVICE, dtype=torch.float16):\n",
    "            pred_values, pred_policy = model(boards)\n",
    "            value_loss = nn.CrossEntropyLoss()(\n",
    "                pred_values,\n",
    "                values,\n",
    "            )\n",
    "\n",
    "            policy_loss = nn.CrossEntropyLoss()(\n",
    "                pred_policy,\n",
    "                policies,\n",
    "            )\n",
    "            loss = value_loss + POLICY_LOSS_WEIGHT * policy_loss\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        # loss.backward()\n",
    "        # optimizer.step()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        training_result = {\n",
    "            \"total_loss\": loss.item(),\n",
    "            \"value_loss\": value_loss.item(),\n",
    "            \"policy_loss\": policy_loss.item(),\n",
    "            \"value_max_correct\": (pred_values.argmax(dim=1) == values.argmax(dim=1)).sum().item() / len(boards),\n",
    "            \"policy_max_correct\": (pred_policy.argmax(dim=1) == policies.argmax(dim=1)).sum().item() / len(boards),\n",
    "        }\n",
    "\n",
    "        for key, value in training_result.items():\n",
    "            run.track(\n",
    "                value,\n",
    "                name=key,\n",
    "                step=batch_index,\n",
    "                context={\"subset\": \"train\"},\n",
    "            )\n",
    "\n",
    "        if batch_index % 1000 == 0:\n",
    "            test_losses = get_test_losses(model)\n",
    "            for key, value in test_losses.items():\n",
    "                run.track(\n",
    "                    value,\n",
    "                    name=key,\n",
    "                    step=batch_index,\n",
    "                    context={\"subset\": \"test\"},\n",
    "                )\n",
    "                print(test_losses)\n",
    "        batch_index += 1\n",
    "\n",
    "    print(\"Finished epoch\")\n",
    "\n",
    "run.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "run.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(model.state_dict(), \"../data/2024-12-02_21-22-57-notebook-models/sample_ratio_two_2.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_dataloader = torch.utils.data.DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=1,\n",
    "    shuffle=False,\n",
    ")\n",
    "\n",
    "boards_seen = set()\n",
    "total_boards_count = 0\n",
    "boards_with_at_least_one_piece_count = 0\n",
    "boards_with_at_least_two_pieces_count = 0\n",
    "boards_with_at_least_three_pieces_count = 0\n",
    "boards_with_at_least_four_pieces_count = 0\n",
    "for boards, policies, values, valid_moves in tqdm(count_dataloader):\n",
    "    boards_seen.add(boards.numpy(force=True).tobytes())\n",
    "    total_boards_count += 1\n",
    "    if torch.sum(boards) > 0:\n",
    "        boards_with_at_least_one_piece_count += 1\n",
    "    if torch.sum(boards) > 5:\n",
    "        boards_with_at_least_two_pieces_count += 1\n",
    "    if torch.sum(boards) > 10:\n",
    "        boards_with_at_least_three_pieces_count += 1\n",
    "    if torch.sum(boards) > 15:\n",
    "        boards_with_at_least_four_pieces_count += 1\n",
    "        \n",
    "print(\"Number of unique boards:\", len(boards_seen))\n",
    "print(\"Number of boards with at least one piece:\", boards_with_at_least_one_piece_count)\n",
    "print(\"Number of boards with at least two pieces:\", boards_with_at_least_two_pieces_count)\n",
    "print(\"Number of boards with at least three pieces:\", boards_with_at_least_three_pieces_count)\n",
    "print(\"Number of boards with at least four pieces:\", boards_with_at_least_four_pieces_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load models\n",
    "def load_model(path):\n",
    "    model = NeuralNet(NETWORK_CONFIG)\n",
    "    model.load_state_dict(torch.load(path, weights_only=True))\n",
    "    model.to(DEVICE)\n",
    "    return model\n",
    "\n",
    "# base_model_1 = load_model(\"/Users/shivamsarodia/Dev/blockus/data/2024-12-02_21-22-57-notebook-models/base_in_notebook_1.pt\")\n",
    "# base_model_2 = load_model(\"/Users/shivamsarodia/Dev/blockus/data/2024-12-02_21-22-57-notebook-models/base_in_notebook_2.pt\")\n",
    "# ratio_two_model_1 = load_model(\"/Users/shivamsarodia/Dev/blockus/data/2024-12-02_21-22-57-notebook-models/sample_ratio_two_1.pt\")\n",
    "ratio_two_model_2 = load_model(\"/Users/shivamsarodia/Dev/blockus/data/2024-12-02_21-22-57-notebook-models/sample_ratio_two_2.pt\")\n",
    "\n",
    "# print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_test_losses(ratio_two_model_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_game_files = glob.glob(\"/Users/shivamsarodia/Dev/blockus/data/2024-11-23_00-37-50-doublehandedness/more_games_we_didnt_train_on/*.npz\")\n",
    "test_gamedata = load_games_new(test_game_files, with_tqdm=True)\n",
    "\n",
    "print(\"Converting to tensors...\")\n",
    "\n",
    "# Convert numpy arrays to torch tensors\n",
    "boards_tensor = torch.from_numpy(test_gamedata[\"boards\"]).to(dtype=torch.float, device=\"mps\")\n",
    "policies_tensor = torch.from_numpy(test_gamedata[\"policies\"]).to(dtype=torch.float, device=\"mps\")\n",
    "values_tensor = torch.from_numpy(test_gamedata[\"values\"]).to(dtype=torch.float, device=\"mps\")\n",
    "valid_moves = torch.from_numpy(test_gamedata[\"valid_moves\"]).to(dtype=torch.bool, device=\"mps\")\n",
    "\n",
    "dataset = torch.utils.data.TensorDataset(boards_tensor, policies_tensor, values_tensor, valid_moves)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# base_model_1_test_result = get_test_losses(base_model_1)\n",
    "base_model_2_test_result = get_test_losses(base_model_2)\n",
    "# ratio_two_model_1_test_result = get_test_losses(ratio_two_model_1)\n",
    "ratio_two_model_2_test_result = get_test_losses(ratio_two_model_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(test_gamedata[\"boards\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "241365 + 336673 + 500000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model_2_test_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratio_two_model_2_test_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def range_of_boolean_var(p):\n",
    "    standard_error = np.sqrt(p * (1 - p) / len(dataset))\n",
    "    return p + 2 * standard_error, p - 2 * standard_error\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create figure with two subplots\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(10, 8))\n",
    "\n",
    "models = ['Base 1', 'Base 2', 'Ratio Two 1', 'Ratio Two 2']\n",
    "\n",
    "# Value accuracy plot\n",
    "value_accuracies = [\n",
    "    base_model_1_test_result[\"value_max_correct\"],\n",
    "    base_model_2_test_result[\"value_max_correct\"], \n",
    "    ratio_two_model_1_test_result[\"value_max_correct\"],\n",
    "    ratio_two_model_2_test_result[\"value_max_correct\"]\n",
    "]\n",
    "value_errors = [range_of_boolean_var(acc) for acc in value_accuracies]\n",
    "value_upper = [err[0] - acc for acc, err in zip(value_accuracies, value_errors)]\n",
    "value_lower = [acc - err[1] for acc, err in zip(value_accuracies, value_errors)]\n",
    "\n",
    "ax1.bar(models, value_accuracies, yerr=[value_lower, value_upper], capsize=5)\n",
    "ax1.set_title('Value Prediction Accuracy')\n",
    "ax1.set_ylabel('Accuracy')\n",
    "ax1.set_ylim(bottom=min(value_accuracies) * 0.95)  # Set bottom to 95% of minimum value\n",
    "\n",
    "# Policy accuracy plot  \n",
    "policy_accuracies = [\n",
    "    base_model_1_test_result[\"policy_max_correct\"],\n",
    "    base_model_2_test_result[\"policy_max_correct\"],\n",
    "    ratio_two_model_1_test_result[\"policy_max_correct\"], \n",
    "    ratio_two_model_2_test_result[\"policy_max_correct\"]\n",
    "]\n",
    "policy_errors = [range_of_boolean_var(acc) for acc in policy_accuracies]\n",
    "policy_upper = [err[0] - acc for acc, err in zip(policy_accuracies, policy_errors)]\n",
    "policy_lower = [acc - err[1] for acc, err in zip(policy_accuracies, policy_errors)]\n",
    "\n",
    "ax2.bar(models, policy_accuracies, yerr=[policy_lower, policy_upper], capsize=5)\n",
    "ax2.set_title('Policy Prediction Accuracy')\n",
    "ax2.set_ylabel('Accuracy')\n",
    "ax2.set_ylim(bottom=min(policy_accuracies) * 0.95)  # Set bottom to 95% of minimum value\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Base model 1\")\n",
    "print(base_model_1_test_result)\n",
    "print(\"Base model 2\")\n",
    "print(base_model_2_test_result)\n",
    "print(\"Ratio two model 1\")\n",
    "print(ratio_two_model_1_test_result)\n",
    "print(\"Ratio two model 2\")\n",
    "print(ratio_two_model_2_test_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import random\n",
    "\n",
    "file_paths = glob.glob(\"/Users/shivamsarodia/Dev/blockus/data/2024-11-23_00-37-50-doublehandedness/untrained_games_*/*.npz\")\n",
    "\n",
    "random.seed(20554)\n",
    "random.shuffle(file_paths)\n",
    "\n",
    "num_train_games = int(len(file_paths) * 0.9)\n",
    "train_file_paths = file_paths[:num_train_games]\n",
    "test_file_paths = file_paths[num_train_games:]\n",
    "\n",
    "print(\"Num train files:\", len(train_file_paths))\n",
    "print(\"Num test files:\", len(test_file_paths))\n",
    "\n",
    "print(\"Loading train games...\")\n",
    "train_dataset = get_dataset(train_file_paths)\n",
    "\n",
    "print(\"Loading test games...\")\n",
    "test_dataset = get_dataset(test_file_paths)\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=1,\n",
    ")\n",
    "test_dataloader = torch.utils.data.DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "test_boards = Counter()\n",
    "for board, _, _, _ in test_dataloader:\n",
    "    test_boards[board.numpy(force=True).tobytes()] += 1\n",
    "\n",
    "print(\"Number of total test boards:\", len(test_dataset))\n",
    "print(\"Number of unique test boards:\", len(test_boards))\n",
    "\n",
    "train_boards = Counter()\n",
    "for board, _, _, _ in train_dataloader:\n",
    "    train_boards[board.numpy(force=True).tobytes()] += 1\n",
    "\n",
    "print(\"Number of total train boards:\", len(train_dataset))\n",
    "print(\"Number of unique train boards:\", len(train_boards))\n",
    "\n",
    "test_boards_in_train = Counter()\n",
    "for board in test_boards:\n",
    "    if board in train_boards:\n",
    "        test_boards_in_train[board] = test_boards[board]\n",
    "\n",
    "print(\"Number of boards shared:\", len(test_boards_in_train))\n",
    "print(\"Number of rows of test data that appear in train data:\", sum(test_boards_in_train.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "99330 / 181003"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "99330 / 181003"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of total test boards:\", len(test_dataset))\n",
    "print(\"Number of total train boards:\", len(train_dataset))\n",
    "print(\"Number of boards shared:\", len(test_boards & train_boards))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "c1 = Counter()\n",
    "c1[4] += 1\n",
    "c2 = Counter()\n",
    "c2[5] += 3\n",
    "c1 & c2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(c2.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "101767 / 181003"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for board, _, _, _ in train_dataset:\n",
    "    print(board.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
