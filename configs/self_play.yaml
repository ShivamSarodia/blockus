development:
  debug_mode: true
  profile: false
  runtime: 36000
  display_logs_in_console: false
  output_directory: "data/2024-11-19_08-38-28-extracted"

logging:
  save_interval: 3600
  mcts_report_fraction: 0.001
  gpu_evaluation: true
  made_move: true

game:
  board_size: 10
  num_moves: 6233
  moves_directory: "data/moves_10/"

architecture:
  gameplay_processes: 6
  coroutines_per_process: 256

  # Number of games to accumulate before they're flushed to disk.
  game_flush_threshold: 200

networks:
  default:
    main_body_channels: 64
    value_head_channels: 16
    value_head_flat_layer_width: 64
    policy_head_channels: 64
    residual_blocks: 8

    # One of model_path or model_directory should be specified.
    model_path: ""
    model_directory: "data/2024-11-19_08-38-28-extracted/models/"

    # Frequency to check if there's a new model to load from disk.
    new_model_check_interval: 120
    batch_size: 128

training:
  run: true
  network_name: "default"
  batch_size: 64

  policy_loss_weight: 0.158
  learning_rate: 1.0e-3

  # Frequency to check if there's new data to train on.
  new_data_check_interval: 120

default_agent:
  mcts:
    network: "default"
    full_move_probability: 0.2
    full_move_rollouts: 500
    fast_move_rollouts: 100
    # Very haphazard guess at an exploration parameter.
    ucb_exploration: 1.4
    # This mimics the value in AlphaZero using the logic from KataGo.
    total_dirichlet_alpha: 10.83
    root_exploration_fraction: 0.25

individual_agents:
  - name: "default"
  - name: "default"
  - name: "default"
  - name: "default"